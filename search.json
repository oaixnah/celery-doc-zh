{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Celery - 分布式任务队列","text":"<p>Celery 是一个简单、灵活且可靠的分布式系统，用于处理大量消息，同时为运维人员提供维护此类系统所需的工具。</p> <p>它是一个专注于实时处理的任务队列，同时也支持任务调度。</p>","path":["Celery - 分布式任务队列"],"tags":[]},{"location":"django/","level":1,"title":"与 Django 一起使用","text":"","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#django-celery","level":2,"title":"在 Django 中使用 Celery","text":"<p>Note</p> <p>Celery 的早期版本需要一个单独的库来与 Django 一起工作，但从 3.1 版本开始就不再是这样了。Django 现在已得到开箱即用的支持，因此本文档仅包含集成 Celery 和 Django 的基本方法。您将使用与非 Django 用户相同的 API，因此建议您先阅读 :ref:<code>first-steps</code> 教程，然后再回到本教程。</p> <p>Note</p> <p>Celery 5.5.x 支持 Django 2.2 LTS 或更新版本。如果您的 Django 版本低于 2.2，请使用 Celery 5.2.x；如果您的 Django 版本低于 1.11，请使用 Celery 4.4.x。</p> <p>要在 Django 项目中使用 Celery，您必须首先定义 Celery 库的一个实例（称为 \"app\"）</p> <p>如果您有一个现代的 Django 项目布局，例如：</p> <pre><code>proj\n├── manage.py\n└── proj\n    ├── __init__.py\n    ├── settings.py\n    └── urls.py\n</code></pre> <p>那么推荐的方式是创建一个新的 <code>proj/proj/celery.py</code> 模块来定义 Celery 实例：</p> proj/proj/celery.py<pre><code>import os\n\nfrom celery import Celery\n\n# 为 'celery' 程序设置默认的 Django 设置模块。\nos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'proj.settings')\n\napp = Celery('proj')\n\n# 在这里使用字符串意味着工作进程不需要将配置对象序列化到子进程。\n# - namespace='CELERY' 表示所有与 celery 相关的配置键\n#   都应该有一个 `CELERY_` 前缀。\napp.config_from_object('django.conf:settings', namespace='CELERY')\n\n# 从所有已注册的 Django 应用中加载任务模块。\napp.autodiscover_tasks()\n\n\n@app.task(bind=True, ignore_result=True)\ndef debug_task(self):\n    print(f'Request: {self.request!r}')\n</code></pre> <p>然后您需要在 <code>proj/proj/__init__.py</code> 模块中导入此应用。这确保了当 Django 启动时应用会被加载，以便稍后提到的 <code>shared_task</code> 装饰器会使用它：</p> proj/proj/__init__.py<pre><code># 这将确保应用在 Django 启动时总是被导入，\n# 以便 shared_task 会使用此应用。\nfrom .celery import app as celery_app\n\n__all__ = ('celery_app',)\n</code></pre> <p>请注意，此示例项目布局适用于较大的项目，对于简单的项目，您可以使用一个包含应用和任务定义的单一模块。</p> <p>让我们分解第一个模块中发生的事情，首先，我们为 <code>celery</code> 命令行程序设置默认的 <code>DJANGO_SETTINGS_MODULE</code> 环境变量：</p> <pre><code>os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'proj.settings')\n</code></pre> <p>您不需要这一行，但它可以避免您总是向 <code>celery</code> 程序传递设置模块。它必须始终在创建应用实例之前出现，就像我们接下来做的那样：</p> <pre><code>app = Celery('proj')\n</code></pre> <p>这是我们的库实例，您可以拥有多个实例，但在使用 Django 时可能没有理由这样做。</p> <p>我们还将 Django 设置模块添加为 Celery 的配置源。这意味着您不必使用多个配置文件，而是可以直接从 Django 设置中配置 Celery；但如果您愿意，也可以将它们分开。</p> <pre><code>app.config_from_object('django.conf:settings', namespace='CELERY')\n</code></pre> <p>大写命名空间意味着所有 配置选项 必须用大写而不是小写指定，并以 <code>CELERY_</code> 开头，例如 <code>task_always_eager</code> 设置变为 <code>CELERY_TASK_ALWAYS_EAGER</code>，而 <code>broker_url</code> 设置变为 <code>CELERY_BROKER_URL</code>。这也适用于工作进程设置，例如 <code>worker_concurrency</code> 设置变为 <code>CELERY_WORKER_CONCURRENCY</code>。</p> <p>例如，Django 项目的配置文件可能包含：</p> settings.py<pre><code>...\n\n# Celery 配置选项\nCELERY_TIMEZONE = \"Australia/Tasmania\"\nCELERY_TASK_TRACK_STARTED = True\nCELERY_TASK_TIME_LIMIT = 30 * 60\n</code></pre> <p>您可以直接传递设置对象，但使用字符串更好，因为这样工作进程就不需要序列化对象。<code>CELERY_</code> 命名空间也是可选的，但推荐使用（以防止与其他 Django 设置重叠）。</p> <p>接下来，对于可重用应用的一个常见做法是在单独的 <code>tasks.py</code> 模块中定义所有任务，而 Celery 确实有一种自动发现这些模块的方法：</p> <pre><code>app.autodiscover_tasks()\n</code></pre> <p>使用上面的代码行，Celery 将自动从所有已安装的应用中发现任务，遵循 <code>tasks.py</code> 约定：</p> <pre><code>app1/\n├── tasks.py\n└── models.py\napp2/\n├── tasks.py\n└── models.py\n</code></pre> <p>这样您就不必手动将各个模块添加到 <code>CELERY_IMPORTS &lt;imports&gt;</code> 设置中。</p> <p>最后，<code>debug_task</code> 示例是一个转储其自身请求信息的任务。这使用了 Celery 3.1 中引入的新 <code>bind=True</code> 任务选项，以便轻松引用当前任务实例。</p>","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#shared_task","level":3,"title":"使用 <code>@shared_task</code> 装饰器","text":"<p>您编写的任务可能存在于可重用应用中，而可重用应用不能依赖于项目本身，因此您也不能直接导入您的应用实例。</p> <p><code>shared_task</code> 装饰器让您可以在没有任何具体应用实例的情况下创建任务：</p> demoapp/tasks.py<pre><code># 在这里创建您的任务\n\nfrom demoapp.models import Widget\n\nfrom celery import shared_task\n\n\n@shared_task\ndef add(x, y):\n    return x + y\n\n\n@shared_task\ndef mul(x, y):\n    return x * y\n\n\n@shared_task\ndef xsum(numbers):\n    return sum(numbers)\n\n\n@shared_task\ndef count_widgets():\n    return Widget.objects.count()\n\n\n@shared_task\ndef rename_widget(widget_id, name):\n    w = Widget.objects.get(id=widget_id)\n    w.name = name\n    w.save()\n</code></pre>","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#_1","level":3,"title":"在数据库事务结束时触发任务","text":"<p>Django 的一个常见陷阱是立即触发任务而不等待数据库事务结束，这意味着 Celery 任务可能在所有更改持久化到数据库之前运行。例如：</p> <pre><code># views.py\ndef create_user(request):\n    # 注意：简化示例，请使用表单验证输入\n    user = User.objects.create(username=request.POST['username'])\n    send_email.delay(user.pk)\n    return HttpResponse('User created')\n\n# task.py\n@shared_task\ndef send_email(user_pk):\n    user = User.objects.get(pk=user_pk)\n    # 发送邮件 ...\n</code></pre> <p>在这种情况下，<code>send_email</code> 任务可能在视图提交事务到数据库之前启动，因此任务可能无法找到用户。</p> <p>一个常见的解决方案是使用 Django 的 on_commit 钩子在事务提交后触发任务：</p> <pre><code>- send_email.delay(user.pk)\n+ transaction.on_commit(lambda: send_email.delay(user.pk))\n</code></pre> <p>由于这是一个非常常见的模式，Celery 5.4 为此引入了一个方便的快捷方式，使用 <code>celery.contrib.django.task.DjangoTask</code>。您应该调用 <code>celery.contrib.django.task.DjangoTask.delay_on_commit</code> 而不是调用 <code>celery.app.task.Task.delay</code>：</p> <pre><code>- send_email.delay(user.pk)\n+ send_email.delay_on_commit(user.pk)\n</code></pre> <p>此 API 负责为您将调用包装到 <code>on_commit</code>_ 钩子中。在极少数情况下，如果您想不等待就触发任务，现有的 <code>celery.app.task.Task.delay</code> API 仍然可用。</p> <p>与 <code>delay</code> 方法相比，一个关键区别是 <code>delay_on_commit</code> 不会将任务 ID 返回给调用者。当您调用该方法时，任务不会发送到代理，只有在 Django 事务完成时才会发送。如果您需要任务 ID，最好坚持使用 <code>celery.app.task.Task.delay</code>。</p> <p>如果您按照上面的设置步骤操作，此任务类应该会自动使用。您需要从 <code>celery.contrib.django.task.DjangoTask</code> 继承而不是 <code>celery.app.task.Task</code> 以获得此行为。</p>","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#django_1","level":3,"title":"Django 连接池","text":"<p>从 Django 5.1+ 开始，内置支持数据库连接池。如果您在 Django <code>DATABASES</code> 设置中启用它，Celery 将自动通过 <code>close_pool</code> 数据库后端方法处理工作进程中的连接池关闭，因为跨进程共享连接是不可能的</p> <p>您可以在 Django 文档 中找到有关连接池的更多信息。</p>","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#_2","level":2,"title":"扩展","text":"","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#django-celery-results","level":3,"title":"<code>django-celery-results</code>","text":"<p>使用 Django ORM/缓存作为结果后端</p> <p><code>django-celery-results</code> 扩展提供了使用 Django ORM 或 Django 缓存框架的结果后端。</p> <p>要在您的项目中使用此扩展，您需要遵循以下步骤：</p> <ol> <li> <p>安装 <code>django-celery-results</code> 库：</p> <pre><code>pip install django-celery-results\n</code></pre> </li> <li> <p>在您的 Django 项目的 <code>settings.py</code> 中将 <code>django_celery_results</code> 添加到 <code>INSTALLED_APPS</code>：</p> <pre><code>INSTALLED_APPS = (\n    ...,\n    'django_celery_results',\n)\n</code></pre> <p>请注意模块名称中没有破折号，只有下划线。</p> </li> <li> <p>通过执行数据库迁移来创建 Celery 数据库表：</p> <pre><code>python manage.py migrate django_celery_results\n</code></pre> </li> <li> <p>配置 Celery 使用 <code>django-celery-results</code> 后端。</p> <p>假设您使用 Django 的 <code>settings.py</code> 来配置 Celery，添加以下设置：</p> <pre><code>CELERY_RESULT_BACKEND = 'django-db'\n</code></pre> <p>当使用缓存后端时，您可以指定在 Django 的 CACHES 设置中定义的缓存。</p> <pre><code>CELERY_RESULT_BACKEND = 'django-cache'\n\n# 从 CACHES 设置中选择哪个缓存。\nCELERY_CACHE_BACKEND = 'default'\n\n# django 设置。\nCACHES = {\n    'default': {\n        'BACKEND': 'django.core.cache.backends.db.DatabaseCache',\n        'LOCATION': 'my_cache_table',\n    }\n}\n</code></pre> </li> </ol>","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#django-celery-beat","level":3,"title":"<code>django-celery-beat</code>","text":"<p>基于数据库的周期性任务，带有管理界面。</p>","path":["与 Django 一起使用"],"tags":[]},{"location":"django/#_3","level":2,"title":"启动工作进程","text":"<p>对于测试和开发，能够使用 <code>celery worker</code> 管理命令启动工作进程实例非常有用，就像您使用 Django 的 <code>manage.py runserver</code> 一样：</p> <pre><code>celery -A proj worker -l INFO\n</code></pre> <p>要获取可用命令行选项的完整列表，请使用帮助命令：</p> <pre><code>celery --help\n</code></pre>","path":["与 Django 一起使用"],"tags":[]},{"location":"faq/","level":1,"title":"常见问题解答","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#_2","level":2,"title":"概述","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery","level":3,"title":"我应该使用 Celery 来做什么？","text":"<p>回答： 队列化一切，让所有人满意 是一篇很好的文章，描述了为什么在 Web 环境中使用队列。</p> <p>以下是一些常见的用例：</p> <ul> <li> <p>在后台运行某些任务。例如，尽快完成 Web 请求，   然后逐步更新用户页面。   这给用户留下了良好性能和\"响应迅速\"的印象，即使   实际工作可能需要一些时间。</p> </li> <li> <p>在 Web 请求完成后运行某些任务。</p> </li> <li> <p>通过异步执行和使用重试机制来确保某些任务完成。</p> </li> <li> <p>调度定期工作。</p> </li> </ul> <p>在某种程度上还包括：</p> <ul> <li> <p>分布式计算。</p> </li> <li> <p>并行执行。</p> </li> </ul>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_3","level":2,"title":"误解","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery-50000","level":3,"title":"Celery 真的包含 50,000 行代码吗？","text":"<p>回答： 不，这个以及类似的大数字已经在多个地方被报告过。</p> <p>截至本文撰写时的数字是：</p> <ul> <li>核心：7,141 行代码</li> <li>测试：14,209 行</li> <li>后端、贡献、兼容性工具：9,032 行</li> </ul> <p>代码行数不是一个有用的指标，所以即使 Celery 确实包含 50k 行代码，你也不能从这样的数字中得出任何结论。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery_1","level":3,"title":"Celery 有很多依赖项吗？","text":"<p>一个常见的批评是 Celery 使用了太多的依赖项。 这种担忧背后的理由很难想象，特别是考虑到代码重用是现代软件开发中对抗复杂性的既定方式，而且现在添加依赖项的成本非常低，因为像 pip 和 PyPI 这样的包管理器使得安装和维护依赖项的麻烦成为过去。</p> <p>Celery 在过程中已经替换了几个依赖项，当前的依赖项列表是：</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery_2","level":4,"title":"celery","text":"<ul> <li><code>kombu</code></li> </ul> <p>Kombu 是 Celery 生态系统的一部分，是用于发送和接收消息的库。它也是使我们能够支持许多不同消息代理的库。它也被 OpenStack 项目和许多其他项目使用，验证了将其与 Celery 代码库分离的选择。</p> <ul> <li><code>billiard</code></li> </ul> <p>Billiard 是 Python 多处理模块的一个分支，包含许多性能和稳定性改进。最终目标是这些改进有一天会被合并回 Python。</p> <p>它也用于与不包含多处理模块的旧版 Python 版本的兼容性。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#kombu","level":4,"title":"kombu","text":"<p>Kombu 依赖于以下包：</p> <ul> <li><code>amqp</code></li> </ul> <p>底层的纯 Python amqp 客户端实现。AMQP 作为默认代理，这是一个自然的依赖项。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery_3","level":3,"title":"Celery 是重量级的吗？","text":"<p>Celery 在内存占用和性能方面都带来了非常小的开销。</p> <p>但请注意，默认配置没有针对时间或空间进行优化，请参阅 优化指南 以获取更多信息。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery-pickle","level":3,"title":"Celery 依赖于 pickle 吗？","text":"<p>回答： 不，Celery 可以支持任何序列化方案。</p> <p>我们内置支持 JSON、YAML、Pickle 和 msgpack。每个任务都与一个内容类型相关联，因此你甚至可以使用 pickle 发送一个任务，使用 JSON 发送另一个任务。</p> <p>默认的序列化支持曾经是 pickle，但从 4.0 开始默认现在是 JSON。如果你需要发送复杂的 Python 对象作为任务参数，你可以使用 pickle 作为序列化格式。</p> <p>如果你需要与其他语言通信，你应该使用适合该任务的序列化格式，这基本上意味着任何不是 pickle 的序列化器。</p> <p>你可以设置全局默认序列化器、特定任务的默认序列化器， 甚至是发送单个任务实例时要使用的序列化器。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery-django","level":3,"title":"Celery 只适用于 Django 吗？","text":"<p>回答： 不，你可以在任何框架中使用 Celery，无论是 Web 框架还是其他框架。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#amqprabbitmq","level":3,"title":"我必须使用 AMQP/RabbitMQ 吗？","text":"<p>回答： 不，虽然推荐使用 RabbitMQ，但你也可以使用 Redis、SQS 或 Qpid。</p> <p>Redis 作为代理的性能不如 AMQP 代理，但 RabbitMQ 作为代理和 Redis 作为结果存储的组合是常用的。如果你有严格的可靠性要求，鼓励你使用 RabbitMQ 或其他 AMQP 代理。一些传输也使用轮询，因此它们可能会消耗更多资源。然而，如果你由于某种原因无法使用 AMQP，请随意使用这些替代方案。它们可能适用于大多数用例，并请注意上述观点并非特定于 Celery；如果之前使用 Redis/数据库作为队列对你有效，现在可能仍然有效。如果需要，你以后可以随时升级。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery_4","level":3,"title":"Celery 是多语言的吗？","text":"<p>回答： 是的。</p> <p><code>celery.bin.worker</code> 是 Celery 在 Python 中的实现。如果某种语言有 AMQP 客户端，创建该语言的 worker 应该不会太困难。一个 Celery worker 只是一个连接到代理来处理消息的程序。</p> <p>此外，还有另一种实现语言独立性的方法，那就是使用 REST 任务，不是将任务作为函数，而是将它们作为 URL。有了这个信息，你甚至可以创建简单的 Web 服务器，实现代码的预加载。只需暴露一个执行操作的端点，并创建一个任务来对该端点执行 HTTP 请求。</p> <p>你也可以使用 Flower's [REST API](https://flower.readthedocs.io/en/latest/api.html#post--api-task-async-apply-(.+) 来调用任务。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_4","level":2,"title":"故障排除","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#mysql","level":3,"title":"MySQL 抛出死锁错误，我该怎么办？","text":"<p>回答： MySQL 默认的隔离级别设置为 <code>REPEATABLE-READ</code>（可重复读），如果您并不真正需要这个级别，请将其设置为 <code>READ-COMMITTED</code>（读已提交）。您可以通过在 :file:<code>my.cnf</code> 文件中添加以下内容来实现：：</p> <pre><code>[mysqld]\ntransaction-isolation = READ-COMMITTED\n</code></pre> <p>有关 InnoDB 事务模型的更多信息，请参阅 MySQL - InnoDB 事务模型和锁定。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#worker","level":3,"title":"Worker 什么都不做，只是挂起","text":"<p>回答： 请参阅 <code>MySQL 抛出死锁错误，我该怎么办？</code>，或 <code>为什么 Task.delay/apply\\*/worker 只是挂起？</code>。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_5","level":3,"title":"任务结果不可靠地返回","text":"<p>回答： 如果您使用数据库后端来存储结果，特别是使用 MySQL，请参阅 <code>MySQL 抛出死锁错误，我该怎么办？</code>。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#taskdelayapplyworker","level":3,"title":"为什么 Task.delay/apply*/worker 只是挂起？","text":"<p>回答： 某些 AMQP 客户端存在一个错误，如果无法验证当前用户、密码不匹配或用户没有访问指定虚拟主机的权限，就会导致挂起。请务必检查您的代理日志（对于 RabbitMQ，在大多数系统上是 :file:<code>/var/log/rabbitmq/rabbit.log</code>），通常其中会包含描述原因的消息。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#freebsd","level":3,"title":"它能在 FreeBSD 上工作吗？","text":"<p>回答： 这取决于具体情况；</p> <p>当使用 RabbitMQ（AMQP）和 Redis 传输时，它应该可以开箱即用。</p> <p>对于其他传输方式，会使用兼容性 prefork 池，这需要可用的 POSIX 信号量实现，自 FreeBSD 8.x 以来，FreeBSD 默认启用了此功能。对于较旧版本的 FreeBSD，您必须在内核中启用 POSIX 信号量并手动重新编译 billiard。</p> <p>幸运的是，Viktor Petersson 编写了一个教程，帮助您在 FreeBSD 上开始使用 Celery： http://www.playingwithwire.com/2009/10/how-to-get-celeryd-to-work-on-freebsd/</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#integrityerror-duplicate-key","level":3,"title":"我遇到了 <code>IntegrityError: Duplicate Key</code> 错误。为什么？","text":"<p>回答： 请参阅 <code>MySQL 抛出死锁错误，我该怎么办？</code>。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_6","level":3,"title":"为什么我的任务没有被处理？","text":"<p>回答： 使用 RabbitMQ 时，您可以通过运行以下命令查看当前有多少消费者正在接收任务：</p> <pre><code>rabbitmqctl list_queues -p &lt;myvhost&gt; name messages consumers\nListing queues ...\ncelery     2891    2\n</code></pre> <p>这显示任务队列中有 2891 条消息等待处理，有两个消费者正在处理它们。</p> <p>队列永远不会被清空的一个原因可能是您有一个陈旧的 worker 进程劫持了消息。如果 worker 没有正确关闭，就可能发生这种情况。</p> <p>当 worker 接收到消息时，代理会等待消息被确认后才将其标记为已处理。在消费者正确关闭之前，代理不会将该消息重新发送给另一个消费者。</p> <p>如果您遇到此问题，必须手动杀死所有 worker 并重新启动它们：</p> <pre><code>pkill 'celery worker'\n\n# - 如果您没有 pkill，请使用：\n# ps auxww | awk '/celery worker/ {print $2}' | xargs kill\n</code></pre> <p>您可能需要等待一段时间，直到所有 worker 完成执行任务。 如果长时间后仍然挂起，您可以使用强制方式杀死它们：</p> <pre><code>pkill -9 'celery worker'\n\n# - 如果您没有 pkill，请使用：\n# ps auxww | awk '/celery worker/ {print $2}' | xargs kill -9\n</code></pre>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_7","level":3,"title":"为什么我的任务不运行？","text":"<p>回答： 可能存在语法错误阻止了任务模块的导入。</p> <p>您可以通过手动执行任务来检查 Celery 是否能够运行该任务：</p> <pre><code>&gt;&gt;&gt; from myapp.tasks import MyPeriodicTask\n&gt;&gt;&gt; MyPeriodicTask.delay()\n</code></pre> <p>查看 worker 的日志文件，看看它是否能够找到任务，或者是否发生了其他错误。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_8","level":3,"title":"为什么我的周期性任务不运行？","text":"<p>回答： 请参阅 <code>为什么我的任务不运行？</code>。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_9","level":3,"title":"如何清除所有等待的任务？","text":"<p>回答： 您可以使用 <code>celery purge</code> 命令清除所有配置的任务队列：</p> <pre><code>celery -A proj purge\n</code></pre> <p>或者通过编程方式：</p> <pre><code>&gt;&gt;&gt; from proj.celery import app\n&gt;&gt;&gt; app.control.purge()\n1753\n</code></pre> <p>如果您只想清除特定队列中的消息， 必须使用 AMQP API 或 <code>celery amqp</code> 实用程序：</p> <pre><code>celery -A proj amqp queue.purge &lt;queue name&gt;\n</code></pre> <p>数字 1753 是已删除消息的数量。</p> <p>您还可以在启动 worker 时启用 <code>celery worker --purge</code> 选项，以便在 worker 启动时清除消息。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_10","level":3,"title":"我已经清除了消息，但队列中仍有消息？","text":"<p>回答： 任务在实际执行后才会被确认（从队列中移除）。在 worker 接收到任务后，需要一些时间才能实际执行，特别是如果已经有大量任务等待执行时。未被确认的消息会被 worker 保留，直到它关闭与代理（AMQP 服务器）的连接。当该连接关闭时（例如，因为 worker 被停止），代理会将任务重新发送给下一个可用的 worker（或者在 worker 重新启动后发送给同一个 worker），因此要正确清除队列中的等待任务，您必须停止所有 worker，然后使用 <code>celery.control.purge</code> 清除任务。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_11","level":2,"title":"结果","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#id","level":3,"title":"如果我有指向任务的ID，如何获取任务的结果？","text":"<p>回答：使用 <code>task.AsyncResult</code>：</p> <pre><code>&gt;&gt;&gt; result = my_task.AsyncResult(task_id)\n&gt;&gt;&gt; result.get()\n</code></pre> <p>这将为您提供一个 <code>celery.result.AsyncResult</code> 实例使用任务的当前结果后端。</p> <p>如果您需要指定自定义结果后端，或者想要使用当前应用程序的默认后端，您可以使用 <code>AsyncResult</code>：</p> <pre><code>&gt;&gt;&gt; result = app.AsyncResult(task_id)\n&gt;&gt;&gt; result.get()\n</code></pre>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_12","level":2,"title":"安全","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#pickle","level":3,"title":"使用 <code>pickle</code> 是否存在安全风险？","text":"<p>回答：确实如此，自 Celery 4.0 起，默认的序列化器已改为 JSON，以确保人们能够有意识地选择序列化器并意识到这一风险。</p> <p>保护您的代理、数据库和其他传输 pickle 数据的服务免受未经授权的访问至关重要。</p> <p>请注意，这不仅仅是 Celery 需要注意的问题，例如 Django 也使用 pickle 作为其缓存客户端。</p> <p>对于任务消息，您可以将 <code>task_serializer</code> 设置改为 \"json\" 或 \"yaml\" 而不是 pickle。同样地，对于任务结果，您可以设置 <code>result_serializer</code>。</p> <p>有关使用的格式以及在检查任务使用什么格式时的查找顺序的更多详细信息。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_13","level":3,"title":"消息可以加密吗？","text":"<p>回答：一些 AMQP 代理支持使用 SSL（包括 RabbitMQ）。您可以使用 <code>broker_use_ssl</code> 设置来启用此功能。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#root-programcelery-worker","level":3,"title":"以 root 身份运行 :program:<code>celery worker</code> 安全吗？","text":"<p>回答：不安全！</p> <p>我们目前没有发现任何安全问题，但假设不存在安全问题是极其天真的，因此建议以非特权用户身份运行 Celery 服务（<code>celery worker</code>、<code>celery beat</code>、<code>celeryev</code> 等）。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_14","level":2,"title":"消息代理","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#rabbitmq","level":3,"title":"为什么 RabbitMQ 会崩溃？","text":"<p>回答： 如果 RabbitMQ 内存耗尽，它就会崩溃。这将在 RabbitMQ 的未来版本中得到修复。请参考 RabbitMQ 常见问题解答： https://www.rabbitmq.com/faq.html#node-runs-out-of-memory</p> <p>Note</p> <p>这种情况已经不再存在，RabbitMQ 2.0 及以上版本包含了一个新的持久化器，能够容忍内存不足错误。建议为 Celery 使用 RabbitMQ 2.1 或更高版本。</p> <p>如果您仍在运行旧版本的 RabbitMQ 并遇到崩溃问题，请升级！</p> <p>Celery 的错误配置最终可能导致旧版本 RabbitMQ 的崩溃。即使没有崩溃，这仍然会消耗大量资源，因此了解常见的陷阱非常重要。</p> <ul> <li> <p>事件。</p> <p>使用 <code>celery worker -E</code> 选项运行 <code>celery.bin.worker</code> 将发送工作器内部发生事件的消息。</p> <p>只有在有活动监视器消费这些事件时，或者定期清除事件队列时，才应启用事件。</p> </li> <li> <p>AMQP 后端结果。</p> <p>当使用 AMQP 结果后端运行时，每个任务结果都将作为消息发送。如果您不收集这些结果，它们会累积起来，RabbitMQ 最终会耗尽内存。</p> <p>这个结果后端现在已被弃用，因此您不应该使用它。对于 rpc 风格的调用使用 RPC 后端，或者如果您需要多消费者访问结果，请使用持久化后端。</p> <p>默认情况下，结果会在 1 天后过期。通过配置 <code>result_expires</code> 设置来降低此值可能是个好主意。</p> <p>如果您不使用任务的结果，请确保设置 <code>ignore_result</code> 选项：</p> <pre><code>@app.task(ignore_result=True)\ndef mytask():\n    pass\n\nclass MyTask(Task):\n    ignore_result = True\n</code></pre> </li> </ul>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery-activemqstomp","level":3,"title":"我可以在 Celery 中使用 ActiveMQ/STOMP 吗？","text":"<p>回答： 不可以。它曾经由 <code>Carrot</code>（我们的旧消息库）支持但目前在 <code>Kombu</code>（我们的新消息库）中不受支持。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#amqp","level":3,"title":"不使用 AMQP 代理时，哪些功能不受支持？","text":"<p>这是使用虚拟传输时不可用的功能不完整列表：</p> <ul> <li>远程控制命令（仅 Redis 支持）。</li> <li>使用事件进行监视可能无法在所有虚拟传输中工作。</li> <li><code>header</code> 和 <code>fanout</code> 交换类型（<code>fanout</code> 由 Redis 支持）。</li> </ul>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_15","level":2,"title":"任务","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#_16","level":3,"title":"如何在调用任务时重用相同的连接？","text":"<p>回答：请参阅 :setting:<code>broker_pool_limit</code> 设置。连接池自版本 2.5 起默认启用。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#subprocess-sudo-none","level":3,"title":"在 <code>subprocess</code> 中的 <code>sudo</code> 返回 <code>None</code>","text":"<p>有一个 <code>sudo</code> 配置选项使得没有 tty 的进程运行 <code>sudo</code> 是非法的：</p> <pre><code>Defaults requiretty\n</code></pre> <p>如果在你的 <code>/etc/sudoers</code> 文件中有此配置，那么当 worker 作为守护进程运行时，任务将无法调用 <code>sudo</code>。如果你想启用此功能，则需要从 <code>/etc/sudoers</code> 中删除该行。</p> <p>参考：http://timelordz.com/wiki/Apache_Sudo_Commands</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#worker_1","level":3,"title":"为什么 worker 会从队列中删除无法处理的任务？","text":"<p>回答：</p> <p>worker 会拒绝未知任务、编码错误的消息以及不包含适当字段的消息（根据任务消息协议）。</p> <p>如果不拒绝它们，它们可能会被重复传递，导致循环。</p> <p>RabbitMQ 的最新版本具有为交换配置死信队列的能力，因此被拒绝的消息会被移动到那里。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_17","level":3,"title":"我可以通过名称调用任务吗？","text":"<p>回答：是的，使用 <code>send_task</code>。</p> <p>你也可以使用 AMQP 客户端从任何语言通过名称调用任务：</p> <pre><code>&gt;&gt;&gt; app.send_task('tasks.add', args=[2, 2], kwargs={})\n&lt;AsyncResult: 373550e8-b9a0-4666-bc61-ace01fa4f91d&gt;\n</code></pre> <p>要使用 <code>chain</code>、<code>chord</code> 或 <code>group</code> 与按名称调用的任务，请使用 <code>Celery.signature</code> 方法：</p> <pre><code>&gt;&gt;&gt; chain(\n...     app.signature('tasks.add', args=[2, 2], kwargs={}),\n...     app.signature('tasks.add', args=[1, 1], kwargs={})\n... ).apply_async()\n&lt;AsyncResult: e9d52312-c161-46f0-9013-2713e6df812d&gt;\n</code></pre>","path":["常见问题解答"],"tags":[]},{"location":"faq/#task-id","level":3,"title":"我可以获取当前任务的 task id 吗？","text":"<p>回答：是的，当前 id 和更多信息在任务请求中可用：：</p> <pre><code>@app.task(bind=True)\ndef mytask(self):\n    cache.set(self.request.id, \"Running\")\n</code></pre> <p>如果你没有对任务实例的引用，可以使用 <code>app.current_task</code>：</p> <pre><code>&gt;&gt;&gt; app.current_task.request.id\n</code></pre> <p>但请注意，这可能是任何任务，无论是 worker 执行的任务，还是该任务直接调用的任务，或者是急切调用的任务。</p> <p>要特别获取当前正在处理的任务，请使用 <code>app.current_worker_task</code>：</p> <pre><code>&gt;&gt;&gt; app.current_worker_task.request.id\n</code></pre> <p>Note</p> <p><code>app.current_task</code> 和 <code>app.current_worker_task</code> 都可能为 <code>None</code>。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#task_id","level":3,"title":"我可以指定自定义的 task_id 吗？","text":"<p>回答：是的，使用 <code>Task.apply_async</code> 的 <code>task_id</code> 参数：</p> <pre><code>&gt;&gt;&gt; task.apply_async(args, kwargs, task_id='…')\n</code></pre>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_18","level":3,"title":"我可以在任务中使用装饰器吗？","text":"<p>回答：是的。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#id_1","level":3,"title":"我可以使用自然的任务 id 吗？","text":"<p>回答：是的，但要确保它是唯一的，因为两个具有相同 id 的任务的行为是未定义的。</p> <p>世界可能不会爆炸，但它们绝对可以覆盖彼此的结果。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_19","level":3,"title":"我可以在另一个任务完成后运行一个任务吗？","text":"<p>回答：是的，你可以在任务内部安全地启动另一个任务。</p> <p>一个常见的模式是为任务添加回调：</p> <pre><code>from celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@app.task\ndef add(x, y):\n    return x + y\n\n@app.task(ignore_result=True)\ndef log_result(result):\n    logger.info(\"log_result got: %r\", result)\n</code></pre> <p>调用：</p> <pre><code>&gt;&gt;&gt; (add.s(2, 2) | log_result.s()).delay()\n</code></pre>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_20","level":3,"title":"我可以取消任务的执行吗？","text":"<p>回答：是的，使用 <code>result.revoke()</code>：</p> <pre><code>&gt;&gt;&gt; result = add.apply_async(args=[2, 2], countdown=120)\n&gt;&gt;&gt; result.revoke()\n</code></pre> <p>或者如果你只有任务 id：</p> <pre><code>&gt;&gt;&gt; from proj.celery import app\n&gt;&gt;&gt; app.control.revoke(task_id)\n</code></pre> <p>后者还支持传递任务 id 列表作为参数。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#worker_2","level":3,"title":"为什么我的远程控制命令没有被所有 worker 接收？","text":"<p>回答：为了接收广播远程控制命令，每个 worker 节点都会基于 worker 的节点名创建一个唯一的队列名称。</p> <p>如果你有多个具有相同主机名的 worker，控制命令将在它们之间以轮询方式接收。</p> <p>要解决这个问题，你可以使用 <code>celery worker -n</code> 参数为每个 worker 显式设置节点名：</p> <pre><code>celery -A proj worker -n worker1@%h\ncelery -A proj worker -n worker2@%h\n</code></pre> <p>其中 <code>%h</code> 扩展为当前主机名。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_21","level":3,"title":"我可以将某些任务仅发送到某些服务器吗？","text":"<p>回答：是的，你可以使用不同的消息路由拓扑将任务路由到一个或多个 worker，并且一个 worker 实例可以绑定到多个队列。</p> <p>更多信息请参阅 路由指南。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_22","level":3,"title":"我可以禁用任务的预取吗？","text":"<p>回答：也许可以！AMQP 术语 \"prefetch\" 令人困惑，因为它仅用于描述任务预取限制。实际上并没有涉及真正的预取。</p> <p>禁用预取限制是可能的，但这意味着 worker 将尽可能快地消耗尽可能多的任务。</p> <p>你可以使用 <code>celery worker --disable-prefetch</code> 标志（或将 <code>worker_disable_prefetch</code> 设置为 <code>True</code>），以便 worker 仅在其某个进程空闲时才获取任务。此功能目前仅在使用 Redis 作为代理时受支持。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_23","level":3,"title":"我可以在运行时更改周期性任务的间隔吗？","text":"<p>回答：是的，你可以使用 Django 数据库调度器，或者你可以创建一个新的调度子类并重写 <code>celery.schedules.schedule.is_due</code>：</p> <pre><code>from celery.schedules import schedule\n\nclass my_schedule(schedule):\n\n    def is_due(self, last_run_at):\n        return run_now, next_time_to_check\n</code></pre>","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery_5","level":3,"title":"Celery 支持任务优先级吗？","text":"<p>回答：是的，RabbitMQ 自版本 3.5.0 起支持优先级，而 Redis 传输模拟了优先级支持。</p> <p>你也可以通过将高优先级任务路由到不同的 worker 来优先处理工作。在现实世界中，这通常比每条消息的优先级效果更好。你可以将此与速率限制和每条消息优先级结合使用，以实现响应式系统。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#retry-acks_lateacks_late-vs-retry","level":3,"title":"我应该使用 retry 还是 acks_late？{#acks_late-vs-retry}","text":"<p>回答：取决于情况。不一定是二选一，你可能想要同时使用两者。</p> <p><code>Task.retry</code> 用于重试任务，特别是对于可通过 <code>try</code> 块捕获的预期错误。AMQP 事务不用于这些错误：如果任务引发异常，它仍然会被确认！</p> <p>当 worker（由于某种原因）在执行过程中崩溃时，如果需要再次执行任务，将使用 <code>acks_late</code> 设置。重要的是要注意，worker 不会已知崩溃，如果确实崩溃，通常是一个需要人工干预的不可恢复错误（worker 或任务代码中的错误）。</p> <p>在理想世界中，你可以安全地重试任何失败的任务，但这种情况很少见。想象以下任务：</p> <pre><code>@app.task\ndef process_upload(filename, tmpfile):\n    # 增加存储在数据库中的文件计数\n    increment_file_counter()\n    add_file_metadata_to_db(filename, tmpfile)\n    copy_file_to_destination(filename, tmpfile)\n</code></pre> <p>如果这在将文件复制到目的地的过程中崩溃，世界将包含不完整的状态。当然，这不是一个关键场景，但你可能会想象更糟糕的情况。因此，为了编程的简便性，我们降低了可靠性；这是一个好的默认设置，需要此功能并知道自己在做什么的用户仍然可以启用 acks_late（并且将来希望使用手动确认）。</p> <p>此外，<code>Task.retry</code> 具有 AMQP 事务不可用的功能：重试之间的延迟、最大重试次数等。</p> <p>因此，对于 Python 错误使用 retry，如果你的任务是幂等的，并且需要这种可靠性级别，则结合使用 <code>acks_late</code>。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#_24","level":3,"title":"我可以安排任务在特定时间执行吗？","text":"<p>回答：是的。你可以使用 <code>Task.apply_async</code> 的 <code>eta</code> 参数。请注意，不建议使用遥远的 <code>eta</code> 时间。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#worker_3","level":3,"title":"我可以安全地关闭 worker 吗？","text":"<p>回答：是的，使用 <code>TERM</code> 信号。</p> <p>这将告诉 worker 完成所有当前正在执行的作业并尽快关闭。只要关闭完成，即使是实验性传输也不应丢失任何任务。</p> <p>你永远不应该使用 <code>KILL</code> 信号（<code>kill -9</code>）停止 <code>celery.bin.worker</code>，除非你已经尝试了几次 <code>TERM</code> 并等待了几分钟让它有机会关闭。</p> <p>还要确保只杀死主 worker 进程，而不是它的任何子进程。如果你知道进程当前正在执行 worker 关闭所依赖的任务，你可以将 kill 信号定向到特定的子进程，但这意味着将为任务设置 <code>WorkerLostError</code> 状态，因此任务不会再次运行。</p> <p>如果你安装了 <code>setproctitle</code> 模块，识别进程类型会更容易：</p> <pre><code>pip install setproctitle\n</code></pre> <p>安装此库后，你将能够在 <code>ps</code> 列表中看到进程类型，但必须重新启动 worker 才能生效。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#platform-worker","level":3,"title":"我可以在 [platform] 的后台运行 worker 吗？","text":"<p>回答：是的。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#django","level":2,"title":"Django","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#django-celery-beat","level":3,"title":"<code>django-celery-beat</code> 创建的数据库表有什么用途？","text":"<p>当使用基于数据库的调度时，周期性任务的调度信息取自 <code>PeriodicTask</code> 模型，还有几个其他辅助表（<code>IntervalSchedule</code>、<code>CrontabSchedule</code>、<code>PeriodicTasks</code>）。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#django-celery-results","level":3,"title":"<code>django-celery-results</code> 创建的数据库表有什么用途？","text":"<p>Django 数据库结果后端扩展需要 两个额外的模型：<code>TaskResult</code> 和 <code>GroupResult</code>。</p>","path":["常见问题解答"],"tags":[]},{"location":"faq/#windows","level":2,"title":"Windows","text":"","path":["常见问题解答"],"tags":[]},{"location":"faq/#celery-windows","level":3,"title":"Celery 是否支持 Windows？","text":"<p>回答：不支持。</p> <p>自 Celery 4.x 起，由于资源不足，不再支持 Windows。</p> <p>但它可能仍然有效，我们很乐意接受补丁。</p>","path":["常见问题解答"],"tags":[]},{"location":"getting-started/first-steps-with-celery/","level":1,"title":"快速上手","text":"<p>Celery 是一个功能齐全的任务队列。它易于使用，让无需了解其解决的全部复杂性即可开始使用。它围绕最佳实践设计，使的产品能够扩展并与其他语言集成，并且配备了在生产环境中运行此类系统所需的工具和支持。</p>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#1-broker","level":2,"title":"1. 选择代理（Broker）","text":"<p>Celery 需要一个发送和接收消息的解决方案；通常这以称为 消息代理（message broker） 的独立服务形式出现。</p> <p>以 Redis 为例。使用 Docker 快速运行：</p> <pre><code>docker run -d -p 6379:6379 redis\n</code></pre>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#2-celery","level":2,"title":"2. 安装 Celery","text":"uvpip <pre><code>uv add celery\n</code></pre> <pre><code>pip install celery\n</code></pre>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#3-celery-app","level":2,"title":"3. 创建 Celery 应用程序（app）","text":"<p>首先需要一个 Celery 实例。称之为 Celery 应用程序 或简称为 app。由于此实例用作在 Celery 中想要执行的所有操作的入口点，例如创建任务（task）和管理工作进程（worker），因此其他模块必须能够导入它。</p> <p>在本教程中，我们将所有内容包含在单个模块中，但对于较大的项目，需要创建一个 项目。</p> <p>创建文件 <code>tasks.py</code>：</p> tasks.py<pre><code>from celery import Celery\n\napp = Celery('tasks', broker='redis://localhost:6379/0')\n\n@app.task\ndef add(x, y):\n    return x + y\n</code></pre> <p>第3行：<code>Celery</code> 实例的第一个参数是当前模块名称。这仅在任务在 <code>__main__</code> 模块中定义时需要，以便可以自动生成名称。第二个参数是代理（broker）关键字参数，指定使用的消息代理（message broker）的 URL。这里使用 Redis。</p> <p>第6行：定义了一个名为 <code>add</code> 的单个任务（task）函数，它接受两个参数 <code>x</code> 和 <code>y</code>，并返回它们的和。</p>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#4-celery-worker","level":2,"title":"4. 运行 Celery Worker 服务","text":"<p>现在可以通过使用 <code>worker</code> 参数执行程序来运行 worker 进程：</p> <pre><code>celery -A tasks worker --loglevel=INFO\n</code></pre> <p>要获取可用命令行选项的完整列表，请执行：</p> <pre><code>celery worker --help\n</code></pre>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#5","level":2,"title":"5. 调用任务","text":"<p>要调用任务（task），可以使用 <code>delay</code> 方法。它是 <code>apply_async()</code> 方法的一个便捷快捷方式，后者对任务执行提供更大的控制（请参阅：调用任务）</p> <pre><code>&gt;&gt;&gt; from tasks import add\n&gt;&gt;&gt; add.delay(4, 4)\n</code></pre> <p>该任务（task）现在已被之前启动的工作（worker）进程处理。可以通过查看工作（worker）进程的控制台输出来验证这一点。</p> <p>调用任务（task）后，会返回一个 <code>AsyncResult</code> 实例。这可用于检查任务的状态、等待任务完成，或获取其返回值（或者如果任务失败，获取异常和回溯信息）。</p> <p>默认情况下未启用结果。为了进行远程过程调用或在数据库中跟踪任务结果，需要配置 Celery 使用结果后端。这将在下一节中描述。</p>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#6","level":2,"title":"6. 保存结果","text":"<p>如果想跟踪任务的状态，Celery 需要将状态存储或发送到某个地方。有几个内置的结果后端可供选择：SQLAlchemy/Django ORM、MongoDB，或者可以定义自己的后端。</p> <p>对于此示例，我们使用 <code>rpc</code> 结果后端，它将状态作为瞬态消息发送回来。后端通过 <code>Celery</code> 的 <code>backend</code> 参数指定（或者如果选择使用配置模块，则通过 <code>result_backend</code> 设置指定）。因此，可以修改 <code>tasks.py</code> 文件中的这一行来启用 <code>rpc://</code> 后端：</p> <pre><code>app = Celery('tasks', backend='rpc://', broker='pyamqp://')\n</code></pre> <p>或者，如果想使用 Redis 作为结果后端（result backend），但仍使用 RabbitMQ 作为消息代理（message broker）（一种流行的组合）：</p> <pre><code>app = Celery('tasks', backend='redis://localhost', broker='pyamqp://')\n</code></pre> <p>要了解有关结果后端（result backend）的更多信息，请参阅：结果后端。</p> <p>现在配置了结果后端（result backend），重新启动工作（worker）进程，关闭当前的 Python 会话并重新导入 <code>tasks</code> 模块以使更改生效。这次将保留调用任务时返回的 <code>AsyncResult</code> 实例：</p> <pre><code>&gt;&gt;&gt; from tasks import add    # 关闭并重新打开以获取更新的 'app'\n&gt;&gt;&gt; result = add.delay(4, 4)\n</code></pre> <p><code>ready()</code> 方法返回任务是否已完成处理：</p> <pre><code>&gt;&gt;&gt; result.ready()\nFalse\n</code></pre> <p>可以等待结果完成，但这很少使用，因为它将异步调用转换为同步调用：</p> <pre><code>&gt;&gt;&gt; result.get(timeout=1)\n8\n</code></pre> <p>如果任务引发异常，<code>get()</code> 方法将重新引发异常，但可以通过指定 <code>propagate</code> 参数来覆盖此行为：</p> <pre><code>&gt;&gt;&gt; result.get(propagate=False)\n</code></pre> <p>如果任务引发异常，还可以访问原始回溯：</p> <pre><code>&gt;&gt;&gt; result.traceback\n</code></pre> <p>Warning</p> <p>后端使用资源来存储和传输结果。为确保资源被释放，最终必须对调用任务后返回的每个 <code>AsyncResult</code> 实例调用 <code>get()</code> 或 <code>forget()</code> 方法。</p> <p>有关完整的结果对象参考，请参阅 <code>celery.result</code>。</p>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#celerytut-configuration","level":2,"title":"7. 配置","text":"<p>Celery 就像一个家用电器，不需要太多配置即可运行。它有一个输入和一个输出。输入必须连接到代理（broker），输出可以选择性地连接到结果后端（result backend）。但是，如果仔细查看背面，会发现一个盖子，里面有很多滑块、刻度盘和按钮：这就是配置。</p> <p>默认配置应该足以满足大多数用例，但有许多选项可以配置，以使 Celery 完全按照需要工作。阅读可用选项是熟悉可配置内容的好方法。可以在 配置 参考中阅读有关选项的信息。</p> <p>配置可以直接在应用程序上设置，也可以通过专用配置模块设置。 例如，可以通过更改 <code>task_serializer</code> 设置来配置用于序列化任务负载的默认序列化器：</p> <pre><code>app.conf.task_serializer = 'json'\n</code></pre> <p>如果要一次配置多个设置，可以使用 <code>update()</code> 方法：</p> <pre><code>app.conf.update(\n    task_serializer='json',\n    accept_content=['json'],  # 忽略其他内容\n    result_serializer='json',\n    timezone='Europe/Oslo',\n    enable_utc=True,\n)\n</code></pre> <p>对于较大的项目，建议使用专用配置模块。不鼓励硬编码周期性任务间隔和任务路由选项。最好将这些内容保存在集中位置。这对于库尤其重要，因为它使用户能够控制其任务的行为。集中配置还将允许的系统管理员在系统出现问题时进行简单更改。</p> <p>可以通过调用 <code>config_from_object()</code> 方法告诉的 Celery 实例使用配置模块：</p> <pre><code>app.config_from_object('celeryconfig')\n</code></pre> <p>此模块通常称为 <code>celeryconfig</code>，但可以使用任何模块名称。</p> <p>在上述情况下，必须可以从当前目录或 Python 路径加载名为 <code>celeryconfig.py</code> 的模块。它可能看起来像这样：</p> celeryconfig.py<pre><code>broker_url = 'pyamqp://'\nresult_backend = 'rpc://'\n\ntask_serializer = 'json'\nresult_serializer = 'json'\naccept_content = ['json']\ntimezone = 'Europe/Oslo'\nenable_utc = True\n</code></pre> <p>要验证的配置文件是否正常工作且不包含任何语法错误，可以尝试导入它：</p> <pre><code>python -m celeryconfig\n</code></pre> <p>有关配置选项的完整参考，请参阅：配置。</p> <p>为了演示配置文件的强大功能，以下是如何将有问题的任务路由到专用队列的方法：</p> celeryconfig.py<pre><code>task_routes = {\n    'tasks.add': 'low-priority',\n}\n</code></pre> <p>或者，可以通过速率限制任务而不是路由它，以便每分钟只能处理 10 个此类任务（10/m）：</p> celeryconfig.py<pre><code>task_annotations = {\n    'tasks.add': {'rate_limit': '10/m'},\n}\n</code></pre> <p>如果使用 RabbitMQ 或 Redis 作为代理，那么还可以指示工作进程在运行时为任务设置新的速率限制：</p> <pre><code>celery -A tasks control rate_limit tasks.add 10/m\nworker@example.com: OK\n    new rate limit set successfully\n</code></pre> <p>有关任务路由的更多信息，请参阅：路由任务，有关注释的更多信息，请参阅 <code>task_annotations</code> 设置，或者有关远程控制命令以及如何监控工作进程的更多信息，请参阅：监控。</p>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#8","level":2,"title":"8. 下一步","text":"<p>如果想了解更多信息，应该继续学习：下一步 教程，之后可以阅读：用户指南。</p>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#9","level":2,"title":"9. 故障排除","text":"<p>QA 中也有故障排除部分。</p>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#_2","level":3,"title":"工作进程无法启动：权限错误","text":"<ul> <li> <p>如果使用 Debian、Ubuntu 或其他基于 Debian 的发行版：</p> <p>Debian 最近将 <code>/dev/shm</code> 特殊文件重命名为 <code>/run/shm</code>。</p> <p>一个简单的解决方法是创建一个符号链接：</p> <pre><code>ln -s /run/shm /dev/shm\n</code></pre> </li> <li> <p>其他系统：</p> <p>如果提供 <code>celery worker --pidfile</code>、<code>celery worker --logfile</code> 或 <code>celery worker --statedb</code> 参数中的任何一个，则必须确保它们指向启动工作进程的用户可写和可读的文件或目录。</p> </li> </ul>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/first-steps-with-celery/#pending","level":3,"title":"结果后端不工作或任务始终处于 <code>PENDING</code> 状态","text":"<p>默认情况下，所有任务都是 <code>PENDING</code>，因此该状态最好命名为 \"unknown\"。Celery 在发送任务时不会更新状态，任何没有历史记录的任务都被假定为挂起（毕竟知道任务 ID）。</p> <ol> <li> <p>确保任务没有启用 <code>ignore_result</code>。</p> <p>启用此选项将强制工作进程跳过更新状态。</p> </li> <li> <p>确保 <code>task_ignore_result</code> 设置未启用。</p> </li> <li> <p>确保没有任何旧的工作进程仍在运行。</p> <p>很容易意外启动多个工作进程，因此请确保在启动新工作进程之前正确关闭了先前的工作进程。</p> <p>一个未配置预期结果后端的旧工作进程可能正在运行并劫持任务。</p> <p>可以将 <code>celery worker --pidfile</code> 参数设置为绝对路径以确保不会发生这种情况。</p> </li> <li> <p>确保客户端配置了正确的后端。</p> <p>如果由于某种原因，客户端配置的后端与工作进程不同，将无法接收结果。 确保后端配置正确：</p> <pre><code>&gt;&gt;&gt; result = task.delay()\n&gt;&gt;&gt; print(result.backend)\n</code></pre> </li> </ol>","path":["快速入门","快速上手"],"tags":[]},{"location":"getting-started/introduction/","level":1,"title":"介绍","text":"","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_2","level":2,"title":"什么是任务队列？","text":"<p>任务队列是一种在多个线程或机器之间分配工作的机制。</p> <p>任务队列的输入称为任务的工作单元。专用的工作进程持续监控任务队列以执行新的工作。</p> <p>Celery 通过消息进行通信，通常使用代理在客户端和工作进程之间进行中介。要启动任务，客户端会向队列添加消息，然后代理将该消息传递给工作进程。</p> <p>一个 Celery 系统可以包含多个工作进程和代理，从而实现高可用性和水平扩展。</p> <p>Celery 是用 Python 编写的，但该协议可以用任何语言实现。除了 Python 之外，还有 Node.js 的 node-celery、PHP客户端、gocelery、gopher-celery和rusty-celery。</p> <p>语言互操作性也可以通过暴露HTTP端点并让任务请求它（webhooks）来实现。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_3","level":2,"title":"我需要什么？","text":"版本要求 <p>Celery 5.5.x 版本运行在：</p> <ul> <li>Python ❨3.8, 3.9, 3.10, 3.11, 3.12, 3.13❩</li> <li>PyPy3.9+ ❨v7.3.12+❩</li> </ul> <p>如果您运行的是较旧版本的Python，则需要运行较旧版本的Celery：</p> <ul> <li>Python 3.7: Celery 5.2 或更早版本</li> <li>Python 3.6: Celery 5.1 或更早版本</li> <li>Python 2.7: Celery 4.x 系列</li> <li>Python 2.6: Celery 3.1 系列或更早版本</li> <li>Python 2.5: Celery 3.0 系列或更早版本</li> <li>Python 2.4: Celery 2.2 系列或更早版本</li> </ul> <p>Celery是一个资金有限的项目， 因此我们不支持Microsoft Windows。 请不要打开与该平台相关的任何问题。</p> <p>Celery 需要一个消息传输器来发送和接收消息。RabbitMQ和Redis代理传输器功能完整，但也支持许多其他实验性解决方案，包括使用SQLite进行本地开发。</p> <p>Celery 可以在单台机器、多台机器甚至跨数据中心运行。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_4","level":2,"title":"开始使用","text":"<p>如果您是第一次尝试使用Celery，或者您没有跟上3.1版本的开发并且来自之前的版本，那么您应该阅读我们的入门教程：</p> <ul> <li>快速上手</li> <li>后续步骤</li> </ul>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#celery","level":2,"title":"Celery是...","text":"","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_5","level":3,"title":"简单","text":"<p>Celery易于使用和维护，并且不需要配置文件。</p> <p>以下是您可以制作的最简单的应用程序之一：</p> <pre><code>from celery import Celery\n\napp = Celery('hello', broker='amqp://guest@localhost//')\n\n@app.task\ndef hello():\n    return 'hello world'\n</code></pre>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_6","level":3,"title":"高可用性","text":"<p>工作进程和客户端在连接丢失或失败时会自动重试，并且一些代理支持主/主或主/副本复制方式的高可用性。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_7","level":3,"title":"快速","text":"<p>单个Celery进程每分钟可以处理数百万个任务，具有亚毫秒级的往返延迟（使用RabbitMQ、librabbitmq和优化设置）。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_8","level":3,"title":"灵活","text":"<p>Celery的几乎每个部分都可以扩展或单独使用，自定义池实现、序列化器、压缩方案、日志记录、调度器、消费者、生产者、代理传输器等等。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_9","level":2,"title":"它支持","text":"","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_10","level":3,"title":"代理","text":"<ul> <li>Redis</li> <li>RabbitMQ</li> <li>Amazon SQS</li> </ul>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_11","level":3,"title":"并发","text":"<ul> <li>prefork（多进程）</li> <li>Eventlet, gevent</li> <li>thread（多线程）</li> <li><code>solo</code>（单线程）</li> </ul>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_12","level":3,"title":"结果存储","text":"<ul> <li>AMQP, Redis</li> <li>Memcached</li> <li>SQLAlchemy, Django ORM</li> <li>Apache Cassandra, Elasticsearch, Riak</li> <li>MongoDB, CouchDB, Couchbase, ArangoDB</li> <li>Amazon DynamoDB, Amazon S3</li> <li>Microsoft Azure Block Blob, Microsoft Azure Cosmos DB</li> <li>Google Cloud Storage</li> <li>文件系统</li> </ul>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_13","level":3,"title":"序列化","text":"<ul> <li>pickle, json, yaml, msgpack</li> <li>zlib, bzip2 压缩</li> <li>加密消息签名</li> </ul>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_14","level":2,"title":"特性","text":"","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_15","level":3,"title":"监控","text":"<p>工作进程会发出监控事件流， 内置和外部工具使用这些事件来实时告诉您 集群正在做什么。了解更多。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_16","level":3,"title":"工作流","text":"<p>简单和复杂的工作流可以使用我们称为\"canvas\"的 一组强大原语来组合， 包括分组、链式、分块等。了解更多。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_17","level":3,"title":"时间和速率限制","text":"<p>您可以控制每秒/分钟/小时可以执行多少个任务，或者任务可以运行多长时间，这可以设置为默认值、针对特定工作进程或针对每个任务类型单独设置。了解更多。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_18","level":3,"title":"调度","text":"<p>您可以以秒为单位或使用 <code>datetime</code>指定任务运行时间，或者您可以使用基于简单间隔的周期性任务来处理重复事件，或者使用支持分钟、小时、星期几、月份日期和年份月份的Crontab表达式。了解更多。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_19","level":3,"title":"资源泄漏保护","text":"<p><code>--max-tasks-per-child</code>选项用于处理用户任务泄漏资源的情况，比如内存或文件描述符，这些完全超出您的控制范围。了解更多。</p>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/introduction/#_20","level":3,"title":"用户组件","text":"<p>每个工作进程组件都可以自定义，并且用户可以定义其他组件。工作进程使用\"bootsteps\"构建——一个依赖关系图，可以精细控制工作进程的内部结构。</p> <ul> <li>Eventlet</li> <li>gevent</li> </ul>","path":["快速入门","介绍"],"tags":[]},{"location":"getting-started/next-steps/","level":1,"title":"后续步骤","text":"<p>快速上手 指南故意保持简洁。在本指南中，我将更详细地演示 Celery 提供的功能，包括如何为您的应用程序和库添加 Celery 支持。</p> <p>本文档并未记录 Celery 的所有功能和最佳实践，因此建议您也阅读：用户指南。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#celery","level":2,"title":"在项目里使用 Celery","text":"","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#project-layout","level":3,"title":"项目","text":"目录结构<pre><code>src\n└── proj\n    ├── __init__.py\n    ├── celery.py\n    └── tasks.py\n</code></pre> proj/celery.py<pre><code>from celery import Celery\n\napp = Celery(\n    'proj',\n    broker='redis://localhost:6379/0',\n    backend='redis://localhost:6379/0',\n    include=['proj.tasks']\n)\n\napp.conf.update(\n    result_expires=3600,\n)\n\n\nif __name__ == '__main__':\n    app.start()\n</code></pre> <p>在此模块中，您创建了我们的 <code>Celery</code> 实例（也称为 app）。要在项目中使用 Celery，您只需导入此实例。</p> <ul> <li><code>broker</code> 参数指定要使用的代理 URL。</li> <li><code>backend</code> 参数指定要使用的结果后端。它用于跟踪任务状态和结果。您可能希望为应用程序使用不同的后端。它们都有不同的优缺点。如果不需要结果，最好禁用它们。也可以通过设置 <code>@task(ignore_result=True)</code> 选项为单个任务禁用结果。</li> <li><code>include</code> 参数是工作进程启动时要导入的模块列表。您需要在此处添加我们的任务模块，以便工作进程能够找到我们的任务。</li> </ul> proj/tasks.py<pre><code>from .celery import app\n\n\n@app.task\ndef add(x, y):\n    return x + y\n\n\n@app.task\ndef mul(x, y):\n    return x * y\n\n\n@app.task\ndef xsum(numbers):\n    return sum(numbers)\n</code></pre>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#worker","level":3,"title":"启动 Worker 进程","text":"<p>可以使用 <code>celery</code> 程序启动工作进程（根据示例项目布局，您需要在 <code>proj</code> 目录的上一级目录中运行工作进程，该目录是 <code>src</code>）：</p> <pre><code>$ celery -A proj worker -l INFO\ncelery@MBP.local v5.6.0 (recovery)\n\nmacOS-15.7.3-arm64-arm-64bit-Mach-O 2025-12-28 11:43:42\n\n[config]\n.&gt; app:         proj:0x1081096a0\n.&gt; transport:   redis://localhost:6379/0\n.&gt; results:     redis://localhost:6379/0\n.&gt; concurrency: 10 (prefork)\n.&gt; task events: OFF (enable -E to monitor tasks in this worker)\n\n[queues]\n.&gt; celery           exchange=celery(direct) key=celery\n\n\n[tasks]\n  . proj.tasks.add\n  . proj.tasks.mul\n  . proj.tasks.xsum\n\n[2025-12-28 11:43:42,407: INFO/MainProcess] Connected to redis://localhost:6379/0\n[2025-12-28 11:43:42,410: INFO/MainProcess] mingle: searching for neighbors\n[2025-12-28 11:43:43,429: INFO/MainProcess] mingle: all alone\n[2025-12-28 11:43:43,463: INFO/MainProcess] celery@MBP.local ready.\n</code></pre> <p>可以通过传递 <code>--help</code> 标志来获取命令行参数的完整列表：</p> <pre><code>$ celery worker --help\nUsage: celery worker [OPTIONS]\n\n  Start worker instance.\n\n  Examples\n  --------\n\n  $ celery --app=proj worker -l INFO\n  $ celery -A proj worker -l INFO -Q hipri,lopri\n  $ celery -A proj worker --concurrency=4\n  $ celery -A proj worker --concurrency=1000 -P eventlet\n  $ celery worker --autoscale=10,0\n\nWorker Options:\n  -n, --hostname HOSTNAME         Set custom hostname (e.g., 'w1@%%h').\n                                  Expands: %%h (hostname), %%n (name) and %%d,\n                                  (domain).\n  -D, --detach                    Start worker as a background process.\n  -S, --statedb PATH              Path to the state database. The extension\n                                  '.db' may be appended to the filename.\n  -l, --loglevel [DEBUG|INFO|WARNING|ERROR|CRITICAL|FATAL]\n                                  Logging level.\n  -O, --optimization [default|fair]\n                                  Apply optimization profile.\n  --prefetch-multiplier &lt;prefetch multiplier&gt;\n                                  Set custom prefetch multiplier value for\n                                  this worker instance.\n  --disable-prefetch              Disable broker prefetching. The worker will\n                                  only fetch a task when a process slot is\n                                  available. Only supported with Redis\n                                  brokers.\n\nPool Options:\n  -c, --concurrency &lt;concurrency&gt;\n                                  Number of child processes processing the\n                                  queue.  The default is the number of CPUs\n                                  available on your system.\n  -P, --pool [prefork|eventlet|gevent|solo|processes|threads|custom]\n                                  Pool implementation.\n  -E, --task-events, --events     Send task-related events that can be\n                                  captured by monitors like celery events,\n                                  celerymon, and others.\n  --time-limit FLOAT              Enables a hard time limit (in seconds\n                                  int/float) for tasks.\n  --soft-time-limit FLOAT         Enables a soft time limit (in seconds\n                                  int/float) for tasks.\n  --max-tasks-per-child INTEGER   Maximum number of tasks a pool worker can\n                                  execute before it's terminated and replaced\n                                  by a new worker.\n  --max-memory-per-child INTEGER  Maximum amount of resident memory, in KiB,\n                                  that may be consumed by a child process\n                                  before it will be replaced by a new one.  If\n                                  a single task causes a child process to\n                                  exceed this limit, the task will be\n                                  completed and the child process will be\n                                  replaced afterwards. Default: no limit.\n\nQueue Options:\n  --purge, --discard\n  -Q, --queues COMMA SEPARATED LIST\n  -X, --exclude-queues COMMA SEPARATED LIST\n  -I, --include COMMA SEPARATED LIST\n\nFeatures:\n  --without-gossip\n  --without-mingle\n  --without-heartbeat\n  --heartbeat-interval INTEGER\n  --autoscale &lt;MIN WORKERS&gt;, &lt;MAX WORKERS&gt;\n\nEmbedded Beat Options:\n  -B, --beat\n  -s, --schedule-filename, --schedule TEXT\n  --scheduler TEXT\n\nDaemonization Options:\n  -f, --logfile TEXT  Log destination; defaults to stderr\n  --pidfile TEXT      PID file path; defaults to no PID file\n  --uid TEXT          Drops privileges to this user ID\n  --gid TEXT          Drops privileges to this group ID\n  --umask TEXT        Create files and directories with this umask\n  --executable TEXT   Override path to the Python executable\n\nOptions:\n  --help  Show this message and exit.\n</code></pre> <p>这些选项在：工作进程 中有更详细的描述。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#worker_1","level":3,"title":"停止 Worker 进程","text":"<p>要停止工作进程，只需按 Ctrl+C。工作进程支持的信号列表在：工作进程 中有详细说明。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#_2","level":3,"title":"在后台运行","text":"<p>在生产环境中，在 后台运行 Worker 进程，这在：守护进程化 中有详细描述。</p> <p>守护进程化脚本使用 <code>celery multi</code> 命令在后台启动一个或多个工作进程：</p> <pre><code>$ celery multi start w1 -A proj -l INFO\ncelery multi v5.6.0 (recovery)\n&gt; Starting nodes...\n    &gt; w1@MBP.local: OK\n</code></pre> <p>也可以 重新启动：</p> <pre><code>$ celery multi restart w1 -A proj -l INFO\ncelery multi v5.6.0 (recovery)\n&gt; Stopping nodes...\n    &gt; w1@MBP.local: TERM -&gt; 87734\n&gt; Waiting for 1 node -&gt; 87734.....\n    &gt; w1@MBP.local: OK\n&gt; Restarting node w1@MBP.local: OK\n&gt; Waiting for 1 node -&gt; None...\n</code></pre> <p>或者 停止：</p> <pre><code>$ celery multi stop w1 -A proj -l INFO\ncelery multi v5.6.0 (recovery)\n&gt; Stopping nodes...\n    &gt; w1@MBP.local: TERM -&gt; 87879\n</code></pre> <p><code>stop</code> 命令是异步的，因此它不会等待工作进程关闭。您可能希望使用 <code>stopwait</code> 命令代替，它确保所有当前正在执行的任务在退出前都已完成：</p> <pre><code>$ celery multi stopwait w1 -A proj -l INFO\ncelery multi v5.6.0 (recovery)\n&gt; Stopping nodes...\n    &gt; w1@MBP.local: TERM -&gt; 88126\n&gt; Waiting for 1 node -&gt; 88126.....\n    &gt; w1@MBP.local: OK\n&gt; w1@MBP.local: DOWN\n&gt; Waiting for 1 node -&gt; None...\n</code></pre> <p><code>celery multi</code> 不存储有关工作进程的信息，因此在重新启动时需要使用相同的命令行参数。只有相同的 pidfile 和 logfile 参数在停止时必须使用。</p> <p>默认情况下，它会在当前目录中创建 pid 和日志文件。为防止多个工作进程相互覆盖启动，建议将这些文件放在专用目录中：</p> <pre><code>mkdir -p /var/run/celery\nmkdir -p /var/log/celery\ncelery multi start w1 -A proj -l INFO --pidfile=/var/run/celery/%n.pid --logfile=/var/log/celery/%n%I.log\n</code></pre> <p>使用 multi 命令，可以启动多个工作进程，并且有一个强大的命令行语法来为不同的工作进程指定参数，例如：</p> <pre><code>celery multi start 10 -A proj -l INFO -Q:1-3 images,video -Q:4,5 data -Q default -L:4,5 debug\n</code></pre> <p>更多示例请参阅 API 参考中的 <code>celery.bin.multi</code> 模块。</p> <p>关于 <code>--app</code> 参数</p> <p><code>--app</code> 参数指定要使用的 Celery 应用实例，格式为 <code>module.path:attribute</code></p> <p>但它也支持快捷形式。如果只指定了包名，它会尝试按以下顺序搜索应用实例：</p> <p>使用 <code>--app=proj</code>：</p> <ol> <li>名为 <code>proj.app</code> 的属性，或</li> <li>名为 <code>proj.celery</code> 的属性，或</li> <li> <p>模块 <code>proj</code> 中值为 Celery 应用程序的任何属性，或 如果以上都未找到，它会尝试名为 <code>proj.celery</code> 的子模块：</p> </li> <li> <p>名为 <code>proj.celery.app</code> 的属性，或</p> </li> <li>名为 <code>proj.celery.celery</code> 的属性，或</li> <li>模块 <code>proj.celery</code> 中值为 Celery 应用程序的任何属性。</li> </ol> <p>此方案模仿了文档中使用的实践 -- 即，对于单个包含模块使用 <code>proj:app</code>，对于较大的项目使用 <code>proj.celery:app</code>。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#_3","level":2,"title":"调用任务","text":"<p>您可以使用 <code>delay()</code> 方法调用任务：</p> <pre><code>&gt;&gt;&gt; from proj.tasks import add\n&gt;&gt;&gt; add.delay(2, 2)\n&lt;AsyncResult: 9c939bba-5cb7-4853-bf0c-9b2483164172&gt;\n</code></pre> <p>此方法实际上是另一个名为 <code>apply_async()</code> 的方法的星号参数快捷方式：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 2))\n&lt;AsyncResult: 9c939bba-5cb7-4853-bf0c-9b2483164172&gt;\n</code></pre> <p>后者使您能够指定执行选项，如运行时间（倒计时）、应发送到的队列等：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 2), queue='lopri', countdown=10)\n</code></pre> <p>在上面的示例中，任务将被发送到名为 <code>lopri</code> 的队列（queue），并且任务最早将在消息发送后 10 秒执行。</p> <p>直接应用任务将在当前进程中执行任务，因此不会发送消息：</p> <pre><code>&gt;&gt;&gt; add(2, 2)\n4\n</code></pre> <p>这三种方法 - <code>delay()</code>、<code>apply_async()</code> 和应用（<code>__call__()</code>），构成了 Celery 调用 API，也用于签名。</p> <p>调用 API 的更详细概述可以在：调用指南 中找到。</p> <p>每个任务调用都会被赋予一个唯一标识符（UUID）-- 这就是任务 ID。</p> <p><code>delay()</code> 和 <code>apply_async()</code> 方法返回一个 <code>AsyncResult</code> 实例，可用于跟踪任务的执行状态。但为此，您需要启用 结果后端，以便状态可以存储在某个地方。</p> <p>默认情况下结果被禁用，因为没有适合每个应用程序的结果后端；要选择一个，您需要考虑每个单独后端的缺点。对于许多任务，保留返回值甚至不是很有用，因此这是一个明智的默认设置。另请注意，结果后端不用于监控任务和工作进程：为此，Celery 使用专用的事件消息（请参阅 监控指南）。</p> <p>如果您配置了结果后端，可以检索任务的返回值：</p> <pre><code>&gt;&gt;&gt; res = add.delay(2, 2)\n&gt;&gt;&gt; res.get(timeout=1)\n4\n</code></pre> <p>您可以通过查看 <code>id</code> 属性找到任务的 ID：</p> <pre><code>&gt;&gt;&gt; res.id\nd6b3aea2-fb9b-4ebc-8da4-848818db9114\n</code></pre> <p>如果任务引发异常，您还可以检查异常和回溯，实际上 <code>result.get()</code> 默认会传播任何错误：</p> <pre><code>&gt;&gt;&gt; res = add.delay(2, '2')\n&gt;&gt;&gt; res.get(timeout=1)\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"celery/result.py\", line 221, in get\n    return self.backend.wait_for_pending(\n  File \"celery/backends/asynchronous.py\", line 195, in wait_for_pending\n    return result.maybe_throw(callback=callback, propagate=propagate)\n  File \"celery/result.py\", line 333, in maybe_throw\n    self.throw(value, self._to_remote_traceback(tb))\n  File \"celery/result.py\", line 326, in throw\n    self.on_ready.throw(*args, **kwargs)\n  File \"vine/promises.py\", line 244, in throw\n    reraise(type(exc), exc, tb)\n  File \"vine/five.py\", line 195, in reraise\n    raise value\nTypeError: unsupported operand type(s) for +: 'int' and 'str'\n</code></pre> <p>如果您不希望错误传播，可以通过传递 <code>propagate</code> 来禁用它：</p> <pre><code>&gt;&gt;&gt; res.get(propagate=False)\nTypeError(\"unsupported operand type(s) for +: 'int' and 'str'\")\n</code></pre> <p>在这种情况下，它将返回引发的异常实例 -- 因此要检查任务是成功还是失败，您必须使用结果实例上的相应方法：</p> <pre><code>&gt;&gt;&gt; res.failed()\nTrue\n\n&gt;&gt;&gt; res.successful()\nFalse\n</code></pre> <p>那么它如何知道任务（task）是否失败了呢？它可以通过查看任务的 state 来找出：</p> <pre><code>&gt;&gt;&gt; res.state\n'FAILURE'\n</code></pre> <p>任务（task）只能处于单一状态，但它可以经历多个状态。典型任务的阶段可以是：</p> <pre><code>PENDING -&gt; STARTED -&gt; SUCCESS\n</code></pre> <p>started 状态是一个特殊状态，只有在启用 <code>task_track_started</code> 设置或为任务设置 <code>@task(track_started=True)</code> 选项时才会记录。</p> <p>pending 状态实际上不是记录的状态，而是任何未知任务 ID 的默认状态：您可以从以下示例中看到这一点：</p> <pre><code>&gt;&gt;&gt; from proj.celery import app\n\n&gt;&gt;&gt; res = app.AsyncResult('this-id-does-not-exist')\n&gt;&gt;&gt; res.state\n'PENDING'\n</code></pre> <p>如果任务被重试，阶段可能会变得更加复杂。为了演示，对于一个重试两次的任务，阶段将是：</p> <pre><code>PENDING -&gt; STARTED -&gt; RETRY -&gt; STARTED -&gt; RETRY -&gt; STARTED -&gt; SUCCESS\n</code></pre> <p>要了解更多关于任务状态的信息，您应该查看任务用户指南中的 任务状态 部分。</p> <p>调用任务在：调用指南 中有详细描述。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#canvas","level":2,"title":"Canvas：设计工作流程","text":"<p>您刚刚学习了如何使用任务的 <code>delay</code> 方法调用任务，这通常就是您所需要的全部。但有时您可能希望将任务调用的签名传递给另一个进程或作为另一个函数的参数，为此 Celery 使用称为 签名（signatures） 的东西。</p> <p>签名将单个任务调用的参数和执行选项包装起来，以便可以传递给函数，甚至可以序列化并通过网络发送。</p> <p>您可以使用参数 <code>(2, 2)</code> 和 10 秒的倒计时来为 <code>add</code> 任务创建签名，如下所示：</p> <pre><code>&gt;&gt;&gt; add.signature((2, 2), countdown=10)\ntasks.add(2, 2)\n</code></pre> <p>还有一个使用星号参数的快捷方式：</p> <pre><code>&gt;&gt;&gt; add.s(2, 2)\ntasks.add(2, 2)\n</code></pre>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#api","level":3,"title":"又是那个调用 API","text":"<p>签名实例也支持调用 API，这意味着它们有 <code>delay()</code> 和 <code>apply_async()</code> 方法。</p> <p>但有一个区别，签名可能已经指定了参数签名。<code>add</code> 任务接受两个参数，因此指定两个参数的签名将构成一个完整的签名：</p> <pre><code>&gt;&gt;&gt; s1 = add.s(2, 2)\n&gt;&gt;&gt; res = s1.delay()\n&gt;&gt;&gt; res.get()\n4\n</code></pre> <p>但是，您也可以创建不完整的签名来创建我们称之为 partials 的东西：</p> <pre><code># 不完整的部分：add(?, 2)\n&gt;&gt;&gt; s2 = add.s(2)\n</code></pre> <p><code>s2</code> 现在是一个部分签名，需要另一个参数才能完成，这可以在调用签名时解决：</p> <pre><code># 解决部分：add(8, 2)\n&gt;&gt;&gt; res = s2.delay(8)\n&gt;&gt;&gt; res.get()\n10\n</code></pre> <p>在这里，您添加了参数 8，它被前置到现有参数 <code>2</code> 之前，形成了 <code>add(8, 2)</code> 的完整签名。</p> <p>关键字参数也可以稍后添加；这些参数随后会与任何现有的关键字参数合并，但新参数优先：</p> <pre><code>&gt;&gt;&gt; s3 = add.s(2, 2, debug=True)\n&gt;&gt;&gt; s3.delay(debug=False)   # debug 现在是 False。\n</code></pre> <p>如前所述，签名支持调用 API：这意味着</p> <ul> <li> <p><code>sig.apply_async(args=(), kwargs={}, **options)</code> 使用可选的局部参数和局部关键字参数调用签名。还支持局部执行选项。</p> </li> <li> <p><code>sig.delay(*args, **kwargs)</code> <code>apply_async</code> 的星号参数版本。任何参数都将前置到签名中的参数，关键字参数将与任何现有键合并。</p> </li> </ul> <p>所以这一切似乎非常有用，但您实际上可以用这些做什么呢？要了解这一点，我必须介绍 canvas 基本元素（primitives）...</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#_4","level":3,"title":"基本元素","text":"<p>这些基本元素本身就是签名对象，因此它们可以以任意方式组合来构成复杂的工作流程。</p> <p>Note</p> <p>这些示例检索结果，因此要尝试它们，您需要配置结果后端。上面的示例项目已经做到了这一点（请参阅 <code>Celery()</code> 的 backend 参数）。</p> <p>让我们看一些例子：</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#groups","level":4,"title":"Groups","text":"<p><code>group</code> 并行调用任务列表，并返回一个特殊的结果实例，让您可以检查组的结果并按顺序检索返回值。</p> <pre><code>&gt;&gt;&gt; from celery import group\n&gt;&gt;&gt; from proj.tasks import add\n\n&gt;&gt;&gt; group(add.s(i, i) for i in range(10))().get()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n</code></pre> <ul> <li>Partial group</li> </ul> <pre><code>&gt;&gt;&gt; g = group(add.s(i) for i in range(10))\n&gt;&gt;&gt; g(10).get()\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n</code></pre>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#chains","level":4,"title":"Chains","text":"<p>任务可以链接在一起，以便在一个任务返回后调用另一个任务：</p> <pre><code>&gt;&gt;&gt; from celery import chain\n&gt;&gt;&gt; from proj.tasks import add, mul\n\n# (4 + 4) * 8\n&gt;&gt;&gt; chain(add.s(4, 4) | mul.s(8))().get()\n64\n</code></pre> <ul> <li>Partial chain</li> </ul> <pre><code>&gt;&gt;&gt; # (? + 4) * 8\n&gt;&gt;&gt; g = chain(add.s(4) | mul.s(8))\n&gt;&gt;&gt; g(4).get()\n64\n</code></pre> <p>也可以这样写：</p> <pre><code>&gt;&gt;&gt; (add.s(4, 4) | mul.s(8))().get()\n64\n</code></pre>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#chords","level":4,"title":"Chords","text":"<p>Chords 是一个带有回调的 Group：</p> <pre><code>&gt;&gt;&gt; from celery import chord\n&gt;&gt;&gt; from proj.tasks import add, xsum\n\n&gt;&gt;&gt; chord((add.s(i, i) for i in range(10)), xsum.s())().get()\n90\n</code></pre> <p>Chain 到另一个任务的 Group 将自动转换为 Chord：</p> <pre><code>&gt;&gt;&gt; (group(add.s(i, i) for i in range(10)) | xsum.s())().get()\n90\n</code></pre> <p>由于这些基本元素（primitives）都是签名（signature）类型，它们几乎可以以任何方式组合，例如：</p> <pre><code>&gt;&gt;&gt; upload_document.s(file) | group(apply_filter.s() for filter in filters)\n</code></pre> <p>请务必在 画布 用户指南中阅读更多关于工作流程的内容。 ·</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#_5","level":2,"title":"路由","text":"<p>Celery 支持 AMQP 提供的所有路由功能，但也支持简单的路由，其中消息被发送到命名队列。</p> <p><code>task_routes</code> 设置使您能够按名称路由任务，并将所有内容集中在一个位置：</p> <pre><code>app.conf.update(\n    task_routes = {\n        'proj.tasks.add': {'queue': 'hipri'},\n    },\n)\n</code></pre> <p>您还可以在运行时使用 <code>apply_async()</code> 的 <code>queue</code> 参数指定队列：</p> <pre><code>&gt;&gt;&gt; from proj.tasks import add\n&gt;&gt;&gt; add.apply_async((2, 2), queue='hipri')\n</code></pre> <p>然后，您可以通过指定 <code>celery worker -Q</code> 选项使工作进程从此队列消费：</p> <pre><code>celery -A proj worker -Q hipri\n</code></pre> <p>您可以使用逗号分隔的列表指定多个队列。例如，您可以使工作进程同时从默认队列和 <code>hipri</code> 队列消费，其中默认队列由于历史原因命名为 <code>celery</code>：</p> <pre><code>celery -A proj worker -Q hipri,celery\n</code></pre> <p>队列的顺序无关紧要，因为工作进程将给予队列相等的权重。</p> <p>要了解更多关于路由的信息，包括利用 AMQP 路由的全部功能，请参阅 路由指南。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#_6","level":2,"title":"远程控制","text":"<p>如果您使用 RabbitMQ (AMQP)、Redis 或 Qpid 作为代理（broker），那么您可以在运行时控制和检查工作进程。</p> <p>例如，您可以看到工作进程当前正在处理哪些任务：</p> <pre><code>celery -A proj inspect active\n</code></pre> <p>这是通过使用广播消息实现的，因此所有远程控制命令都会被集群中的每个工作进程接收。</p> <p>您还可以使用 <code>celery inspect --destination</code> 选项指定一个或多个工作进程来处理请求。这是一个逗号分隔的工作进程主机名列表：</p> <pre><code>celery -A proj inspect active --destination=celery@example.com\n</code></pre> <p>如果未提供目标，则每个工作进程都会处理并回复请求。</p> <p><code>celery inspect</code> 命令包含不更改工作进程中任何内容的命令；它只返回有关工作进程内部情况的信息和统计信息。要查看检查命令列表，您可以执行：</p> <pre><code>celery -A proj inspect --help\n</code></pre> <p>然后是 <code>celery control</code> 命令，它包含在运行时实际更改工作进程内容的命令：</p> <pre><code>celery -A proj control --help\n</code></pre> <p>例如，您可以强制工作进程启用事件消息（用于监控任务和工作进程）：</p> <pre><code>celery -A proj control enable_events\n</code></pre> <p>启用事件后，您可以启动事件转储器来查看工作进程正在做什么：</p> <pre><code>celery -A proj events --dump\n</code></pre> <p>或者您可以启动 curses 界面：</p> <pre><code>celery -A proj events\n</code></pre> <p>完成监控后，您可以再次禁用事件：</p> <pre><code>celery -A proj control disable_events\n</code></pre> <p>:program:<code>celery status</code> 命令也使用远程控制命令，并显示集群中在线工作进程的列表：</p> <pre><code>celery -A proj status\n</code></pre> <p>您可以在 监控指南 中阅读更多关于 <code>celery</code> 命令和监控的信息。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#_7","level":2,"title":"时区","text":"<p>所有时间和日期，在内部和消息中都使用 UTC 时区。</p> <p>当工作进程收到消息时，例如设置了倒计时，它会将该 UTC 时间转换为本地时间。如果您希望使用与系统时区不同的时区，则必须使用 <code>timezone</code> 设置进行配置：</p> <pre><code>app.conf.timezone = 'Europe/London'\n</code></pre>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/next-steps/#_8","level":2,"title":"优化","text":"<p>默认配置未针对吞吐量进行优化。默认情况下，它试图在多个短任务和较少长任务之间走中间路线，这是吞吐量和公平调度之间的折衷。</p> <p>如果您有严格的公平调度要求，或者希望优化吞吐量，那么您应该阅读 优化指南。</p>","path":["快速入门","后续步骤"],"tags":[]},{"location":"getting-started/backends-and-brokers/","level":1,"title":"后端和代理","text":"<p>Celery 支持多种消息传输替代方案。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/#_2","level":2,"title":"代理概览","text":"名称 状态 监控 远程控制 RabbitMQ Stable Yes Yes Redis Stable Yes Yes Amazon SQS Stable No No Zookeeper Experimental No No Kafka Experimental No No GC PubSub Experimental Yes Yes <p>实验性代理可能功能正常，但它们没有专门的维护者。</p> <p>缺少监控支持意味着传输不实现事件，因此 Flower、<code>celery events</code>、<code>celerymon</code> 和其他基于事件的监控工具将无法工作。</p> <p>远程控制意味着能够在运行时使用 <code>celery inspect</code> 和 <code>celery control</code> 命令（以及使用远程控制 API 的其他工具）检查和管理工作器。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/#_3","level":2,"title":"摘要","text":"<p>本节并非对后端和代理的全面介绍。</p> <p>Celery 能够与许多不同的后端（结果存储）和代理（消息传输）进行通信和存储。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/#redis","level":3,"title":"Redis","text":"<p>Redis 既可以作为后端（backend）也可以作为代理（broker）。</p> <p>作为代理： Redis 适用于快速传输小消息。大消息可能会阻塞系统。</p> <p>作为后端： Redis 是一个超快的键值存储，使其在获取任务调用结果时非常高效。与 Redis 的设计一样，您需要考虑可用于存储数据的有限内存，以及如何处理数据持久性。如果结果持久性很重要，请考虑为后端使用另一个数据库。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/#rabbitmq","level":3,"title":"RabbitMQ","text":"<p>RabbitMQ 是一个代理（broker）。</p> <p>作为代理： RabbitMQ 处理大消息比 Redis 更好，但是如果消息非常快速地大量涌入，扩展性可能成为问题，除非 RabbitMQ 运行在非常大的规模上，否则应考虑使用 Redis 或 SQS。</p> <p>作为后端： RabbitMQ 可以通过 <code>rpc://</code> 后端存储结果。此后端为每个客户端创建单独的临时队列。</p> <p>注意：RabbitMQ（作为代理）和 Redis（作为后端）经常一起使用。如果结果存储需要更可靠的长时期持久性，请考虑使用 PostgreSQL 或 MySQL（通过 SQLAlchemy）、Cassandra 或自定义定义的后端。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/#sqs","level":3,"title":"SQS","text":"<p>SQS 是一个代理（broker）。</p> <p>如果您已经与 AWS 紧密集成，并且熟悉 SQS，它作为一个代理是一个很好的选择。它极其可扩展且完全托管，任务委派方式与 RabbitMQ 类似。但它缺少 RabbitMQ 代理的一些功能，例如 <code>worker remote control commands</code>。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/#sqlalchemy","level":3,"title":"SQLAlchemy","text":"<p>SQLAlchemy 是一个后端（backend）。</p> <p>它允许 Celery 与 MySQL、PostgreSQL、SQLite 等接口。它是一个 ORM，是 Celery 可以使用 SQL 数据库作为结果后端的方式。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/#gcpubsub","level":3,"title":"GCPubSub","text":"<p>Google Cloud Pub/Sub 是一个代理（broker）。</p> <p>如果您已经与 Google Cloud 紧密集成，并且熟悉 Pub/Sub，它作为一个代理是一个很好的选择。它极其可扩展且完全托管，任务委派方式与 RabbitMQ 类似。</p>","path":["快速入门","后端与代理","后端和代理"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/","level":1,"title":"使用 Google Pub/Sub","text":"","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_1","level":2,"title":"安装","text":"<p>要支持 Google Pub/Sub，您需要安装额外的依赖项。您可以使用 <code>celery[gcpubsub]</code> 一次性安装 Celery 和这些依赖项：</p> uvpip <pre><code>uv add \"celery[gcpubsub]\"\n</code></pre> <pre><code>pip install \"celery[gcpubsub]\"\n</code></pre>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_2","level":2,"title":"配置","text":"<p>您必须在代理 URL 中指定 gcpubsub 和 Google 项目：</p> <pre><code>broker_url = 'gcpubsub://projects/project-id'\n</code></pre> <p>URL 格式为：</p> <pre><code>gcpubsub://projects/project-id\n</code></pre> <p>请注意，您必须在 URL 中为 project-id 添加 <code>projects/</code> 前缀。</p> <p>登录凭据将是您在环境中设置的常规 GCP 凭据。</p>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_3","level":2,"title":"选项","text":"","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_4","level":3,"title":"资源过期","text":"<p>默认设置旨在尽可能简单、经济高效且直观，以便\"开箱即用\"。Pub/Sub 消息和订阅设置为 24 小时后过期，可以通过配置 <code>expiration_seconds</code> 设置来调整：</p> <pre><code>expiration_seconds = 86400\n</code></pre> <p>Google Cloud Pub/Sub 设置的概述</p>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_5","level":3,"title":"确认截止时间","text":"<p><code>ack_deadline_seconds</code> 定义了 Pub/Sub 基础设施在将消息重新传递给另一个工作器之前，应等待工作器确认任务的秒数。</p> <p>此选项通过 <code>broker_transport_options</code> 设置进行配置：</p> <pre><code>broker_transport_options = {'ack_deadline_seconds': 60}  # 1 分钟。\n</code></pre> <p>默认的可见性超时为 240 秒，工作器会自动延长其所有待处理消息的确认时间。</p> <p>Pub/Sub 截止时间的概述</p>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_6","level":3,"title":"轮询间隔","text":"<p>轮询间隔决定了在轮询失败之间休眠的秒数。此值可以是整数或浮点数。默认值为 0.1 秒。但这并不意味着当没有更多消息可读时，工作器会每 0.1 秒轰炸 Pub/Sub API，因为它会被对 Pub/Sub API 的阻塞调用所阻塞，该调用只会在有新消息可读或 10 秒后返回。</p> <p>轮询间隔可以通过 <code>broker_transport_options</code> 设置进行配置：</p> <pre><code>broker_transport_options = {'polling_interval': 0.3}\n</code></pre> <p>非常频繁的轮询间隔可能导致忙循环，导致工作器使用大量 CPU 时间。如果您需要亚毫秒级的精度，应考虑使用其他传输方式，如 RabbitMQ 或 Redis。</p>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_7","level":3,"title":"队列前缀","text":"<p>默认情况下，Celery 会为队列名称分配 <code>kombu-</code> 前缀。如果您有其他使用 Pub/Sub 的服务，可以通过 <code>broker_transport_options</code> 设置进行配置：</p> <pre><code>broker_transport_options = {'queue_name_prefix': 'kombu-'}\n</code></pre>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_8","level":3,"title":"结果","text":"<p>Google Cloud Storage (GCS) 可能是存储结果的一个不错的选择。。</p>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/gcpubsub/#_9","level":2,"title":"注意事项","text":"<ul> <li> <p>使用 celery flower 时，需要 --inspect-timeout=10 选项才能正确检测工作器状态。</p> </li> <li> <p>GCP 订阅的空闲订阅（没有排队的消息）配置为 24 小时后删除。   这旨在降低成本。</p> </li> <li> <p>排队和未确认的消息设置为 24 小时后自动清理。   原因同上。</p> </li> <li> <p>通道队列大小是近似值，可能不准确。   原因是 Pub/Sub API 不提供获取订阅中确切消息数量的方法。</p> </li> <li> <p>孤儿（无订阅）Pub/Sub 主题不会被自动删除！！   由于 GCP 对每个项目引入了 10k 个主题的硬限制，   建议定期手动删除孤儿主题。</p> </li> <li> <p>最大消息大小限制为 10MB，作为解决方法，您可以使用 GCS 后端   将消息存储在 GCS 中，并将 GCS URL 传递给任务。</p> </li> </ul>","path":["快速入门","后端与代理","使用 Google Pub/Sub"],"tags":[]},{"location":"getting-started/backends-and-brokers/kafka/","level":1,"title":"使用 Kafka","text":"","path":["快速入门","后端与代理","使用 Kafka"],"tags":[]},{"location":"getting-started/backends-and-brokers/kafka/#_1","level":2,"title":"配置","text":"celeryconfig.py<pre><code>import os\n\ntask_serializer = 'json'\nbroker_transport_options = {\n    # \"allow_create_topics\": True,\n}\nbroker_connection_retry_on_startup = True\n\n# 对于使用 SQLAlchemy 作为后端\n# result_backend = 'db+postgresql://postgres:example@localhost/postgres'\n\nbroker_transport_options.update({\n    \"security_protocol\": \"SASL_SSL\",\n    \"sasl_mechanism\": \"SCRAM-SHA-512\",\n})\nsasl_username = os.environ[\"SASL_USERNAME\"]\nsasl_password = os.environ[\"SASL_PASSWORD\"]\nbroker_url = f\"confluentkafka://{sasl_username}:{sasl_password}@broker:9094\"\nbroker_transport_options.update({\n    \"kafka_admin_config\": {\n        \"sasl.username\": sasl_username,\n        \"sasl.password\": sasl_password,\n    },\n    \"kafka_common_config\": {\n        \"sasl.username\": sasl_username,\n        \"sasl.password\": sasl_password,\n        \"security.protocol\": \"SASL_SSL\",\n        \"sasl.mechanism\": \"SCRAM-SHA-512\",\n        \"bootstrap_servers\": \"broker:9094\",\n    }\n})\n</code></pre> <p>请注意，如果主题尚不存在，则需要 \"allow_create_topics\"，否则不需要。</p> tasks.py<pre><code>from celery import Celery\n\napp = Celery('tasks')\napp.config_from_object('celeryconfig')\n\n\n@app.task\ndef add(x, y):\n    return x + y\n</code></pre>","path":["快速入门","后端与代理","使用 Kafka"],"tags":[]},{"location":"getting-started/backends-and-brokers/kafka/#_2","level":2,"title":"认证","text":"<p>参见上文。SASL 用户名和密码通过环境变量传递。</p>","path":["快速入门","后端与代理","使用 Kafka"],"tags":[]},{"location":"getting-started/backends-and-brokers/kafka/#_3","level":2,"title":"更多信息","text":"<p>Celery 队列会被路由到 Kafka 主题。例如，如果一个队列名为 \"add_queue\"，那么将在 Kafka 中创建/使用一个名为 \"add_queue\" 的主题。</p> <p>对于 canvas，当使用支持它的后端时，典型的机制如 chain、group 和 chord 似乎可以工作。</p>","path":["快速入门","后端与代理","使用 Kafka"],"tags":[]},{"location":"getting-started/backends-and-brokers/kafka/#_4","level":2,"title":"限制","text":"<p>目前，使用 Kafka 作为代理意味着只能使用一个工作进程。参见 Multiple celery fork pool workers don't work #1785 。</p>","path":["快速入门","后端与代理","使用 Kafka"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/","level":1,"title":"使用 RabbitMQ","text":"","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#_1","level":2,"title":"安装与配置","text":"<p>RabbitMQ 是默认的代理，因此除了您想要使用的代理实例的 URL 位置外，不需要任何额外的依赖项或初始配置：</p> <pre><code>broker_url = 'amqp://myuser:mypassword@localhost:5672/myvhost'\n</code></pre> <p>有关代理 URL 的描述以及 Celery 可用的各种代理配置选项的完整列表，请参阅 <code>conf-broker-settings</code>，并参阅下文设置用户名、密码和虚拟主机。</p>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#rabbitmq-server","level":2,"title":"安装 RabbitMQ Server","text":"<p>请参阅 RabbitMQ 网站上的 Installing RabbitMQ。</p>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#rabbitmq_1","level":3,"title":"设置 RabbitMQ","text":"<p>要使用 Celery，我们需要创建一个 RabbitMQ 用户、一个虚拟主机，并允许该用户访问该虚拟主机：</p> <pre><code>sudo rabbitmqctl add_user myuser mypassword\n\nsudo rabbitmqctl add_vhost myvhost\n\nsudo rabbitmqctl set_user_tags myuser mytag\n\nsudo rabbitmqctl set_permissions -p myvhost myuser \".*\" \".*\" \".*\"\n</code></pre> <p>将上述 <code>myuser</code>、<code>mypassword</code> 和 <code>myvhost</code> 替换为适当的值。</p> <p>有关 access control 的更多信息，请参阅 RabbitMQ Authentication, Authorisation, Access Control。</p>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#macos-rabbitmq","level":3,"title":"在 macOS 上安装 RabbitMQ","text":"<p>在 macOS 上安装 RabbitMQ 最简单的方法是使用 Homebrew。</p> <pre><code>brew install rabbitmq\n</code></pre> <p>使用 <code>brew</code> 安装 RabbitMQ 后，您需要将以下内容添加到您的路径中，以便能够启动和停止代理：将其添加到您的 shell 启动文件中（例如 <code>.bash_profile</code> 或 <code>.profile</code>）。</p> <pre><code>PATH=$PATH:/usr/local/sbin\n</code></pre>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#_2","level":4,"title":"配置系统主机名","text":"<p>如果您使用的 DHCP 服务器给您一个随机的主机名，您需要永久配置主机名。这是因为 RabbitMQ 使用主机名与节点通信。</p> <p>使用 <code>scutil</code> 命令永久设置您的主机名：</p> <pre><code>sudo scutil --set HostName myhost.local\n</code></pre> <p>然后将该主机名添加到 <code>/etc/hosts</code> 中，以便可以将其解析回 IP 地址：</p> <pre><code>127.0.0.1       localhost myhost myhost.local\n</code></pre> <p>如果您启动 <code>rabbitmq-server</code>，您的 rabbit 节点现在应该是 <code>rabbit@myhost</code>，可以通过 <code>rabbitmqctl</code> 验证：</p> <pre><code>sudo rabbitmqctl status\nStatus of node rabbit@myhost ...\n[{running_applications,[{rabbit,\"RabbitMQ\",\"1.7.1\"},\n                    {mnesia,\"MNESIA  CXC 138 12\",\"4.4.12\"},\n                    {os_mon,\"CPO  CXC 138 46\",\"2.2.4\"},\n                    {sasl,\"SASL  CXC 138 11\",\"2.1.8\"},\n                    {stdlib,\"ERTS  CXC 138 10\",\"1.16.4\"},\n                    {kernel,\"ERTS  CXC 138 10\",\"2.13.4\"}]},\n{nodes,[rabbit@myhost]},\n{running_nodes,[rabbit@myhost]}]\n...done.\n</code></pre> <p>如果您的 DHCP 服务器给您一个以 IP 地址开头的主机名（例如 <code>23.10.112.31.comcast.net</code>），这一点尤其重要。在这种情况下，RabbitMQ 将尝试使用 <code>rabbit@23</code>：一个非法的主机名。</p>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#rabbitmq_2","level":4,"title":"启动/停止 RabbitMQ 服务器","text":"<p>要启动服务器：</p> <pre><code>sudo rabbitmq-server\n</code></pre> <p>您也可以通过添加 <code>-detached</code> 选项在后台运行它（注意：只有一个破折号）：</p> <pre><code>sudo rabbitmq-server -detached\n</code></pre> <p>切勿使用 <code>kill</code> (<code>kill(1)</code>) 停止 RabbitMQ 服务器，而是使用 <code>rabbitmqctl</code> 命令：</p> <pre><code>sudo rabbitmqctl stop\n</code></pre>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#quorum","level":2,"title":"使用 Quorum 队列","text":"<p>Warning</p> <p>Quorum 队列需要禁用全局 QoS，这意味着某些功能将无法按预期工作。 有关详细信息，请参阅 <code>limitations</code>。</p> <p>Celery 支持 <code>Quorum Queues</code>，通过将 <code>x-queue-type</code> 标头设置为 <code>quorum</code>，如下所示：</p> <pre><code>from kombu import Queue\n\ntask_queues = [Queue('my-queue', queue_arguments={'x-queue-type': 'quorum'})]\nbroker_transport_options = {\"confirm_publish\": True}\n</code></pre> <p>如果您想更改默认队列的类型，请将 <code>task_default_queue_type</code> 设置为 <code>\"quorum\"</code>。</p> <p>配置 Quorum Queues 的另一种方法是依赖默认设置并使用 <code>task_routes</code>：</p> <pre><code>task_default_queue_type = \"quorum\"\ntask_default_exchange_type = \"topic\"\ntask_default_queue = \"my-queue\"\nbroker_transport_options = {\"confirm_publish\": True}\n\ntask_routes = {\n    \"*\": {\n        \"routing_key\": \"my-queue\",\n    },\n}\n</code></pre> <p>Celery 使用 <code>worker_detect_quorum_queues</code> 设置自动检测是否使用了 quorum 队列。我们建议保持默认行为开启。</p> <p>要从经典镜像队列迁移到 quorum 队列，请参阅 Migrating from Mirrored Classic Queues to Quorum Queues。</p>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#_3","level":3,"title":"限制","text":"<p>禁用全局 QoS 意味着每通道 QoS 现在是静态的。这意味着在使用 Quorum 队列时，某些 Celery 功能将无法工作。</p> <p>自动缩放依赖于在实例化或终止新进程时增加和减少预取计数，因此在检测到 Quorum 队列时它将无法工作。</p> <p>类似地，<code>worker_enable_prefetch_count_reduction</code> 设置在检测到 Quorum 队列时即使设置为 <code>True</code> 也将无效。</p> <p>此外，<code>ETA 和倒计时</code> 在接收到时会阻塞工作进程，直到 ETA 到达，因为我们无法再增加预取计数并从队列中获取另一个任务。</p> <p>为了正确调度 ETA 和倒计时 任务，我们自动检测是否使用了 quorum 队列，如果使用了，Celery 会自动启用 原生延迟交付。</p>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/rabbitmq/#native-delayed-delivery","level":3,"title":"原生延迟交付","text":"<p>由于带有 ETA 和倒计时 的任务会阻塞工作进程，直到它们被调度执行， 我们需要使用 RabbitMQ 的原生功能来调度任务的执行。</p> <p>该设计借鉴自 NServiceBus。如果您对实现细节感兴趣，请参阅 RabbitMQ Delayed Delivery。</p> <p>原生延迟交付在检测到 quorum 队列时自动启用。</p> <p>默认情况下，原生延迟交付队列是 quorum 队列。如果您想将它们更改为经典队列，可以将 <code>broker_native_delayed_delivery_queue_type</code> 设置为 classic。</p>","path":["快速入门","后端与代理","使用 RabbitMQ"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/","level":1,"title":"使用 Redis","text":"","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#_1","level":2,"title":"安装","text":"<p>要使用 Redis 支持，您需要安装额外的依赖项。 您可以使用 <code>celery[redis]</code> 一次性安装 Celery 和这些依赖项：</p> uvpip <pre><code>uv add \"celery[redis]\"\n</code></pre> <pre><code>pip install -U \"celery[redis]\"\n</code></pre>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#_2","level":2,"title":"配置","text":"<p>配置很简单，只需配置 Redis 数据库的位置：</p> <pre><code>app.conf.broker_url = 'redis://localhost:6379/0'\n</code></pre> URL 格式说明 <ol> <li> <p>默认格式</p> <pre><code>redis://:password@hostname:port/db_number\n</code></pre> <p>scheme 后的所有字段都是可选的，将默认为端口 6379 上的 <code>localhost</code>，使用数据库 <code>0</code>。</p> </li> <li> <p>使用 Redis 凭据提供程序</p> <pre><code>redis://@hostname:port/db_number?credential_provider=mymodule.myfile.myclass\n</code></pre> </li> <li> <p>使用 Unix 套接字：</p> <pre><code>redis+socket:///path/to/redis.sock\n</code></pre> <p>使用 Unix 套接字时，可以通过向 URL 添加 <code>virtual_host</code> 参数来指定不同的数据库编号：</p> <pre><code>redis+socket:///path/to/redis.sock?virtual_host=db_number\n</code></pre> </li> <li> <p>连接 Redis Sentinel 列表：</p> <pre><code>app.conf.broker_url = 'sentinel://localhost:26379;sentinel://localhost:26380;sentinel://localhost:26381'\napp.conf.broker_transport_options = {'master_name': \"cluster1\"}\n</code></pre> <p>可以使用 <code>sentinel_kwargs</code> 向 Sentinel 客户端传递其他选项：</p> <pre><code>app.conf.broker_transport_options = {'sentinel_kwargs': {'password': \"password\"}}\n</code></pre> </li> </ol>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#redis-visibility_timeout","level":3,"title":"可见性超时（Visibility Timeout）","text":"<p>可见性超时定义了在消息重新传递给另一个 worker 之前等待 worker 确认任务的秒数。请务必查看下面的 注意事项。</p> <p>此选项通过 <code>broker_transport_options</code> 设置进行配置：</p> <pre><code>app.conf.broker_transport_options = {'visibility_timeout': 3600}    # 默认 1 小时。\n</code></pre>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#redis-results-configuration","level":3,"title":"结果存储（Result Backend）","text":"<p>如果您还想在 Redis 中存储任务的状态和返回值，您应该配置这些设置：</p> <pre><code>app.conf.result_backend = 'redis://localhost:6379/0'\n</code></pre> <p>有关 Redis 结果后端支持的选项的完整列表，请参阅 Redis 后端设置。</p> <p>如果您使用 Sentinel，应使用 <code>result_backend_transport_options</code> 设置指定 master_name：</p> <pre><code>app.conf.result_backend_transport_options = {'master_name': \"my_master\"}\n</code></pre>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#redis-result-backend-global-keyprefix","level":4,"title":"全局键前缀","text":"<p>全局键前缀将添加到结果后端使用的所有键之前，这在 Redis 数据库由不同用户共享时非常有用。 默认情况下，不添加前缀。</p> <p>要配置 Redis 结果后端的全局键前缀，请在 <code>result_backend_transport_options</code> 下使用 <code>global_keyprefix</code> 键：</p> <pre><code>app.conf.result_backend_transport_options = {\n    'global_keyprefix': 'my_prefix_'\n}\n</code></pre>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#redis-result-backend-timeout","level":4,"title":"连接超时","text":"<p>要配置 Redis 结果后端的连接超时，请在 <code>result_backend_transport_options</code> 下使用 <code>retry_policy</code> 键：</p> <pre><code>app.conf.result_backend_transport_options = {\n    'retry_policy': {\n        'timeout': 5.0\n    }\n}\n</code></pre> <p>有关可能的重试策略选项，请参阅 <code>retry_over_time()</code>。</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#redis-serverless","level":2,"title":"Serverless","text":"<p>Celery 支持使用远程无服务器 Redis，这可以显著降低运营开销和成本，使其成为微服务架构或最小化运营费用至关重要的环境中的有利选择。无服务器 Redis 提供了必要的功能，无需手动设置、配置和管理，因此与 Celery 提倡的自动化和可扩展性原则非常契合。</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#upstash","level":3,"title":"Upstash","text":"<p>Upstash 提供无服务器 Redis 数据库服务，为希望利用无服务器架构的 Celery 用户提供无缝解决方案。Upstash 的无服务器 Redis 服务采用最终一致性模型和持久存储，通过多层存储架构实现。</p> <p>与 Celery 的集成很简单，如 Upstash 提供的示例 所示。</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#dragonfly","level":3,"title":"Dragonfly","text":"<p>Dragonfly 是一个即插即用的 Redis 替代品，可降低成本并提升性能。Dragonfly 旨在充分利用现代云硬件的功能，满足现代应用程序的数据需求，使开发人员摆脱传统内存数据存储的限制。</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#redis-caveats","level":2,"title":"注意事项","text":"","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#visibility-timeoutredis-visibility_timeout","level":3,"title":"可见性超时（Visibility Timeout）{#redis-visibility_timeout}","text":"<p>如果任务被确认，任务将被重新传递给另一个 worker 并执行。</p> <p>这会导致 ETA/倒计时/重试 任务出现问题，其中执行时间超过可见性超时；实际上，如果发生这种情况，任务将再次执行，并循环执行。</p> <p>为了解决这个问题，您可以增加可见性超时以匹配您计划使用的最长 ETA 时间。但是，这不推荐，因为它可能对可靠性产生负面影响。Celery 会在 worker 关闭时重新传递消息，因此较长的可见性超时只会延迟在电源故障或强制终止 worker 时\"丢失\"任务的重新传递。</p> <p>Broker 不是数据库，因此如果您需要为更远的将来调度任务，基于数据库的周期性任务可能是更好的选择。周期性任务不会受到可见性超时的影响，因为这是一个与 ETA/倒计时 分开的概念。</p> <p>您可以通过配置以下所有同名选项来增加此超时（需要设置所有选项）：</p> <pre><code>app.conf.broker_transport_options = {'visibility_timeout': 43200}\napp.conf.result_backend_transport_options = {'visibility_timeout': 43200}\napp.conf.visibility_timeout = 43200\n</code></pre> <p>该值必须是一个描述秒数的整数。</p> <p>注意：如果多个应用程序共享同一个 Broker，但设置不同，将使用 最短 的值。这包括如果未设置该值，并且发送了默认值。</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#soft-shutdown","level":3,"title":"软关闭（Soft Shutdown）","text":"<p>在 停止 worker 进程 期间，worker 将尝试重新排队任何未确认的消息（启用 <code>task_acks_late</code> 时）。但是，如果 worker 被强制终止 <code>冷关闭</code>， worker 可能无法按时重新排队任务，并且它们将不会再次被消费，直到 可见性超时 过去。当 可见性超时 非常高且 worker 在刚接收到任务后需要关闭时，这会产生问题。如果在这种情况下任务没有被重新排队，它将需要等待较长的可见性超时过去才能再次被消费，导致任务执行可能出现非常长的延迟。</p> <p><code>软关闭</code> 在 <code>冷关闭</code> 之前引入了一个有时间限制的暖关闭阶段。这个时间窗口显著增加了在关闭期间重新排队任务的机会，从而缓解了长可见性超时的问题。</p> <p>要启用 <code>软关闭</code>，请将 <code>worker_soft_shutdown_timeout</code> 设置为大于 0 的值。该值必须是一个描述秒数的浮点数。在此期间，worker 将继续处理正在运行的任务，直到超时到期，之后将自动启动 <code>冷关闭</code> 以优雅地终止 worker。</p> <p>如果 TERM 在环境变量中配置为 SIGQUIT，并且设置了 <code>worker_soft_shutdown_timeout</code>，则 worker 在接收到 <code>TERM</code> 信号（和 <code>QUIT</code> 信号）时将启动 <code>软关闭</code>。</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#key-eviction","level":3,"title":"键驱逐（Key Eviction）","text":"<p>在某些情况下，Redis 可能会从数据库中驱逐键。</p> <p>如果您遇到类似以下错误：</p> <pre><code>InconsistencyError: Probably the key ('_kombu.binding.celery') has been\nremoved from the Redis database.\n</code></pre> <p>那么您可能希望配置 redis-server 不驱逐键，通过在 Redis 配置文件中设置：</p> <ul> <li><code>maxmemory</code> 选项</li> <li><code>maxmemory-policy</code> 选项设置为 <code>noeviction</code> 或 <code>allkeys-lru</code></li> </ul> <p>有关驱逐策略的详细信息，请参阅 Key eviction | Docs</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/redis/#redis-group-result-ordering","level":3,"title":"组结果排序（Group Result Ordering）","text":"<p>Celery 4.4.6 及更早版本使用未排序的列表在 Redis 后端中存储组的 result 对象。这可能导致这些结果以与原始组实例化中关联任务不同的顺序返回。Celery 4.4.7 引入了一个可选行为，修复了此问题，并确保组结果按照任务定义的相同顺序返回，与其他后端的行为匹配。在 Celery 5.0 中，此行为更改为选择退出。该行为由 <code>result_chord_ordered</code> 配置选项控制，可以像这样设置：</p> <pre><code># 为运行 Celery 4.4.6 或更早版本的 worker 指定此选项无效\napp.conf.result_backend_transport_options = {\n    'result_chord_ordered': True    # 或 False\n}\n</code></pre> <p>这是共享相同 Redis 后端进行结果存储的 worker 运行时行为的不兼容更改，因此所有 worker 必须遵循新行为或旧行为以避免中断。对于运行 Celery 4.4.6 或更早版本的一些 worker 的集群，这意味着运行 4.4.7 的 worker 不需要特殊配置，而运行 5.0 或更高版本的 worker 必须将 <code>result_chord_ordered</code> 设置为 <code>False</code>。对于没有运行 4.4.6 或更早版本但有一些运行 4.4.7 的 worker 的集群，建议将所有 worker 的 <code>result_chord_ordered</code> 设置为 <code>True</code>，以便于将来的迁移。行为之间的迁移将破坏当前保存在 Redis 后端中的结果，如果迁移的 worker 运行下游任务，将导致中断 - 请相应地进行规划。</p>","path":["快速入门","后端与代理","使用 Redis"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/","level":1,"title":"使用 Amazon SQS","text":"","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#broker-sqs-installation","level":2,"title":"安装","text":"<p>要支持 Amazon SQS，您需要安装额外的依赖项。 您可以使用 <code>celery[sqs]</code> 一次性安装 Celery 和这些依赖项：</p> uvpip <pre><code>uv add \"celery[sqs]\"\n</code></pre> <pre><code>pip install \"celery[sqs]\"\n</code></pre>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#broker-sqs-configuration","level":2,"title":"配置","text":"<p>您必须在代理 URL 中指定 SQS:</p> <pre><code>broker_url = 'sqs://ABCDEFGHIJKLMNOPQRST:ZYXK7NiynGlTogH8Nj+P9nlE73sq3@'\n</code></pre> <p>其中 URL 格式为：</p> <pre><code>sqs://aws_access_key_id:aws_secret_access_key@\n</code></pre> <p>请注意，您必须记住在末尾包含 <code>@</code> 符号，并对密码进行编码，以便始终能够正确解析。例如：</p> <pre><code>from kombu.utils.url import safequote\n\naws_access_key = safequote(\"ABCDEFGHIJKLMNOPQRST\")\naws_secret_key = safequote(\"ZYXK7NiynG/TogH8Nj+P9nlE73sq3\")\n\nbroker_url = \"sqs://{aws_access_key}:{aws_secret_key}@\".format(\n    aws_access_key=aws_access_key, aws_secret_key=aws_secret_key,\n)\n</code></pre> <p>Warning</p> <p>不要将此设置选项与 django 的 <code>debug=True</code> 一起使用。这可能导致已部署的 django 应用程序出现安全问题。</p> <p>在调试模式下，django 会显示环境变量，SQS URL 可能会暴露给互联网，包括您的 AWS 访问密钥和密钥。请在已部署的 django 应用程序上关闭调试模式，或考虑使用下面描述的设置选项。</p> <p>登录凭据也可以使用环境变量 <code>AWS_ACCESS_KEY_ID</code> 和 <code>AWS_SECRET_ACCESS_KEY</code> 设置，在这种情况下，代理 URL 可能仅为 <code>sqs://</code>。</p> <p>如果您在实例上使用 IAM 角色，可以将 BROKER_URL 设置为：<code>sqs://</code>，kombu 将尝试从实例元数据中检索访问令牌。</p>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#_1","level":2,"title":"选项","text":"","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#_2","level":3,"title":"区域","text":"<p>默认区域是 <code>us-east-1</code>，但您可以通过配置 <code>broker_transport_options</code> 设置来选择其他区域:</p> <pre><code>broker_transport_options = {'region': 'eu-west-1'}\n</code></pre> <p>AWS 全球基础设施</p>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#sqs-visibility-timeout","level":3,"title":"可见性超时","text":"<p>可见性超时定义了在消息重新传递给另一个工作器之前，等待工作器确认任务的秒数。另请参阅下面的注意事项。</p> <p>此选项通过 <code>broker_transport_options</code> 设置:</p> <pre><code>broker_transport_options = {'visibility_timeout': 1800}  # 默认 30 分钟。\n</code></pre>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#_3","level":3,"title":"轮询间隔","text":"<p>轮询间隔决定了在轮询失败之间休眠的秒数。此值可以是整数或浮点数。默认值为 一秒：这意味着当没有更多消息可读取时，工作器将休眠一秒。</p> <p>您必须注意 更频繁的轮询也更昂贵，因此增加轮询间隔可以节省您的资金。</p> <p>轮询间隔可以通过 <code>broker_transport_options</code> 设置:</p> <pre><code>broker_transport_options = {'polling_interval': 0.3}\n</code></pre> <p>非常频繁的轮询间隔可能导致 忙循环，导致工作器使用大量 CPU 时间。如果您需要亚毫秒精度，应考虑使用其他传输方式，如 Redis 或 RabbitMQ。</p>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#_4","level":3,"title":"长轮询","text":"<p>默认启用 SQS 长轮询，并且 ReceiveMessage 操作的 <code>WaitTimeSeconds</code> 参数设置为 10 秒。</p> <p><code>WaitTimeSeconds</code> 参数的值可以通过 <code>broker_transport_options</code> 设置:</p> <pre><code>broker_transport_options = {'wait_time_seconds': 15}\n</code></pre> <p>有效值为 0 到 20。请注意，新创建的队列本身（即使由 Celery 创建）也将为 \"接收消息等待时间\" 队列属性设置默认值 0。</p>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#_5","level":3,"title":"队列前缀","text":"<p>默认情况下，Celery 不会为队列名称分配任何前缀，如果您有其他使用 SQS 的服务，可以通过 <code>broker_transport_options</code> 设置进行配置:</p> <pre><code>broker_transport_options = {'queue_name_prefix': 'celery-'}\n</code></pre>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#predefined-queues","level":3,"title":"预定义队列","text":"<p>如果您希望 Celery 使用 AWS 中的一组预定义队列，并且从不尝试列出 SQS 队列，也不尝试创建或删除它们，请使用 预定义队列 设置传递队列名称到 URL 的映射:</p> <pre><code>broker_transport_options = {\n    'predefined_queues': {\n        'my-q': {\n            'url': 'https://ap-southeast-2.queue.amazonaws.com/123456/my-q',\n            'access_key_id': 'xxx',\n            'secret_access_key': 'xxx',\n        }\n    }\n}\n</code></pre> <p>Warning</p> <p>重要： 使用 预定义队列 时，请勿对 <code>access_key_id</code> 和 <code>secret_access_key</code> 值使用 URL 编码的凭据（<code>safequote</code>）。 URL 编码应仅应用于代理 URL 中的凭据。</p> <p>在 预定义队列 中使用 URL 编码的凭据将导致签名不匹配错误，例如：\"我们计算的请求签名与您提供的签名不匹配。\"</p> <p>结合代理 URL 和预定义队列的正确示例：</p> <pre><code>import os\nfrom kombu.utils.url import safequote\nfrom celery import Celery\n\n# 来自环境的原始凭据\nAWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\nAWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n\n# 仅对代理 URL 进行 URL 编码\naws_access_key_encoded = safequote(AWS_ACCESS_KEY_ID)\naws_secret_key_encoded = safequote(AWS_SECRET_ACCESS_KEY)\n\n# 在代理 URL 中使用编码的凭据\nbroker_url = f\"sqs://{aws_access_key_encoded}:{aws_secret_key_encoded}@\"\n\ncelery_app = Celery(\"tasks\", broker=broker_url)\ncelery_app.conf.broker_transport_options = {\n    \"region\": \"us-east-1\",\n    \"predefined_queues\": {\n        \"my-queue\": {\n            \"url\": \"https://sqs.us-east-1.amazonaws.com/123456/my-queue\",\n            # 在此处使用原始凭据（非编码）\n            \"access_key_id\": AWS_ACCESS_KEY_ID,\n            \"secret_access_key\": AWS_SECRET_ACCESS_KEY,\n        },\n    },\n}\n</code></pre> <p>使用此选项时，可见性超时应在 SQS 队列中（在 AWS 中）设置，而不是通过 可见性超时 选项设置。</p>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#_6","level":3,"title":"退避策略","text":"<p>退避策略使用 SQS 可见性超时机制来改变任务重试之间的时间差。该机制将消息特定的 可见性超时 从队列的 <code>Default visibility timeout</code> 更改为策略配置的超时时间。重试次数由 SQS 管理（具体通过 <code>ApproximateReceiveCount</code> 消息属性），用户无需进一步操作。</p> <p>配置队列和退避策略:</p> <pre><code>broker_transport_options = {\n    'predefined_queues': {\n        'my-q': {\n            'url': 'https://ap-southeast-2.queue.amazonaws.com/123456/my-q',\n            'access_key_id': 'xxx',\n            'secret_access_key': 'xxx',\n            'backoff_policy': {1: 10, 2: 20, 3: 40, 4: 80, 5: 320, 6: 640},\n            'backoff_tasks': ['svc.tasks.tasks.task1']\n        }\n    }\n}\n</code></pre> <p><code>backoff_policy</code> 字典，其中键是重试次数，值是重试之间的延迟秒数（即 SQS 可见性超时） <code>backoff_tasks</code> 应用上述策略的任务名称列表</p> <p>上述策略：</p> 尝试次数 延迟 <code>第 2 次尝试</code> 20 秒 <code>第 3 次尝试</code> 40 秒 <code>第 4 次尝试</code> 80 秒 <code>第 5 次尝试</code> 320 秒 <code>第 6 次尝试</code> 640 秒","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#sts","level":3,"title":"STS 令牌认证","text":"<p>https://docs.aws.amazon.com/cli/latest/reference/sts/assume-role.html</p> <p>通过使用 <code>sts_role_arn</code> 和 <code>sts_token_timeout</code> 代理传输选项支持 AWS STS 认证。<code>sts_role_arn</code> 是我们用于授权访问 SQS 的假定 IAM 角色 ARN。<code>sts_token_timeout</code> 是令牌超时时间，默认为 900 秒（最小值）。在指定时间段后，将创建新令牌:</p> <pre><code>broker_transport_options = {\n    'predefined_queues': {\n        'my-q': {\n            'url': 'https://ap-southeast-2.queue.amazonaws.com/123456/my-q',\n            'access_key_id': 'xxx',\n            'secret_access_key': 'xxx',\n            'backoff_policy': {1: 10, 2: 20, 3: 40, 4: 80, 5: 320, 6: 640},\n            'backoff_tasks': ['svc.tasks.tasks.task1']\n        }\n    },\n'sts_role_arn': 'arn:aws:iam::&lt;xxx&gt;:role/STSTest', # 可选\n'sts_token_timeout': 900 # 可选\n}\n</code></pre>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#sqs-caveats","level":2,"title":"注意事项","text":"<ul> <li> <p>如果任务在 可见性超时 内未被确认，任务将被重新传递给另一个工作器并执行。</p> <p>这会导致 ETA/倒计时/重试任务出现问题，其中执行时间超过可见性超时；实际上，如果发生这种情况， 任务将再次执行，并循环执行。</p> <p>因此，您必须增加可见性超时以匹配您计划使用的最长 ETA 时间。</p> <p>请注意，Celery 将在工作器关闭时重新传递消息，因此较长的可见性超时只会延迟在电源故障或强制终止工作器时 \"丢失\"任务的重新传递。</p> <p>周期性任务不会受到可见性超时的影响，因为这是一个与 ETA/倒计时分离的概念。</p> <p>截至本文撰写时，AWS 支持的最大可见性超时为 12 小时（43200 秒）:</p> <pre><code>broker_transport_options = {'visibility_timeout': 43200}\n</code></pre> </li> <li> <p>SQS 尚不支持工作器远程控制命令。</p> </li> <li> <p>SQS 尚不支持事件，因此不能与 <code>celery events</code>、<code>celerymon</code> 或 Django Admin 监视器一起使用。</p> </li> <li> <p>对于 FIFO 队列，在发布消息时可能需要设置额外的消息属性，如 <code>MessageGroupId</code> 和 <code>MessageDeduplicationId</code>。</p> <p>消息属性可以作为关键字参数传递给 <code>apply_async()</code>：</p> <pre><code>message_properties = {\n    'MessageGroupId': '&lt;YourMessageGroupId&gt;',\n    'MessageDeduplicationId': '&lt;YourMessageDeduplicationId&gt;'\n}\ntask.apply_async(**message_properties)\n</code></pre> </li> <li> <p>在 停止 worker 进程 期间，工作器将尝试重新排队任何未确认的消息（启用 <code>task_acks_late</code>）。     但是，如果工作器被强制终止（<code>冷关闭</code>），工作器可能无法及时重新排队任务，     并且它们将不会被再次消费，直到 :ref:<code>sqs-visibility-timeout</code> 过去。当 :ref:<code>sqs-visibility-timeout</code> 非常高且     工作器在接收到任务后需要关闭时，这会产生问题。如果在这种情况下任务没有被重新排队，它将需要等待长的可见性超时     过去才能再次被消费，导致任务执行可能非常长的延迟。</p> <p><code>软关闭</code> 在 <code>冷关闭</code> 之前引入了一个有时间限制的温关闭阶段。 这个时间窗口显著增加了在关闭期间重新排队任务的机会，从而缓解了长可见性超时的问题。</p> <p>要启用 <code>软关闭</code>，请将 <code>worker_soft_shutdown_timeout</code> 设置为大于 0 的值。 该值必须是一个描述秒数的浮点数。在此期间，工作器将继续处理正在运行的任务，直到超时到期， 之后将自动启动 <code>冷关闭</code> 以优雅地终止工作器。</p> <p>如果 SIGTERM 在环境变量中配置为 SIGQUIT，并且设置了 <code>worker_soft_shutdown_timeout</code>， 工作器将在接收到 <code>TERM</code> 信号（和 <code>QUIT</code> 信号）时启动 <code>软关闭</code>。</p> </li> </ul>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"getting-started/backends-and-brokers/sqs/#sqs-results-configuration","level":3,"title":"结果","text":"<p>Amazon Web Services 系列中的多个产品可能是存储或发布结果的良好候选者，但目前没有包含这样的结果后端。</p> <p>注意</p> <p>不要将 <code>amqp</code> 结果后端与 SQS 一起使用。</p> <p>它将为每个任务创建一个队列，并且队列不会被收集。这可能会花费您的资金，而这些资金最好用于为 Celery 贡献一个 AWS 结果存储后端。</p>","path":["快速入门","后端与代理","使用 Amazon SQS"],"tags":[]},{"location":"user-guide/application/","level":1,"title":"应用程序","text":"<p>Celery 在使用前必须被实例化，这个实例被称为应用程序（或简称为 app）。</p> <p>应用程序是线程安全的，因此具有不同配置、组件和任务的多个 Celery 应用程序可以在同一个进程空间中共存。</p> <p>现在让我们创建一个：</p> <pre><code>&gt;&gt;&gt; from celery import Celery\n&gt;&gt;&gt; app = Celery()\n&gt;&gt;&gt; app\n&lt;Celery __main__:0x100469fd0&gt;\n</code></pre> <p>最后一行显示了应用程序的文本表示：包括应用程序类的名称（<code>Celery</code>）、当前主模块的名称（<code>__main__</code>）和对象的内存地址（<code>0x100469fd0</code>）。</p>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#main-name","level":2,"title":"主名称（Main Name）","text":"<p>这些中只有一个是重要的，那就是主模块名称。让我们看看为什么是这样。</p> <p>当你在 Celery 中发送任务消息时，该消息不会包含任何源代码，只包含你想要执行的任务的名称。这类似于互联网上主机名的工作方式：每个工作器维护一个任务名称到其实际函数的映射，称为 任务注册表。</p> <p>每当你定义一个任务时，该任务也会被添加到本地注册表中：</p> <pre><code>&gt;&gt;&gt; @app.task\n... def add(x, y):\n...     return x + y\n\n&gt;&gt;&gt; add\n&lt;@task: __main__.add&gt;\n\n&gt;&gt;&gt; add.name\n__main__.add\n\n&gt;&gt;&gt; app.tasks['__main__.add']\n&lt;@task: __main__.add&gt;\n</code></pre> <p>在那里你又看到了 <code>__main__</code>；每当 Celery 无法检测到函数属于哪个模块时，它会使用主模块名称来生成任务名称的开头。</p> <p>这仅在有限的用例中是个问题：</p> <ol> <li>如果定义任务的模块作为程序运行。</li> <li>如果应用程序是在 Python shell（REPL）中创建的。</li> </ol> <p>例如这里，任务模块也用于使用 <code>app.worker_main()</code> 启动工作器：</p> tasks.py<pre><code>from celery import Celery\napp = Celery()\n\n@app.task\ndef add(x, y): return x + y\n\nif __name__ == '__main__':\n    args = ['worker', '--loglevel=INFO']\n    app.worker_main(argv=args)\n</code></pre> <p>当这个模块被执行时，任务将以 <code>__main__</code> 开头命名，但当模块被另一个进程导入时，比如调用任务，任务将以 <code>tasks</code>（模块的真实名称）开头命名：</p> <pre><code>&gt;&gt;&gt; from tasks import add\n&gt;&gt;&gt; add.name\ntasks.add\n</code></pre> <p>你可以为 main 模块指定另一个名称：</p> <pre><code>&gt;&gt;&gt; app = Celery('tasks')\n&gt;&gt;&gt; app.main\n'tasks'\n\n&gt;&gt;&gt; @app.task\n... def add(x, y):\n...     return x + y\n\n&gt;&gt;&gt; add.name\ntasks.add\n</code></pre> <p>任务指南 - 名称</p>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#configuration","level":2,"title":"配置（Configuration）","text":"<p>你可以设置几个选项来改变 Celery 的工作方式。这些选项可以直接在应用程序实例上设置，或者你可以使用专用的配置模块。</p> <p>配置可作为 <code>app.conf</code> 使用：</p> <pre><code>&gt;&gt;&gt; app.conf.timezone\n'Europe/London'\n</code></pre> <p>你也可以直接设置配置值：</p> <pre><code>&gt;&gt;&gt; app.conf.enable_utc = True\n</code></pre> <p>或者使用 <code>update()</code> 方法一次更新多个键：</p> <pre><code>&gt;&gt;&gt; app.conf.update(\n...     enable_utc=True,\n...     timezone='Europe/London',\n... )\n</code></pre> <p>配置对象由多个按顺序查询的字典组成：</p> <ol> <li>运行时进行的更改。</li> <li>配置模块（如果有）</li> <li>默认配置（<code>celery.app.defaults</code>）。</li> </ol> <p>你甚至可以使用 <code>app.add_defaults()</code> 方法添加新的默认源。</p> <p>完整配置参考：查看所有可用设置及其默认值的完整列表。</p>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#config_from_object","level":3,"title":"<code>config_from_object</code>","text":"<p><code>app.config_from_object()</code> 方法从配置对象加载配置。</p> <p>这可以是一个配置模块，或者任何具有配置属性的对象。</p> <p>请注意，当调用 <code>app.config_from_object()</code> 时，任何先前设置的配置都将被重置。如果你想设置额外的配置，应该在此之后进行。</p>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#1","level":4,"title":"示例 1：使用模块名称","text":"<p><code>app.config_from_object()</code> 方法可以接受 Python 模块的完全限定名称，甚至是 Python 属性的名称，例如：<code>celeryconfig</code>、<code>myproj.config.celery</code> 或 <code>myproj.config:CeleryConfig</code>：</p> <pre><code>from celery import Celery\n\napp = Celery()\napp.config_from_object('celeryconfig')\n</code></pre> <p><code>celeryconfig</code> 模块可能看起来像这样：</p> celeryconfig.py<pre><code>enable_utc = True\ntimezone = 'Europe/London'\n</code></pre> <p>只要 <code>import celeryconfig</code> 是可能的，应用程序就能够使用它。</p>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#2","level":4,"title":"示例 2：传递实际的模块对象","text":"<p>你也可以传递一个已经导入的模块对象，但这并不总是推荐的。</p> <p>Tip</p> <p>推荐使用模块的名称，因为这意味着在使用 prefork 池时不需要序列化模块。如果你遇到配置问题或 pickle 错误，请尝试使用模块名称代替。</p> <pre><code>import celeryconfig\n\nfrom celery import Celery\n\napp = Celery()\napp.config_from_object(celeryconfig)\n</code></pre>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#3","level":4,"title":"示例 3：使用配置类/对象","text":"<pre><code>from celery import Celery\n\napp = Celery()\n\nclass Config:\n    enable_utc = True\n    timezone = 'Europe/London'\n\napp.config_from_object(Config)\n# 或者使用对象的完全限定名称：\n#   app.config_from_object('module:Config')\n</code></pre>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#config_from_envvar","level":3,"title":"<code>config_from_envvar</code>","text":"<p><code>app.config_from_envvar()</code> 方法从环境变量中获取配置模块名称</p> <p>例如——要从名为 <code>CELERY_CONFIG_MODULE</code> 的环境变量指定的模块加载配置：</p> <pre><code>import os\nfrom celery import Celery\n\n#: 设置默认配置模块名称\nos.environ.setdefault('CELERY_CONFIG_MODULE', 'celeryconfig')\n\napp = Celery()\napp.config_from_envvar('CELERY_CONFIG_MODULE')\n</code></pre> <p>然后你可以通过环境指定要使用的配置模块：</p> <pre><code>CELERY_CONFIG_MODULE=\"celeryconfig.prod\" celery worker -l INFO\n</code></pre>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#_2","level":3,"title":"审查配置","text":"<p>如果你想要打印出配置作为调试信息或类似用途，你可能还想过滤掉敏感信息，如密码和 API 密钥。</p> <p>Celery 附带了一些用于呈现配置的有用工具，其中之一是 <code>humanize()</code>：</p> <pre><code>&gt;&gt;&gt; app.conf.humanize(with_defaults=False, censored=True)\n</code></pre> <p>此方法将配置作为表格字符串返回。默认情况下，这仅包含对配置的更改，但你可以通过启用 <code>with_defaults</code> 参数来包含内置的默认键和值。</p> <p>如果你希望将配置作为字典处理，可以使用 <code>table()</code> 方法：</p> <pre><code>&gt;&gt;&gt; app.conf.table(with_defaults=False, censored=True)\n</code></pre> <p>请注意，Celery 无法删除所有敏感信息，因为它仅使用正则表达式搜索常用命名的键。如果你添加包含敏感信息的自定义设置，应该使用 Celery 识别为机密的名称来命名键。</p> <p>如果配置设置的名称包含以下任何子字符串，将被审查：</p> <p><code>API</code>, <code>TOKEN</code>, <code>KEY</code>, <code>SECRET</code>, <code>PASS</code>, <code>SIGNATURE</code>, <code>DATABASE</code></p>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#laziness","level":2,"title":"惰性（Laziness）","text":"<p>应用程序实例是惰性的，意味着它只有在实际需要时才会被求值。</p> <p>创建 <code>Celery</code> 实例只会执行以下操作：</p> <ol> <li>创建一个逻辑时钟实例，用于事件。</li> <li>创建任务注册表。</li> <li>将自己设置为当前应用程序（但如果 <code>set_as_current</code> 参数被禁用则不会）</li> <li>调用 <code>app.on_init()</code> 回调（默认情况下不执行任何操作）。</li> </ol> <p><code>app.task()</code> 装饰器不会在定义任务时创建任务，而是将任务的创建推迟到任务被使用时，或者在应用程序被最终化之后。</p> <p>这个例子展示了任务直到你使用任务或访问属性（在这种情况下是 <code>__repr__</code>）时才会被创建：</p> <pre><code>&gt;&gt;&gt; @app.task\n&gt;&gt;&gt; def add(x, y):\n...    return x + y\n\n&gt;&gt;&gt; type(add)\n&lt;class 'celery.local.PromiseProxy'&gt;\n\n&gt;&gt;&gt; add.__evaluated__()\nFalse\n\n&gt;&gt;&gt; add        # &lt;-- 导致 repr(add) 发生\n&lt;@task: __main__.add&gt;\n\n&gt;&gt;&gt; add.__evaluated__()\nTrue\n</code></pre> <p>应用程序的 最终化 可以通过显式调用 <code>app.finalize()</code> 发生，或者通过隐式访问 <code>app.tasks</code> 属性发生。</p> <p>最终化对象将：</p> <ol> <li>复制必须在应用程序之间共享的任务默认情况下任务是被共享的，但如果任务装饰器的 <code>shared</code> 参数被禁用，那么任务将对其绑定的应用程序私有。</li> <li>评估所有挂起的任务装饰器。</li> <li> <p>确保所有任务都绑定到当前应用程序。</p> <p>任务绑定到应用程序，以便它们可以从配置中读取默认值。</p> </li> </ol> <p>\"默认应用程序\"</p> <p>Celery 并不总是有应用程序，过去只有基于模块的 API。在 Celery 5.0 发布之前，旧位置提供了兼容性 API，但已被移除。</p> <p>Celery 总是创建一个特殊的应用程序 - \"默认应用程序\"，如果没有实例化自定义应用程序，就会使用这个应用程序。</p> <p><code>celery.task</code> 模块不再可用。使用应用程序实例上的方法，而不是基于模块的 API：</p> <pre><code>from celery.task import Task   # &lt;&lt; 旧的 Task 基类\n\nfrom celery import Task        # &lt;&lt; 新的基类\n</code></pre>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#breaking-the-chain","level":2,"title":"打破链（Breaking the chain）","text":"<p>虽然可以依赖当前设置的应用程序，但最佳实践是始终将应用程序实例传递给任何需要它的地方。</p> <p>我称之为\"应用程序链（app chain）\"，因为它创建了一个依赖于传递的应用程序的实例链。</p> <p>以下示例被认为是糟糕的做法：</p> <pre><code>from celery import current_app\n\nclass Scheduler:\n\n    def run(self):\n        app = current_app\n</code></pre> <p>相反，它应该将 <code>app</code> 作为参数：</p> <pre><code>class Scheduler:\n\n    def __init__(self, app):\n        self.app = app\n</code></pre> <p>在内部，Celery 使用 <code>celery.app.app_or_default()</code> 函数，以便所有内容也能在基于模块的兼容性 API 中工作</p> <pre><code>from celery.app import app_or_default\n\nclass Scheduler:\n    def __init__(self, app=None):\n        self.app = app_or_default(app)\n</code></pre> <p>在开发中，你可以设置 <code>CELERY_TRACE_APP</code> 环境变量，以便在应用程序链断开时引发异常：</p> <pre><code>CELERY_TRACE_APP=1 celery worker -l INFO\n</code></pre> <p>API 的演进</p> <p>Celery 自 2009 年最初创建以来已经发生了很大变化。</p> <p>例如，在开始时，可以使用任何可调用对象作为任务：</p> <pre><code>def hello(to):\n    return 'hello {0}'.format(to)\n\n&gt;&gt;&gt; from celery.execute import apply_async\n\n&gt;&gt;&gt; apply_async(hello, ('world!',))\n</code></pre> <p>或者你也可以创建一个 <code>Task</code> 类来设置某些选项，或覆盖其他行为</p> <pre><code>from celery import Task\nfrom celery.registry import tasks\n\nclass Hello(Task):\n    queue = 'hipri'\n\n    def run(self, to):\n        return 'hello {0}'.format(to)\ntasks.register(Hello)\n\n&gt;&gt;&gt; Hello.delay('world!')\n</code></pre> <p>后来，人们认为传递任意可调用对象是一种反模式，因为它使得使用除 pickle 之外的其他序列化器变得非常困难，该功能在 2.0 版本中被移除，被任务装饰器取代：</p> <pre><code>from celery import app\n\n@app.task(queue='hipri')\ndef hello(to):\n    return 'hello {0}'.format(to)\n</code></pre>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/application/#abstract-tasks","level":2,"title":"抽象任务（Abstract Tasks）","text":"<p>所有使用 <code>app.task()</code> 装饰器创建的任务都将继承应用程序的基础 <code>Task</code> 类。</p> <p>你可以使用 <code>base</code> 参数指定不同的基类：</p> <pre><code>@app.task(base=OtherTask)\ndef add(x, y):\n    return x + y\n</code></pre> <p>要创建自定义任务类，你应该继承中性基类：<code>celery.Task</code>。</p> <pre><code>from celery import Task\n\nclass DebugTask(Task):\n\n    def __call__(self, *args, **kwargs):\n        print('TASK STARTING: {0.name}[{0.request.id}]'.format(self))\n        return self.run(*args, **kwargs)\n</code></pre> <p>Tip</p> <p>如果你重写了任务的 <code>__call__</code> 方法，那么非常重要的一点是你也要调用 <code>self.run</code> 来执行任务的主体。不要调用 <code>super().__call__</code>。中性基类 <code>celery.Task</code> 的 <code>__call__</code> 方法仅用于参考。为了优化，这已经被展开到 <code>celery.app.trace.build_tracer.trace_task</code> 中，如果没有定义 <code>__call__</code> 方法，它会直接在自定义任务类上调用 <code>run</code>。</p> <p>中性基类是特殊的，因为它还没有绑定到任何特定的应用程序。一旦任务绑定到应用程序，它将读取配置来设置默认值，等等。</p> <p>要实现一个基类，你需要使用 <code>app.task()</code> 装饰器创建一个任务：</p> <pre><code>@app.task(base=DebugTask)\ndef add(x, y):\n    return x + y\n</code></pre> <p>甚至可以通过更改应用程序的 <code>app.Task()</code> 属性来更改应用程序的默认基类：</p> <pre><code>&gt;&gt;&gt; from celery import Celery, Task\n\n&gt;&gt;&gt; app = Celery()\n\n&gt;&gt;&gt; class MyBaseTask(Task):\n...    queue = 'hipri'\n\n&gt;&gt;&gt; app.Task = MyBaseTask\n&gt;&gt;&gt; app.Task\n&lt;unbound MyBaseTask&gt;\n\n&gt;&gt;&gt; @app.task\n... def add(x, y):\n...     return x + y\n\n&gt;&gt;&gt; add\n&lt;@task: __main__.add&gt;\n\n&gt;&gt;&gt; add.__class__.mro()\n[&lt;class add of &lt;Celery __main__:0x1012b4410&gt;&gt;,\n &lt;unbound MyBaseTask&gt;,\n &lt;unbound Task&gt;,\n &lt;type 'object'&gt;]\n</code></pre>","path":["用户指南","应用程序"],"tags":[]},{"location":"user-guide/calling/","level":1,"title":"调用","text":"","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_2","level":2,"title":"基础","text":"<p>本文档描述了 Celery 的统一\"调用 API\"，该 API 由任务实例和 画布指南 使用。</p> <p>该 API 定义了一组标准的执行选项，以及三种方法：</p> 方法 描述 <code>apply_async(args[, kwargs[, …]])</code> 发送任务消息。 <code>delay(*args, **kwargs)</code> 发送任务消息的快捷方式，但不支持执行选项。 <code>__call__(*args, **kwargs)</code> 应用支持调用 API 的对象（例如，<code>add(2, 2)</code>）意味着任务不会由工作进程执行，而是在当前进程中执行（不会发送消息）。 快速参考表 函数 描述 <code>delay(arg, kwarg=value)</code> 星号参数到 <code>.apply_async</code> 的快捷方式。（<code>.delay(*args, **kwargs)</code> 调用 <code>.apply_async(args, kwargs)</code>）。 <code>apply_async((arg,), {'kwarg': value})</code> - <code>apply_async(countdown=10)</code> 从现在起 10 秒后执行。 <code>apply_async(eta=now + timedelta(seconds=10))</code> 从现在起 10 秒后执行，使用 <code>eta</code> 指定。 <code>apply_async(countdown=60, expires=120)</code> 从现在起一分钟后执行，但在 2 分钟后过期。 <code>apply_async(expires=now + timedelta(days=2))</code> 在 2 天后过期，使用 :class:<code>~datetime.datetime</code> 设置。 <code>apply_async(task_id=f'my_own_task_id')</code> 将任务的 ID 设置为 my_own_task_id，而不是通常生成的 uuid。","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_3","level":3,"title":"示例","text":"<p><code>delay()</code> 方法很方便，因为它看起来像调用常规函数：</p> <pre><code>task.delay(arg1, arg2, kwarg1='x', kwarg2='y')\n</code></pre> <p>使用 <code>apply_async()</code> 则需要编写：</p> <pre><code>task.apply_async(args=[arg1, arg2], kwargs={'kwarg1': 'x', 'kwarg2': 'y'})\n</code></pre> <p>Tip</p> <p>如果任务未在当前进程中注册，您可以使用 <code>send_task()</code> 通过名称调用任务。</p> <p>所以 <code>delay</code> 显然很方便，但如果您想设置额外的执行选项，则必须使用 <code>apply_async()</code>。</p> <p>本文档的其余部分将详细讨论任务执行选项。所有示例都使用一个名为 <code>add</code> 的任务，返回两个参数的和：</p> <pre><code>@app.task\ndef add(x, y):\n    return x + y\n</code></pre> <p>还有另一种方式…</p> <p>您将在阅读 画布指南 时了解更多信息，但 <code>Signature</code> 是用于传递任务调用签名的对象（例如通过网络发送），它们也支持调用 API：</p> <pre><code>task.s(arg1, arg2, kwarg1='x', kwargs2='y').apply_async()\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_4","level":2,"title":"链接（回调/错误回调）","text":"<p>Celery 支持将任务链接在一起，以便一个任务跟随另一个任务。回调任务将使用父任务的结果作为部分参数来应用：</p> <pre><code>add.apply_async((2, 2), link=add.s(16))\n</code></pre> <p>什么是 <code>s</code>？</p> <p>这里使用的 <code>add.s</code> 调用被称为签名。如果您不知道它们是什么，您应该在画布指南 中阅读相关内容。在那里您还可以了解 <code>chain</code>：一种更简单的链接任务的方式。</p> <p>实际上，<code>link</code> 执行选项被认为是一个内部原语，您可能不会直接使用它，而是使用链式调用。</p> <p>这里第一个任务的结果（4）将被发送到一个新的任务，该任务将 16 加到前一个结果上，形成表达式 <code>(2 + 2) + 16 = 20</code></p> <p>您还可以在任务引发异常时应用回调（错误回调）。工作进程实际上不会将错误回调作为任务调用，而是直接调用错误回调函数，以便可以将原始请求、异常和回溯对象传递给它。</p> <p>这是一个错误回调的示例：</p> <pre><code>@app.task\ndef error_handler(request, exc, traceback):\n    print('Task {0} raised exception: {1!r}\\n{2!r}'.format(\n          request.id, exc, traceback))\n</code></pre> <p>可以使用 <code>link_error</code> 执行选项将其添加到任务中：</p> <pre><code>add.apply_async((2, 2), link_error=error_handler.s())\n</code></pre> <p>此外，<code>link</code> 和 <code>link_error</code> 选项都可以表示为列表：</p> <pre><code>add.apply_async((2, 2), link=[add.s(16), other_task.s()])\n</code></pre> <p>然后回调/错误回调将按顺序调用，并且所有回调都将使用父任务的返回值作为部分参数调用。</p> <p>在 chord 的情况下，我们可以使用多种处理策略来处理错误。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_5","level":2,"title":"关于消息处理","text":"<p>Celery 支持通过设置 <code>on_message</code> 回调来捕获所有状态变化。</p> <p>例如，对于长时间运行的任务发送任务进度，您可以这样做：</p> <pre><code>@app.task(bind=True)\ndef hello(self, a, b):\n    time.sleep(1)\n    self.update_state(state=\"PROGRESS\", meta={'progress': 50})\n    time.sleep(1)\n    self.update_state(state=\"PROGRESS\", meta={'progress': 90})\n    time.sleep(1)\n    return 'hello world: %i' % (a+b)\n</code></pre> <pre><code>def on_raw_message(body):\n    print(body)\n\na, b = 1, 1\nr = hello.apply_async(args=(a, b))\nprint(r.get(on_message=on_raw_message, propagate=False))\n</code></pre> <p>将生成类似这样的输出：</p> <pre><code>{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n 'result': {'progress': 50},\n 'children': [],\n 'status': 'PROGRESS',\n 'traceback': None}\n{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n 'result': {'progress': 90},\n 'children': [],\n 'status': 'PROGRESS',\n 'traceback': None}\n{'task_id': '5660d3a3-92b8-40df-8ccc-33a5d1d680d7',\n 'result': 'hello world: 10',\n 'children': [],\n 'status': 'SUCCESS',\n 'traceback': None}\nhello world: 10\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#calling-eta","level":2,"title":"ETA 和倒计时","text":"<p>ETA（预计到达时间）允许您设置一个特定的日期和时间，这是任务最早执行的时间。<code>countdown</code> 是通过秒数设置未来 ETA 的快捷方式。</p> <pre><code>&gt;&gt;&gt; result = add.apply_async((2, 2), countdown=3)\n&gt;&gt;&gt; result.get()    # this takes at least 3 seconds to return\n4\n</code></pre> <p>任务保证在指定日期和时间之后的某个时间执行，但不一定在确切的时间执行。可能破坏截止时间的原因可能包括队列中有许多项目等待，或者网络延迟严重。为了确保您的任务及时执行，您应该监控队列的拥塞情况。使用 Munin 或类似工具接收警报，以便可以采取适当的措施来减轻工作负载。参见 :ref:<code>monitoring-munin</code>。</p> <p>虽然 <code>countdown</code> 是一个整数，但 <code>eta</code> 必须是一个 <code>datetime</code> 对象，指定确切的日期和时间（包括毫秒精度和时区信息）：</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timedelta, timezone\n\n&gt;&gt;&gt; tomorrow = datetime.now(timezone.utc) + timedelta(days=1)\n&gt;&gt;&gt; add.apply_async((2, 2), eta=tomorrow)\n</code></pre> <p>Warning</p> <p>带有 <code>eta</code> 或 <code>countdown</code> 的任务会立即被工作进程获取，并且在预定时间过去之前，它们会驻留在工作进程的内存中。当使用这些选项来调度大量远期任务时，这些任务可能会在工作进程中累积并对 RAM 使用产生重大影响。</p> <p>此外，任务只有在工作进程开始执行它们时才会被确认。如果使用 Redis 作为代理，当 <code>countdown</code> 超过 <code>visibility_timeout</code> 时，任务将被重新传递（参见 :ref:<code>redis-caveats</code>）。</p> <p>因此，不建议使用 <code>eta</code> 和 <code>countdown</code> 来调度远期任务。理想情况下，使用不超过几分钟的值。对于更长的持续时间，请考虑使用基于数据库的周期性任务，例如在使用 Django 时使用 <code>django-celery-beat</code> 。</p> <p>Warning</p> <p>当使用 RabbitMQ 作为消息代理时，如果指定超过 15 分钟的 <code>countdown</code>，您可能会遇到工作进程终止并引发 :exc:<code>~amqp.exceptions.PreconditionFailed</code> 错误的问题：</p> <pre><code>amqp.exceptions.PreconditionFailed: (0, 0): (406) PRECONDITION_FAILED - consumer ack timed out on channel\n</code></pre> <p>在 RabbitMQ 自版本 3.8.15 起，<code>consumer_timeout</code> 的默认值为 15 分钟。自版本 3.8.17 起，它增加到 30 分钟。如果消费者在超过超时值的时间内没有确认其交付，其通道将以 <code>PRECONDITION_FAILED</code> 通道异常关闭。有关更多信息，请参阅 交付确认超时。</p> <p>要解决此问题，在 RabbitMQ 配置文件 <code>rabbitmq.conf</code> 中，您应该指定 <code>consumer_timeout</code> 参数大于或等于您的倒计时值。例如，您可以指定一个非常大的值<code>consumer_timeout = 31622400000</code>，这相当于 1 年的毫秒数，以避免将来出现问题。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_6","level":2,"title":"过期时间","text":"<p><code>expires</code> 参数定义了一个可选的过期时间，可以是任务发布后的秒数，也可以是使用 <code>datetime</code> 的特定日期和时间：</p> <pre><code>&gt;&gt;&gt; # 任务从现在起一分钟后过期\n&gt;&gt;&gt; add.apply_async((10, 10), expires=60)\n\n&gt;&gt;&gt; # 也支持 datetime\n&gt;&gt;&gt; from datetime import datetime, timedelta, timezone\n&gt;&gt;&gt; add.apply_async((10, 10), kwargs, expires=datetime.now(timezone.utc) + timedelta(days=1))\n</code></pre> <p>当工作进程接收到过期的任务时，它会将任务标记为 <code>REVOKED</code> (<code>TaskRevokedError</code>)。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_7","level":2,"title":"消息发送重试","text":"<p>Celery 会在连接失败时自动重试发送消息，并且重试行为可以配置——比如重试频率、最大重试次数——或者完全禁用。</p> <p>要禁用重试，您可以将 <code>retry</code> 执行选项设置为 <code>False</code>：</p> <pre><code>add.apply_async((2, 2), retry=False)\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_8","level":2,"title":"相关设置","text":"","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#calling-retry","level":3,"title":"重试策略","text":"<p>重试策略是一个映射，用于控制重试的行为， 可以包含以下键：</p> Key Description <code>max_retries</code>  放弃前的最大重试次数，在这种情况下， 导致重试失败的异常将被抛出。 值为 <code>None</code> 表示将无限重试。 默认重试 3 次。  <code>interval_start</code>  定义重试之间等待的秒数（浮点数或整数）。默认值为 0（第一次重试将是即时的）。  <code>interval_step</code>  在每次连续重试时，此数字将被添加到重试延迟中（浮点数或整数）。默认值为 0.2。  <code>interval_max</code>  重试之间等待的最大秒数（浮点数或整数）。默认值为 0.2。  <code>retry_errors</code>  `retry_errors` 是一个异常类的元组，这些异常应该被重试。如果未指定，将被忽略。默认值为 None（忽略）。 例如，如果您只想重试超时的任务，可以使用 <code>TimeoutError</code>：  <pre><code>from kombu.exceptions import TimeoutError\n\nadd.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'retry_errors': (TimeoutError, ),\n})\n</code></pre> <p>例如，默认策略对应：</p> <pre><code>add.apply_async((2, 2), retry=True, retry_policy={\n    'max_retries': 3,\n    'interval_start': 0,\n    'interval_step': 0.2,\n    'interval_max': 0.2,\n    'retry_errors': None,\n})\n</code></pre> <p>重试花费的最大时间将是 0.4 秒。默认设置相对较短，因为如果代理连接断开，连接失败可能导致重试堆积效应——例如，许多 Web 服务器进程等待重试，阻塞其他传入请求。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_9","level":2,"title":"连接错误处理","text":"<p>当您发送任务且消息传输连接丢失，或无法建立连接时，将引发 <code>OperationalError</code> 错误：</p> <pre><code>&gt;&gt;&gt; from proj.tasks import add\n&gt;&gt;&gt; add.delay(2, 2)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"celery/app/task.py\", line 388, in delay\n        return self.apply_async(args, kwargs)\n  File \"celery/app/task.py\", line 503, in apply_async\n    **options\n  File \"celery/app/base.py\", line 662, in send_task\n    amqp.send_task_message(P, name, message, **options)\n  File \"celery/backends/rpc.py\", line 275, in on_task_call\n    maybe_declare(self.binding(producer.channel), retry=True)\n  File \"/opt/celery/kombu/kombu/messaging.py\", line 204, in _get_channel\n    channel = self._channel = channel()\n  File \"/opt/celery/py-amqp/amqp/connection.py\", line 272, in connect\n    self.transport.connect()\n  File \"/opt/celery/py-amqp/amqp/transport.py\", line 100, in connect\n    self._connect(self.host, self.port, self.connect_timeout)\n  File \"/opt/celery/py-amqp/amqp/transport.py\", line 141, in _connect\n    self.sock.connect(sa)\n  kombu.exceptions.OperationalError: [Errno 61] Connection refused\n</code></pre> <p>您也可以处理此错误：</p> <pre><code>&gt;&gt;&gt; from celery.utils.log import get_logger\n&gt;&gt;&gt; logger = get_logger(__name__)\n\n&gt;&gt;&gt; try:\n...     add.delay(2, 2)\n... except add.OperationalError as exc:\n...     logger.exception('Sending task raised: %r', exc)\n</code></pre> <p>Note</p> <p>对于 RabbitMQ，这些错误仅表示代理无法访问。当代理达到资源限制时，消息仍可能被静默丢弃。在 <code>broker_transport_options</code> 中启用 <code>confirm_publish</code> 来检测这种情况。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#calling-serializers","level":2,"title":"序列化器","text":"<p>安全</p> <p>pickle 模块允许执行任意函数，请参阅 安全指南。</p> <p>Celery 还附带了一个特殊的序列化器，它使用密码学来签名您的消息。</p> <p>客户端和工作器之间传输的数据需要被序列化，因此 Celery 中的每条消息都有一个 <code>content_type</code> 头，用于描述用于编码的序列化方法。</p> <p>默认的序列化器是 <code>JSON</code>，但您可以使用 <code>task_serializer</code> 设置来更改它，或者为每个单独的任务，甚至每条消息更改。</p> <p>内置支持 <code>JSON</code>、:mod:<code>pickle</code>、<code>YAML</code> 和 <code>msgpack</code>，您还可以通过将自定义序列化器注册到 Kombu 序列化器注册表中来添加自己的序列化器。</p> <p>每种选项都有其优缺点。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#json","level":3,"title":"json","text":"<p>JSON 在许多编程语言中都得到支持，现在是 Python 的标准部分（自 2.6 版起），并且解码速度相当快。</p> <p>JSON 的主要缺点是它限制您使用以下数据类型：字符串、Unicode、浮点数、布尔值、字典和列表。十进制数和日期明显缺失。</p> <p>二进制数据将使用 Base64 编码传输，与支持原生二进制类型的编码格式相比，传输数据的大小增加了 34%。</p> <p>但是，如果您的数据符合上述约束条件并且您需要跨语言支持，JSON 的默认设置可能是您的最佳选择。</p> <p>有关更多信息，请参阅 http://json.org。</p> <p>Note</p> <p>（来自 Python 官方文档 https://docs.python.org/3.6/library/json.html）JSON 键/值对中的键始终是 :class:<code>str</code> 类型。当字典转换为 JSON 时，字典的所有键都被强制转换为字符串。因此，如果字典被转换为 JSON 然后再转换回字典，该字典可能不等于原始字典。也就是说，如果 x 有非字符串键，则 <code>loads(dumps(x)) != x</code>。</p> <p>Warning</p> <p>在使用 :ref:<code>guide-canvas</code> 创建的更复杂的工作流中，观察到 JSON 序列化器由于递归引用而大幅增加消息大小，导致资源问题。pickle 序列化器不易受此影响，因此在某些情况下可能更可取。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#pickle","level":3,"title":"pickle","text":"<p>如果您不希望支持除 Python 之外的任何语言，那么使用 pickle 编码将为您提供所有内置 Python 数据类型（类实例除外）的支持，发送二进制文件时消息更小，并且比 JSON 处理速度略有提升。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#yaml","level":3,"title":"yaml","text":"<p>YAML 具有与 json 相同的许多特性，但它原生支持更多数据类型（包括日期、递归引用等）。</p> <p>但是，Python 的 YAML 库比 JSON 库要慢得多。</p> <p>如果您需要更具表现力的数据类型集并且需要保持跨语言兼容性，那么 YAML 可能比上述选项更适合。</p> <p>要使用它，请安装 Celery：</p> <pre><code>pip install celery[yaml]\n</code></pre> <p>有关更多信息，请参阅 http://yaml.org/。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#msgpack","level":3,"title":"msgpack","text":"<p>msgpack 是一种二进制序列化格式，其特性更接近 JSON。该格式压缩效果更好，因此解析和编码速度比 JSON 更快。</p> <p>要使用它，请安装 Celery：</p> <pre><code>pip install celery[msgpack]\n</code></pre> <p>有关更多信息，请参阅 http://msgpack.org/。</p> <p>要使用自定义序列化器，您需要将内容类型添加到 <code>accept_content</code>。默认情况下，只接受 JSON，包含其他内容头的任务将被拒绝。</p> <p>以下顺序用于确定发送任务时使用的序列化器：</p> <ol> <li><code>serializer</code> 执行选项。</li> <li><code>Task.serializer</code> 属性</li> <li><code>task_serializer</code> 设置。</li> </ol> <p>为单个任务调用设置自定义序列化器的示例：</p> <pre><code>&gt;&gt;&gt; add.apply_async((10, 10), serializer='json')\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#calling-compression","level":2,"title":"压缩","text":"<p>Celery 可以使用以下内置方案压缩消息：</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#brotli","level":3,"title":"<code>brotli</code>","text":"<p>brotli 针对 Web 进行了优化，特别适用于小型文本文档。它在提供静态内容（如字体和 HTML 页面）时最为有效。</p> <p>要使用它，请安装带有 brotli 支持的 Celery：</p> <pre><code>pip install celery[brotli]\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#bzip2","level":3,"title":"<code>bzip2</code>","text":"<p>bzip2 创建的文件比 gzip 更小，但压缩和解压缩速度明显比 gzip 慢。</p> <p>要使用它，请确保您的 Python 可执行文件已编译支持 bzip2。</p> <p>如果您遇到以下 <code>ImportError</code>：</p> <pre><code>&gt;&gt;&gt; import bz2\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nImportError: No module named 'bz2'\n</code></pre> <p>这意味着您应该重新编译支持 bzip2 的 Python 版本。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#gzip","level":3,"title":"<code>gzip</code>","text":"<p>gzip 适用于需要小内存占用的系统，使其成为内存受限系统的理想选择。它通常用于生成带有 \".tar.gz\" 扩展名的文件。</p> <p>要使用它，请确保您的 Python 可执行文件已编译支持 gzip。</p> <p>如果您遇到以下 <code>ImportError</code>：</p> <pre><code>&gt;&gt;&gt; import gzip\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nImportError: No module named 'gzip'\n</code></pre> <p>这意味着您应该重新编译支持 gzip 的 Python 版本。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#lzma","level":3,"title":"<code>lzma</code>","text":"<p>lzma 提供良好的压缩比，并以快速的压缩和解压缩速度执行，但代价是更高的内存使用量。</p> <p>要使用它，请确保您的 Python 可执行文件已编译支持 lzma，并且您的 Python 版本为 3.3 及以上。</p> <p>如果您遇到以下 <code>ImportError</code>：</p> <pre><code>&gt;&gt;&gt; import lzma\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nImportError: No module named 'lzma'\n</code></pre> <p>这意味着您应该重新编译支持 lzma 的 Python 版本。</p> <p>或者，您也可以使用以下命令安装向后移植版本：</p> <pre><code>pip install celery[lzma]\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#zlib","level":3,"title":"<code>zlib</code>","text":"<p>zlib 是 Deflate 算法的库形式抽象，在其 API 中同时支持 gzip 文件格式和轻量级流格式。它是许多软件系统的关键组件 - 仅举几例，如 Linux 内核和 Git 版本控制系统。</p> <p>要使用它，请确保您的 Python 可执行文件已编译支持 zlib。</p> <p>如果您遇到以下 <code>ImportError</code>：</p> <pre><code>&gt;&gt;&gt; import zlib\nTraceback (most recent call last):\nFile \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\nImportError: No module named 'zlib'\n</code></pre> <p>这意味着您应该重新编译支持 zlib 的 Python 版本。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#zstd","level":3,"title":"<code>zstd</code>","text":"<p>zstd 针对 zlib 级别的实时压缩场景和更好的压缩比。它由非常快速的熵阶段支持，由 Huff0 和 FSE 库提供。</p> <p>要使用它，请安装带有 zstd 支持的 Celery：</p> <pre><code>pip install celery[zstd]\n</code></pre> <p>以下顺序用于决定发送任务时使用的压缩方案：</p> <ol> <li><code>compression</code> 执行选项</li> <li><code>Task.compression</code> 属性</li> <li><code>task_compression</code> 设置</li> </ol> <p>示例指定调用任务时使用的压缩方案：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 2), compression='zlib')\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_10","level":2,"title":"连接","text":"<p>自动连接池支持</p> <p>自版本 2.3 起支持自动连接池，因此您无需手动处理连接和发布者来重用连接。</p> <p>自版本 2.5 起默认启用连接池。</p> <p>有关更多信息，请参阅 <code>broker_pool_limit</code> 设置。</p> <p>您可以通过创建发布者来手动处理连接：</p> <pre><code>numbers = [(2, 2), (4, 4), (8, 8), (16, 16)]\nresults = []\nwith add.app.pool.acquire(block=True) as connection:\n    with add.get_publisher(connection) as publisher:\n        try:\n            for i, j in numbers:\n                res = add.apply_async((i, j), publisher=publisher)\n                results.append(res)\nprint([res.get() for res in results])\n</code></pre> <p>不过这个特定示例更适合用组来表达：</p> <pre><code>&gt;&gt;&gt; from celery import group\n\n&gt;&gt;&gt; numbers = [(2, 2), (4, 4), (8, 8), (16, 16)]\n&gt;&gt;&gt; res = group(add.s(i, j) for i, j in numbers).apply_async()\n\n&gt;&gt;&gt; res.get()\n[4, 8, 16, 32]\n</code></pre>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_11","level":2,"title":"路由选项","text":"<p>Celery 可以将任务路由到不同的队列。</p> <p>简单的路由（名称 &lt;-&gt; 名称）可以通过使用 <code>queue</code> 选项来实现：：</p> <pre><code>add.apply_async(queue='priority.high')\n</code></pre> <p>然后您可以通过使用工作者的 <code>celery worker -Q</code> 参数将工作者分配给 <code>priority.high</code> 队列：</p> <pre><code>celery -A proj worker -l INFO -Q celery,priority.high\n</code></pre> <p>Quote</p> <p>在代码中硬编码队列名称不推荐，最佳实践是使用配置路由器（<code>task_routes</code>）。</p> <p>要了解更多关于路由的信息，请参阅 路由指南。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_12","level":2,"title":"结果选项","text":"<p>您可以使用 <code>task_ignore_result</code> 设置或 <code>ignore_result</code> 选项来启用或禁用结果存储：</p> <pre><code>&gt;&gt;&gt; result = add.apply_async((1, 2), ignore_result=True)\n&gt;&gt;&gt; result.get()\nNone\n\n&gt;&gt;&gt; # 不忽略结果（默认）\n...\n&gt;&gt;&gt; result = add.apply_async((1, 2), ignore_result=False)\n&gt;&gt;&gt; result.get()\n3\n</code></pre> <p>如果您想在结果后端存储有关任务的额外元数据，请将 <code>result_extended</code> 设置设为 <code>True</code>。</p> <p>有关任务的更多信息，请参阅 任务指南。</p>","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/calling/#_13","level":3,"title":"高级选项","text":"<p>这些选项适用于希望利用 AMQP 完整路由功能的高级用户。感兴趣的读者可以阅读 路由指南。</p> 选项 描述 <code>exchange</code> 要发送消息到的交换器名称（或 <code>Exchange</code>）。 <code>routing_key</code> 用于确定的路由键。 <code>priority</code> 介于 <code>0</code> 和 <code>255</code> 之间的数字，其中 <code>255</code> 是最高优先级。支持：RabbitMQ、Redis（优先级反转，0 为最高）。","path":["用户指南","调用"],"tags":[]},{"location":"user-guide/canvas/","level":1,"title":"画布：设计工作流","text":"","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_2","level":2,"title":"签名","text":"<p>您刚刚在 调用指南 指南中学习了如何使用任务的 <code>delay()</code> 方法来调用任务，这通常就是您所需要的全部，但有时您可能希望将任务调用的签名传递给另一个进程或作为另一个函数的参数。</p> <p><code>signature()</code> 包装了单个任务调用的参数、关键字参数和执行选项，使其可以传递给函数，甚至可以序列化并通过网络发送。</p> <ul> <li> <p>您可以使用任务名称创建 <code>add()</code> 任务的签名，如下所示：</p> <pre><code>&gt;&gt;&gt; from celery import signature\n&gt;&gt;&gt; signature('tasks.add', args=(2, 2), countdown=10)\ntasks.add(2, 2)\n</code></pre> <p>此任务具有 2 个参数（两个参数）的签名：<code>(2, 2)</code>，并将倒计时执行选项设置为 10。</p> </li> <li> <p>或者您可以使用任务的 <code>signature()</code> 方法创建一个：</p> <pre><code>&gt;&gt;&gt; add.signature((2, 2), countdown=10)\ntasks.add(2, 2)\n</code></pre> </li> <li> <p>还有一个使用星号参数的快捷方式：</p> <pre><code>&gt;&gt;&gt; add.s(2, 2)\ntasks.add(2, 2)\n</code></pre> </li> <li> <p>也支持关键字参数：</p> <pre><code>&gt;&gt;&gt; add.s(2, 2, debug=True)\ntasks.add(2, 2, debug=True)\n</code></pre> </li> <li> <p>从任何签名实例中，您可以检查不同的字段：</p> <pre><code>&gt;&gt;&gt; s = add.signature((2, 2), {'debug': True}, countdown=10)\n&gt;&gt;&gt; s.args\n(2, 2)\n&gt;&gt;&gt; s.kwargs\n{'debug': True}\n&gt;&gt;&gt; s.options\n{'countdown': 10}\n</code></pre> </li> <li> <p>它支持 <code>delay()</code>、<code>apply_async()</code> 等的\"调用 API\"，包括直接调用（<code>__call__</code>）。</p> <p>调用签名将在当前进程中内联执行任务：</p> <pre><code>&gt;&gt;&gt; add(2, 2)\n4\n&gt;&gt;&gt; add.s(2, 2)()\n4\n</code></pre> <p><code>delay()</code> 是我们喜爱的 <code>apply_async()</code> 快捷方式，接受星号参数：</p> <pre><code>&gt;&gt;&gt; result = add.delay(2, 2)\n&gt;&gt;&gt; result.get()\n4\n</code></pre> <p><code>apply_async()</code> 接受与 <code>app.Task.apply_async()</code> 方法相同的参数：</p> <pre><code>&gt;&gt;&gt; add.apply_async(args, kwargs, **options)\n&gt;&gt;&gt; add.signature(args, kwargs, **options).apply_async()\n\n&gt;&gt;&gt; add.apply_async((2, 2), countdown=1)\n&gt;&gt;&gt; add.signature((2, 2), countdown=1).apply_async()\n</code></pre> </li> <li> <p>您不能使用 <code>s()</code> 定义选项，但链式 <code>set()</code> 调用可以解决这个问题：</p> <pre><code>&gt;&gt;&gt; add.s(2, 2).set(countdown=1)\nproj.tasks.add(2, 2)\n</code></pre> </li> </ul>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_3","level":3,"title":"部分签名","text":"<p>使用签名，您可以在工作进程中执行任务：</p> <pre><code>&gt;&gt;&gt; add.s(2, 2).delay()\n&gt;&gt;&gt; add.s(2, 2).apply_async(countdown=1)\n</code></pre> <p>或者您可以在当前进程中直接调用它：</p> <pre><code>&gt;&gt;&gt; add.s(2, 2)()\n4\n</code></pre> <p>向 <code>apply_async</code>/<code>delay</code> 指定额外的参数、关键字参数或选项会创建部分签名：</p> <ul> <li> <p>添加的任何参数都将前置到签名中的参数之前：</p> <pre><code>&gt;&gt;&gt; partial = add.s(2)          # 不完整的签名\n&gt;&gt;&gt; partial.delay(4)            # 4 + 2\n&gt;&gt;&gt; partial.apply_async((4,))   # 相同\n</code></pre> </li> <li> <p>添加的任何关键字参数将与签名中的关键字参数合并，新的关键字参数优先：</p> <pre><code>&gt;&gt;&gt; s = add.s(2, 2)\n&gt;&gt;&gt; s.delay(debug=True)                    # -&gt; add(2, 2, debug=True)\n&gt;&gt;&gt; s.apply_async(kwargs={'debug': True})  # 相同\n</code></pre> </li> <li> <p>添加的任何选项将与签名中的选项合并，新的选项优先：</p> <pre><code>&gt;&gt;&gt; s = add.signature((2, 2), countdown=10)\n&gt;&gt;&gt; s.apply_async(countdown=1)  # 倒计时现在是 1\n</code></pre> </li> </ul> <p>您还可以克隆签名以创建衍生签名：</p> <pre><code>&gt;&gt;&gt; s = add.s(2)\nproj.tasks.add(2)\n\n&gt;&gt;&gt; s.clone(args=(4,), kwargs={'debug': True})\nproj.tasks.add(4, 2, debug=True)\n</code></pre>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_4","level":3,"title":"不可变性","text":"<p>部分签名旨在与回调一起使用，任何链接的任务或和弦回调都将使用父任务的结果来应用。有时您希望指定一个不接受额外参数的回调，在这种情况下，您可以将签名设置为不可变：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 2), link=reset_buffers.signature(immutable=True))\n</code></pre> <p><code>.si()</code> 快捷方式也可以用于创建不可变签名：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 2), link=reset_buffers.si())\n</code></pre> <p>当签名不可变时，只能设置执行选项，因此无法使用部分参数/关键字参数调用签名。</p> <p>Note</p> <p>在本教程中，我有时使用前缀运算符 <code>~</code> 来操作签名。您可能不应该在生产代码中使用它，但在 Python shell 中进行实验时，它是一个方便的快捷方式：</p> <pre><code>&gt;&gt;&gt; ~sig\n\n&gt;&gt;&gt; # 等同于\n&gt;&gt;&gt; sig.delay().get()\n</code></pre>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_5","level":3,"title":"回调","text":"<p>可以使用 <code>apply_async()</code> 的 <code>link</code> 参数将回调添加到任何任务：</p> <pre><code>add.apply_async((2, 2), link=other_task.s())\n</code></pre> <p>回调仅在任务成功退出时应用，并且将使用父任务的返回值作为参数来应用。</p> <p>正如我之前提到的，您添加到签名的任何参数都将前置到签名本身指定的参数之前！</p> <p>如果您有签名：</p> <pre><code>&gt;&gt;&gt; sig = add.s(10)\n</code></pre> <p>那么 <code>sig.delay(result)</code> 变为：</p> <pre><code>&gt;&gt;&gt; add.apply_async(args=(result, 10))\n</code></pre> <p>...</p> <p>现在让我们使用部分参数调用我们的 <code>add()</code> 任务并添加回调：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 2), link=add.s(8))\n</code></pre> <p>正如预期的那样，这将首先启动一个计算 <code>2 + 2</code> 的任务，然后启动另一个计算 <code>4 + 8</code> 的任务。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_6","level":2,"title":"原语","text":"原语 描述 <code>group</code> group原语是一个签名，它接受一个任务列表，这些任务应该并行应用。 <code>chain</code> chain原语允许我们将签名链接在一起，以便一个接一个地调用，本质上形成一个回调*链*。 <code>chord</code> chord就像一个带有回调的group。一个chord由一个头部组和一个主体组成，其中主体是在头部所有任务完成后应该执行的任务。 <code>map</code>  map原语的工作方式类似于内置的 <code>map</code> 函数，但会创建一个临时任务，其中参数列表被应用到任务上。例如，<code>task.map([1, 2])</code> -- 导致调用单个任务，按顺序将参数应用到任务函数，结果是：  <pre><code>res = [task(1), task(2)]\n</code></pre> <code>starmap</code>  工作方式与map完全相同，只是参数以 <code>*args</code> 的形式应用。 例如 <code>add.starmap([(2, 2), (4, 4)])</code> 导致单个任务调用：  <pre><code>res = [add(2, 2), add(4, 4)]\n</code></pre> <code>chunks</code>  分块将长参数列表分成多个部分，例如操作：  <pre><code>&gt;&gt;&gt; items = zip(range(1000), range(1000))  # 1000个项目\n&gt;&gt;&gt; add.chunks(items, 10)\n</code></pre>  将项目列表分成10个一组，产生100个任务（每个任务按顺序处理10个项目）。  <p>这些原语本身也是签名对象，因此它们可以以多种方式组合来构成复杂的工作流。</p> <p>以下是一些示例：</p> <ul> <li> <p>简单链</p> <p>这是一个简单的链，第一个任务执行并将其返回值传递给链中的下一个任务，依此类推。</p> <pre><code>&gt;&gt;&gt; from celery import chain\n\n&gt;&gt;&gt; # 2 + 2 + 4 + 8\n&gt;&gt;&gt; res = chain(add.s(2, 2), add.s(4), add.s(8))()\n&gt;&gt;&gt; res.get()\n16\n</code></pre> <p>也可以使用管道符号编写：</p> <pre><code>&gt;&gt;&gt; (add.s(2, 2) | add.s(4) | add.s(8))().get()\n16\n</code></pre> </li> <li> <p>不可变签名</p> <p>签名可以是部分的，因此可以向现有参数添加参数，但您可能并不总是需要这样，例如，如果您不想要链中前一个任务的结果。</p> <p>在这种情况下，您可以将签名标记为不可变，这样参数就不能被更改：</p> <pre><code>&gt;&gt;&gt; add.signature((2, 2), immutable=True)\n</code></pre> <p>还有一个<code>.si()</code>快捷方式，这是创建签名的首选方式：</p> <pre><code>&gt;&gt;&gt; add.si(2, 2)\n</code></pre> <p>现在您可以创建一个独立任务的链：</p> <pre><code>&gt;&gt;&gt; res = (add.si(2, 2) | add.si(4, 4) | add.si(8, 8))()\n&gt;&gt;&gt; res.get()\n16\n\n&gt;&gt;&gt; res.parent.get()\n8\n\n&gt;&gt;&gt; res.parent.parent.get()\n4\n</code></pre> </li> <li> <p>简单组</p> <p>您可以轻松创建一组并行执行的任务：</p> <pre><code>&gt;&gt;&gt; from celery import group\n&gt;&gt;&gt; res = group(add.s(i, i) for i in range(10))()\n&gt;&gt;&gt; res.get(timeout=1)\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n</code></pre> </li> <li> <p>简单和弦</p> <p>chord原语使我们能够添加一个回调，当组中的所有任务执行完成时调用。这对于那些不是令人尴尬的并行的算法通常是必需的：</p> <pre><code>&gt;&gt;&gt; from celery import chord\n&gt;&gt;&gt; res = chord((add.s(i, i) for i in range(10)), tsum.s())()\n&gt;&gt;&gt; res.get()\n90\n</code></pre> <p>上面的示例创建了10个并行启动的任务，当所有任务完成后，返回值被组合成一个列表并发送到<code>tsum</code>任务。</p> <p>chord的主体也可以是不可变的，这样组的返回值就不会传递给回调：</p> <pre><code>&gt;&gt;&gt; chord((import_contact.s(c) for c in contacts), notify_complete.si(import_id)).apply_async()\n</code></pre> <p>注意上面使用了<code>.si</code>；这会创建一个不可变签名，意味着传递的任何新参数（包括前一个任务的返回值）都将被忽略。</p> </li> <li> <p>通过组合让您大开眼界</p> <p>链也可以是部分的：</p> <pre><code>&gt;&gt;&gt; c1 = (add.s(4) | mul.s(8))\n\n# (16 + 4) * 8\n&gt;&gt;&gt; res = c1(16)\n&gt;&gt;&gt; res.get()\n160\n</code></pre> <p>这意味着您可以组合链：</p> <pre><code># ((4 + 16) * 2 + 4) * 8\n&gt;&gt;&gt; c2 = (add.s(4, 16) | mul.s(2) | (add.s(4) | mul.s(8)))\n\n&gt;&gt;&gt; res = c2()\n&gt;&gt;&gt; res.get()\n352\n</code></pre> <p>将组与另一个任务链接在一起会自动将其升级为chord：</p> <pre><code>&gt;&gt;&gt; c3 = (group(add.s(i, i) for i in range(10)) | tsum.s())\n&gt;&gt;&gt; res = c3()\n&gt;&gt;&gt; res.get()\n90\n</code></pre> <p>组和chord也接受部分参数，因此在链中，前一个任务的返回值会转发给组中的所有任务：</p> <pre><code>&gt;&gt;&gt; new_user_workflow = (create_user.s() | group(import_contacts.s(), send_welcome_email.s()))\n... new_user_workflow.delay(username='artv', first='Art', last='Vandelay', email='art@vandelay.com')\n</code></pre> <p>如果您不想将参数转发给组，那么您可以使组中的签名不可变：</p> <pre><code>&gt;&gt;&gt; res = (add.s(4, 4) | group(add.si(i, i) for i in range(10)))()\n&gt;&gt;&gt; res.get()\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n\n&gt;&gt;&gt; res.parent.get()\n8\n</code></pre> </li> </ul> <p>Warning</p> <p>对于更复杂的工作流，已观察到默认的JSON序列化器由于递归引用而显著增加消息大小，导致资源问题。pickle序列化器不容易受到此问题的影响，因此在这样的情况下可能更可取。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#chains","level":3,"title":"Chains","text":"<p>任务可以链接在一起：当任务成功返回时调用链接的任务：</p> <pre><code>&gt;&gt;&gt; res = add.apply_async((2, 2), link=mul.s(16))\n&gt;&gt;&gt; res.get()\n4\n</code></pre> <p>链接的任务将以其父任务的结果作为第一个参数应用。在上面的例子中，结果是4，这将导致 <code>mul(4, 16)</code>。</p> <p>结果将跟踪原始任务调用的任何子任务，这可以从结果实例中访问：</p> <pre><code>&gt;&gt;&gt; res.children\n[&lt;AsyncResult: 8c350acf-519d-4553-8a53-4ad3a5c5aeb4&gt;]\n\n&gt;&gt;&gt; res.children[0].get()\n64\n</code></pre> <p>结果实例还有一个 <code>collect()</code> 方法，它将结果视为图，使您能够迭代结果：</p> <pre><code>&gt;&gt;&gt; list(res.collect())\n[(&lt;AsyncResult: 7b720856-dc5f-4415-9134-5c89def5664e&gt;, 4), (&lt;AsyncResult: 8c350acf-519d-4553-8a53-4ad3a5c5aeb4&gt;, 64)]\n</code></pre> <p>默认情况下，如果图未完全形成（其中一个任务尚未完成），<code>collect()</code> 方法将引发 <code>IncompleteStream</code> 异常，但您也可以获取图的中间表示：</p> <pre><code>&gt;&gt;&gt; for result, value in res.collect(intermediate=True):\n...\n</code></pre> <p>您可以根据需要链接任意多个任务，签名也可以链接：</p> <pre><code>&gt;&gt;&gt; s = add.s(2, 2)\n&gt;&gt;&gt; s.link(mul.s(4))\n&gt;&gt;&gt; s.link(log_result.s())\n</code></pre> <p>您还可以使用 <code>on_error</code> 方法添加错误回调：</p> <pre><code>&gt;&gt;&gt; add.s(2, 2).on_error(log_error.s()).delay()\n</code></pre> <p>当签名被应用时，这将导致以下 <code>.apply_async</code> 调用：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 2), link_error=log_error.s())\n</code></pre> <p>工作进程实际上不会将错误回调作为任务调用，而是直接调用错误回调函数，以便可以将原始请求、异常和回溯对象传递给它。</p> <p>以下是一个错误回调的示例：</p> <pre><code>import os\n\nfrom proj.celery import app\n\n@app.task\ndef log_error(request, exc, traceback):\n    with open(os.path.join('/var/errors', request.id), 'a') as fh:\n        print('--\\n\\n{0} {1} {2}'.format(\n            request.id, exc, traceback), file=fh)\n</code></pre> <p>为了使链接任务更容易，有一个特殊的签名 <code>chain()</code> 可以让您将任务链接在一起：</p> <pre><code>&gt;&gt;&gt; from celery import chain\n&gt;&gt;&gt; from proj.tasks import add, mul\n\n&gt;&gt;&gt; # (4 + 4) * 8 * 10\n&gt;&gt;&gt; res = chain(add.s(4, 4), mul.s(8), mul.s(10))\nproj.tasks.add(4, 4) | proj.tasks.mul(8) | proj.tasks.mul(10)\n</code></pre> <p>调用链将在当前进程中调用任务，并返回链中最后一个任务的结果：</p> <pre><code>&gt;&gt;&gt; res = chain(add.s(4, 4), mul.s(8), mul.s(10))()\n&gt;&gt;&gt; res.get()\n640\n</code></pre> <p>它还设置 <code>parent</code> 属性，以便您可以沿着链向上工作以获取中间结果：</p> <pre><code>&gt;&gt;&gt; res.parent.get()\n64\n\n&gt;&gt;&gt; res.parent.parent.get()\n8\n\n&gt;&gt;&gt; res.parent.parent\n&lt;AsyncResult: eeaad925-6778-4ad1-88c8-b2a63d017933&gt;\n</code></pre> <p>也可以使用 <code>|</code>（管道）运算符创建链：</p> <pre><code>&gt;&gt;&gt; (add.s(2, 2) | mul.s(8) | mul.s(10)).apply_async()\n</code></pre>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#idtask-id","level":4,"title":"任务 ID（Task ID）","text":"<p>链将继承链中最后一个任务的任务ID。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#graphs","level":4,"title":"图（Graphs）","text":"<p>此外，您可以将结果图作为 <code>DependencyGraph</code> 来处理：</p> <pre><code>&gt;&gt;&gt; res = chain(add.s(4, 4), mul.s(8), mul.s(10))()\n\n&gt;&gt;&gt; res.parent.parent.graph\n285fa253-fcf8-42ef-8b95-0078897e83e6(1)\n    463afec2-5ed4-4036-b22d-ba067ec64f52(0)\n872c3995-6fa0-46ca-98c2-5a19155afcf0(2)\n    285fa253-fcf8-42ef-8b95-0078897e83e6(1)\n        463afec2-5ed4-4036-b22d-ba067ec64f52(0)\n</code></pre> <p>您甚至可以将这些图转换为dot格式：</p> <pre><code>&gt;&gt;&gt; with open('graph.dot', 'w') as fh:\n...     res.parent.parent.graph.to_dot(fh)\n</code></pre> <p>并创建图像：</p> <pre><code>dot -Tpng graph.dot -o graph.png\n</code></pre> <p></p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#canvas-group","level":3,"title":"Groups","text":"<p>Note</p> <p>与和弦类似，在组中使用的任务不能忽略其结果。。</p> <p>组可以用于并行执行多个任务。</p> <p><code>group</code> 函数接受一个签名列表：</p> <pre><code>&gt;&gt;&gt; from celery import group\n&gt;&gt;&gt; from proj.tasks import add\n\n&gt;&gt;&gt; group(add.s(2, 2), add.s(4, 4))\n(proj.tasks.add(2, 2), proj.tasks.add(4, 4))\n</code></pre> <p>如果您调用组，任务将在当前进程中依次应用，并返回一个 <code>GroupResult</code> 实例，可用于跟踪结果或了解有多少任务已准备就绪等：</p> <pre><code>&gt;&gt;&gt; g = group(add.s(2, 2), add.s(4, 4))\n&gt;&gt;&gt; res = g()\n&gt;&gt;&gt; res.get()\n[4, 8]\n</code></pre> <p>组也支持迭代器：</p> <pre><code>&gt;&gt;&gt; group(add.s(i, i) for i in range(100))()\n</code></pre> <p>组是一个签名对象，因此可以与其他签名结合使用。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_7","level":4,"title":"回调和错误处理","text":"<p>组也可以链接回调和错误回调签名，但由于组不是真正的任务，只是将链接的任务传递给其封装的签名，因此行为可能有些令人惊讶。这意味着组的返回值不会被收集并传递给链接的回调签名。此外，链接任务不保证它仅在所有组任务完成后才激活。例如，以下使用简单 <code>add(a, b)</code> 任务的代码片段是有问题的，因为链接的 <code>add.s()</code> 签名不会像预期的那样接收最终的组结果。</p> <pre><code>&gt;&gt;&gt; g = group(add.s(2, 2), add.s(4, 4))\n&gt;&gt;&gt; g.link(add.s())\n&gt;&gt;&gt; res = g()\n[4, 8]\n</code></pre> <p>请注意，前两个任务的最终结果已返回，但回调签名将在后台运行并引发异常，因为它没有收到期望的两个参数。</p> <p>组错误回调也会传递给封装的签名，这可能导致仅链接一次的错误回调在组中多个任务失败时被多次调用。 例如，以下使用引发异常的 <code>fail()</code> 任务的代码片段可以预期为组中运行的每个失败任务调用一次 <code>log_error()</code> 签名。</p> <pre><code>&gt;&gt;&gt; g = group(fail.s(), fail.s())\n&gt;&gt;&gt; g.link_error(log_error.s())\n&gt;&gt;&gt; res = g()\n</code></pre> <p>考虑到这一点，通常建议创建幂等或计数任务，这些任务能够容忍被重复调用以用作错误回调。</p> <p>这些用例更适合由 <code>chord</code> 类处理，该类在某些后端实现中受支持。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_8","level":4,"title":"结果","text":"<p>组任务也返回一个特殊的结果，这个结果的工作方式类似于普通任务结果， 只是它作用于整个组：</p> <pre><code>&gt;&gt;&gt; from celery import group\n&gt;&gt;&gt; from tasks import add\n\n&gt;&gt;&gt; job = group([add.s(2, 2), add.s(4, 4), add.s(8, 8), add.s(16, 16), add.s(32, 32)])\n\n&gt;&gt;&gt; result = job.apply_async()\n\n&gt;&gt;&gt; result.ready()  # 所有子任务都完成了吗？\nTrue\n&gt;&gt;&gt; result.successful() # 所有子任务都成功了吗？\nTrue\n&gt;&gt;&gt; result.get()\n[4, 8, 16, 32, 64]\n</code></pre> <p><code>GroupResult</code> 接受一个 <code>AsyncResult</code> 实例列表，并像操作单个任务一样操作它们。</p> <p>它支持以下操作：</p> 方法 描述 <code>successful()</code> 如果所有子任务都成功完成（例如，没有引发异常），则返回 <code>True</code>。 <code>failed()</code> 如果有任何子任务失败，则返回 <code>True</code>。 <code>waiting()</code> 如果有任何子任务尚未就绪，则返回 <code>True</code>。 <code>ready()</code> 如果所有子任务都已就绪，则返回 <code>True</code>。 <code>completed_count()</code> 返回已完成的子任务数量。请注意，在此上下文中 <code>complete</code> 意味着 <code>successful</code>。换句话说，此方法的返回值是 <code>successful</code> 任务的数量。 <code>revoke()</code> 撤销所有子任务。 <code>join()</code> 收集所有子任务的结果，并按它们被调用的顺序返回（作为列表）。","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_9","level":4,"title":"展开","text":"<p>当链接时，包含单个签名的组将展开为单个签名。这意味着以下组可能会根据组中项目的数量向链传递结果列表或单个结果。</p> <pre><code>&gt;&gt;&gt; from celery import chain, group\n&gt;&gt;&gt; from tasks import add\n&gt;&gt;&gt; chain(add.s(2, 2), group(add.s(1)), add.s(1))\nadd(2, 2) | add(1) | add(1)\n&gt;&gt;&gt; chain(add.s(2, 2), group(add.s(1), add.s(2)), add.s(1))\nadd(2, 2) | %add((add(1), add(2)), 1)\n</code></pre> <p>这意味着您应该小心，并确保 <code>add()</code> 任务可以接受列表或单个项目作为输入，如果您计划将其用作更大画布的一部分。</p> <p>Warning</p> <p>在 Celery 4.x 中，由于一个错误，下面的组不会展开为链，而是画布将升级为和弦。</p> <pre><code>&gt;&gt;&gt; from celery import chain, group\n&gt;&gt;&gt; from tasks import add\n&gt;&gt;&gt; chain(group(add.s(1, 1)), add.s(2))\n%add([add(1, 1)], 2)\n</code></pre> <p>在 Celery 5.x 中，此错误已修复，组正确展开为单个签名。</p> <pre><code>&gt;&gt;&gt; from celery import chain, group\n&gt;&gt;&gt; from tasks import add\n&gt;&gt;&gt; chain(group(add.s(1, 1)), add.s(2))\nadd(1, 1) | add(2)\n</code></pre>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#chords","level":3,"title":"Chords","text":"<p>Note</p> <p>在 chord 中使用的任务不能忽略它们的结果。如果在你的 chord 中任何任务（header 或 body）的结果后端被禁用。Chords 目前不支持 RPC 结果后端。</p> <p>Chord 是一个只有在组中所有任务都执行完成后才会执行的任务。</p> <p>让我们计算表达式 <code>1 + 1 + 2 + 2 + 3 + 3 ... n + n</code> 到一百位数字的和。</p> <p>首先你需要两个任务，<code>add()</code> 和 <code>tsum()</code>（<code>sum()</code> 已经是一个标准函数）：</p> <pre><code>@app.task\ndef add(x, y):\n    return x + y\n\n@app.task\ndef tsum(numbers):\n    return sum(numbers)\n</code></pre> <p>现在你可以使用 chord 来并行计算每个加法步骤，然后得到结果数字的总和：</p> <pre><code>&gt;&gt;&gt; from celery import chord\n&gt;&gt;&gt; from tasks import add, tsum\n\n&gt;&gt;&gt; chord(add.s(i, i) for i in range(100))(tsum.s()).get()\n9900\n</code></pre> <p>这显然是一个非常人为的例子，消息传递和同步的开销使得这比其 Python 对应版本慢很多：</p> <pre><code>&gt;&gt;&gt; sum(i + i for i in range(100))\n</code></pre> <p>同步步骤成本很高，所以你应该尽可能避免使用 chords。尽管如此，chord 仍然是工具箱中一个强大的原语，因为同步是许多并行算法所需的步骤。</p> <p>让我们分解 chord 表达式：</p> <pre><code>&gt;&gt;&gt; callback = tsum.s()\n&gt;&gt;&gt; header = [add.s(i, i) for i in range(100)]\n&gt;&gt;&gt; result = chord(header)(callback)\n&gt;&gt;&gt; result.get()\n9900\n</code></pre> <p>记住，回调只能在 header 中的所有任务都返回后才能执行。header 中的每个步骤都作为一个任务执行，并行地，可能在不同的节点上。然后使用 header 中每个任务的返回值来应用回调。<code>chord()</code> 返回的任务 id 是回调的 id，所以你可以等待它完成并获取最终的返回值。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_10","level":4,"title":"错误处理","text":"<p>那么如果其中一个任务引发异常会发生什么？</p> <p>Chord 回调结果将转换到失败状态，错误被设置为 <code>ChordError</code> 异常：</p> <pre><code>&gt;&gt;&gt; c = chord([add.s(4, 4), raising_task.s(), add.s(8, 8)])\n&gt;&gt;&gt; result = c()\n&gt;&gt;&gt; result.get()\n</code></pre> <pre><code>Traceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"*/celery/result.py\", line 120, in get\n    interval=interval)\n  File \"*/celery/backends/amqp.py\", line 150, in wait_for\n    raise meta['result']\ncelery.exceptions.ChordError: Dependency 97de6f3f-ea67-4517-a21c-d867c61fcb47\n    raised ValueError('something something',)\n</code></pre> <p>虽然跟踪回溯可能因使用的结果后端而异，但你可以看到错误描述包括失败任务的 id 和原始异常的字符串表示。你也可以在 <code>result.traceback</code> 中找到原始跟踪回溯。</p> <p>请注意，其余任务仍将执行，所以第三个任务（<code>add.s(8, 8)</code>）即使中间任务失败也会执行。此外，<code>ChordError</code> 只显示首先（按时间）失败的任务：它不尊重 header 组的顺序。</p> <p>因此，要在 chord 失败时执行操作，你可以将 errback 附加到 chord 回调：</p> <pre><code>@app.task\ndef on_chord_error(request, exc, traceback):\n    print('Task {0!r} raised error: {1!r}'.format(request.id, exc))\n</code></pre> <pre><code>&gt;&gt;&gt; c = (group(add.s(i, i) for i in range(10)) | tsum.s().on_error(on_chord_error.s())).delay()\n</code></pre> <p>Chords 可以有回调（callback）和错误回调（errback）签名链接到它们，这解决了将签名链接到组的一些问题。这样做会将提供的签名链接到 chord 的 body，期望在 body 完成时优雅地调用回调一次，或者在 chord header 或 body 中的任何任务失败时调用错误回调一次。</p> <p>这种行为可以通过使用 task_allow_error_cb_on_chord_header 标志来操作，以允许对 chord header 进行错误处理。启用此标志将导致 chord header 调用 body 的错误回调（默认行为）以及 chord header 中任何失败的任务。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_11","level":4,"title":"重要注意事项","text":"<p>在 chord 中使用的任务不能忽略它们的结果。实际上这意味着你必须启用 <code>result_backend</code> 才能使用 chords。此外，如果在你的配置中 <code>task_ignore_result</code> 设置为 <code>True</code>，请确保要在 chord 中使用的各个任务都定义为 <code>ignore_result=False</code>。这适用于 Task 子类和装饰的任务。</p> <p>Task 子类示例：</p> <pre><code>class MyTask(Task):\n    ignore_result = False\n</code></pre> <p>装饰任务示例：</p> <pre><code>@app.task(ignore_result=False)\ndef another_task(project):\n    do_something()\n</code></pre> <p>默认情况下，同步步骤是通过让一个循环任务每秒轮询组的完成情况，在准备好时调用签名来实现的。</p> <p>示例实现：</p> <pre><code>from celery import maybe_signature\n\n@app.task(bind=True)\ndef unlock_chord(self, group, callback, interval=1, max_retries=None):\n    if group.ready():\n        return maybe_signature(callback).delay(group.join())\n    raise self.retry(countdown=interval, max_retries=max_retries)\n</code></pre> <p>这被除 Redis、Memcached 和 DynamoDB 之外的所有结果后端使用：它们在 header 中的每个任务之后递增一个计数器，然后在计数器超过集合中的任务数时应用回调。</p> <p>Redis、Memcached 和 DynamoDB 的方法是一个更好的解决方案，但不容易在其他后端中实现（欢迎建议！）。</p> <p>Note</p> <p>Chords 在 Redis 2.2 版本之前不能正常工作；你需要升级到至少 redis-server 2.2 才能使用它们。</p> <p>Note</p> <p>如果你使用 Redis 结果后端和 chords，并且还重写了 <code>Task.after_return()</code> 方法，你需要确保调用 super 方法，否则 chord 回调将不会被应用。</p> <pre><code>def after_return(self, *args, **kwargs):\n    do_something()\n    super().after_return(*args, **kwargs)\n</code></pre>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#map-starmap","level":3,"title":"Map &amp; Starmap","text":"<p><code>map</code> 和 <code>starmap</code> 是内置任务，它们为序列中的每个元素调用提供的调用任务。</p> <p>它们与 <code>group</code> 的不同之处在于：</p> <ul> <li>只发送一个任务消息</li> <li>操作是顺序执行的</li> </ul> <p>例如使用 <code>map</code>：</p> <pre><code>&gt;&gt;&gt; from proj.tasks import add\n\n&gt;&gt;&gt; ~tsum.map([list(range(10)), list(range(100))])\n[45, 4950]\n</code></pre> <p>等同于有一个任务执行：</p> <pre><code>@app.task\ndef temp():\n    return [tsum(range(10)), tsum(range(100))]\n</code></pre> <p>使用 <code>starmap</code>：</p> <pre><code>&gt;&gt;&gt; ~add.starmap(zip(range(10), range(10)))\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n</code></pre> <p>等同于有一个任务执行：</p> <pre><code>@app.task\ndef temp():\n    return [add(i, i) for i in range(10)]\n</code></pre> <p><code>map</code> 和 <code>starmap</code> 都是签名对象，因此可以像其他签名一样使用，并可以在组等中组合使用，例如在10秒后调用starmap：</p> <pre><code>&gt;&gt;&gt; add.starmap(zip(range(10), range(10))).apply_async(countdown=10)\n</code></pre>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#chunks","level":3,"title":"Chunks","text":"<p>分块允许您将可迭代的工作分成多个部分，这样如果您有一百万个对象，您可以创建10个任务，每个任务处理十万个对象。</p> <p>有些人可能担心对任务进行分块会导致并行性降低，但对于繁忙的集群来说，这种情况很少发生，并且在实践中，由于您避免了消息传递的开销，它可能会显著提高性能。</p> <p>要创建分块的签名，您可以使用 <code>chunks()</code>：</p> <pre><code>&gt;&gt;&gt; add.chunks(zip(range(100), range(100)), 10)\n</code></pre> <p>与 <code>group</code> 类似，当调用时，发送分块消息的操作将在当前进程中发生：</p> <pre><code>&gt;&gt;&gt; from proj.tasks import add\n\n&gt;&gt;&gt; res = add.chunks(zip(range(100), range(100)), 10)()\n&gt;&gt;&gt; res.get()\n[[0, 2, 4, 6, 8, 10, 12, 14, 16, 18],\n [20, 22, 24, 26, 28, 30, 32, 34, 36, 38],\n [40, 42, 44, 46, 48, 50, 52, 54, 56, 58],\n [60, 62, 64, 66, 68, 70, 72, 74, 76, 78],\n [80, 82, 84, 86, 88, 90, 92, 94, 96, 98],\n [100, 102, 104, 106, 108, 110, 112, 114, 116, 118],\n [120, 122, 124, 126, 128, 130, 132, 134, 136, 138],\n [140, 142, 144, 146, 148, 150, 152, 154, 156, 158],\n [160, 162, 164, 166, 168, 170, 172, 174, 176, 178],\n [180, 182, 184, 186, 188, 190, 192, 194, 196, 198]]\n</code></pre> <p>而调用 <code>.apply_async</code> 将创建一个专用任务，以便各个任务在工作者中应用：</p> <pre><code>&gt;&gt;&gt; add.chunks(zip(range(100), range(100)), 10).apply_async()\n</code></pre> <p>您还可以将分块转换为组：</p> <pre><code>&gt;&gt;&gt; group = add.chunks(zip(range(100), range(100)), 10).group()\n</code></pre> <p>并使用组将每个任务的倒计时按增量为一进行偏移：</p> <pre><code>&gt;&gt;&gt; group.skew(start=1, stop=10)()\n</code></pre> <p>这意味着第一个任务的倒计时为一秒，第二个任务的倒计时为两秒，依此类推。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_12","level":2,"title":"标记","text":"<p>Stamping API 的目标是为签名及其组件提供标记能力，以便于调试信息的目的。例如，当画布（canvas）是一个复杂结构时，可能需要标记已形成结构的部分或全部元素。当嵌套组展开或链元素被替换时，复杂性会进一步增加。在这种情况下，可能需要了解某个元素属于哪个组或处于什么嵌套级别。这需要一个遍历画布元素并用特定元数据标记它们的机制。标记 API 基于访问者模式（Visitor pattern）实现这一功能。</p> <p>例如，</p> <pre><code>&gt;&gt;&gt; sig1 = add.si(2, 2)\n&gt;&gt;&gt; sig1_res = sig1.freeze()\n&gt;&gt;&gt; g = group(sig1, add.si(3, 3))\n&gt;&gt;&gt; g.stamp(stamp='your_custom_stamp')\n&gt;&gt;&gt; res = g.apply_async()\n&gt;&gt;&gt; res.get(timeout=TIMEOUT)\n[4, 6]\n&gt;&gt;&gt; sig1_res._get_task_meta()['stamp']\n['your_custom_stamp']\n</code></pre> <p>将初始化一个组 <code>g</code> 并用标记 <code>your_custom_stamp</code> 标记其组件。</p> <p>为了使此功能有用，您需要将 <code>result_extended</code> 配置选项设置为 <code>True</code> 或指令 <code>result_extended = True</code>。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_13","level":3,"title":"画布标记","text":"<p>我们还可以使用自定义标记逻辑来标记画布，使用访问者类 <code>StampingVisitor</code> 作为自定义标记访问者的基类。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_14","level":3,"title":"自定义标记","text":"<p>如果需要更复杂的标记逻辑，可以基于访问者模式实现自定义标记行为。 实现此自定义逻辑的类必须继承 <code>StampingVisitor</code> 并实现适当的方法。</p> <p>例如，以下示例 <code>InGroupVisitor</code> 将通过标签 <code>in_group</code> 标记位于某个组内的任务。</p> <pre><code>class InGroupVisitor(StampingVisitor):\n    def __init__(self):\n        self.in_group = False\n\n    def on_group_start(self, group, **headers) -&gt; dict:\n        self.in_group = True\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n\n    def on_group_end(self, group, **headers) -&gt; None:\n        self.in_group = False\n\n    def on_chain_start(self, chain, **headers) -&gt; dict:\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n\n    def on_signature(self, sig, **headers) -&gt; dict:\n        return {\"in_group\": [self.in_group], \"stamped_headers\": [\"in_group\"]}\n</code></pre> <p>以下示例展示了另一个自定义标记访问者，它为所有任务标记一个自定义的 <code>monitoring_id</code>，该 ID 可以代表外部监控系统的 UUID 值，通过包含此 ID 的访问者实现来跟踪任务执行。这个 <code>monitoring_id</code> 可以是一个随机生成的 UUID，或者是外部监控系统使用的 span id 的唯一标识符等。</p> <pre><code>class MonitoringIdStampingVisitor(StampingVisitor):\n    def on_signature(self, sig, **headers) -&gt; dict:\n        return {'monitoring_id': uuid4().hex}\n</code></pre> <p>Tip</p> <p><code>on_signature()</code>（或任何其他访问者方法）返回的字典中的 <code>stamped_headers</code> 键是可选的：</p> <pre><code># 方法 1：不使用 stamped_headers - 所有键都被视为标记\ndef on_signature(self, sig, **headers) -&gt; dict:\n    return {'monitoring_id': uuid4().hex}  # monitoring_id 成为标记\n\n# 方法 2：使用 stamped_headers - 只有列出的键是标记\ndef on_signature(self, sig, **headers) -&gt; dict:\n    return {\n        'monitoring_id': uuid4().hex,      # 这将是一个标记\n        'other_data': 'value',             # 这将不是标记\n        'stamped_headers': ['monitoring_id']  # 只有 monitoring_id 被标记\n    }\n</code></pre> <p>如果未指定 <code>stamped_headers</code> 键，标记访问者将假定返回字典中的所有键都是标记头。</p> <p>接下来，让我们看看如何使用 <code>MonitoringIdStampingVisitor</code> 示例标记访问者。</p> <pre><code>sig_example = signature('t1')\nsig_example.stamp(visitor=MonitoringIdStampingVisitor())\n\ngroup_example = group([signature('t1'), signature('t2')])\ngroup_example.stamp(visitor=MonitoringIdStampingVisitor())\n\nchord_example = chord([signature('t1'), signature('t2')], signature('t3'))\nchord_example.stamp(visitor=MonitoringIdStampingVisitor())\n\nchain_example = chain(signature('t1'), group(signature('t2'), signature('t3')), signature('t4'))\nchain_example.stamp(visitor=MonitoringIdStampingVisitor())\n</code></pre> <p>最后，需要说明的是，上述示例中的每个监控 ID 标记在任务之间都是不同的。</p>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/canvas/#_15","level":3,"title":"回调标记","text":"<p>标记 API 还支持隐式标记回调。这意味着当回调添加到任务时，标记访问者也会应用于回调。</p> <p>Warning</p> <p>回调必须在标记之前链接到签名。</p> <p>例如，让我们检查以下使用隐式方法的自定义标记访问者，其中所有返回的字典键都会自动被视为标记头，而无需显式指定 <code>stamped_headers</code>。</p> <pre><code>class CustomStampingVisitor(StampingVisitor):\n    def on_signature(self, sig, **headers) -&gt; dict:\n        # 'header' 将自动被视为标记头\n        # 无需指定 'stamped_headers': ['header']\n        return {'header': 'value'}\n\n    def on_callback(self, callback, **header) -&gt; dict:\n        # 'on_callback' 将自动被视为标记头\n        return {'on_callback': True}\n\n    def on_errback(self, errback, **header) -&gt; dict:\n        # 'on_errback' 将自动被视为标记头\n        return {'on_errback': True}\n</code></pre> <p>此自定义标记访问者将用 <code>{'header': 'value'}</code> 标记签名、回调和错误回调，并分别用 <code>{'on_callback': True}</code> 和 <code>{'on_errback': True}</code> 标记回调和错误回调，如下所示。</p> <pre><code>c = chord([add.s(1, 1), add.s(2, 2)], xsum.s())\ncallback = signature('sig_link')\nerrback = signature('sig_link_error')\nc.link(callback)\nc.link_error(errback)\nc.stamp(visitor=CustomStampingVisitor())\n</code></pre> <p>此示例将产生以下标记：</p> <pre><code>&gt;&gt;&gt; c.options\n{'header': 'value', 'stamped_headers': ['header']}\n&gt;&gt;&gt; c.tasks.tasks[0].options\n{'header': 'value', 'stamped_headers': ['header']}\n&gt;&gt;&gt; c.tasks.tasks[1].options\n{'header': 'value', 'stamped_headers': ['header']}\n&gt;&gt;&gt; c.body.options\n{'header': 'value', 'stamped_headers': ['header']}\n&gt;&gt;&gt; c.body.options['link'][0].options\n{'header': 'value', 'on_callback': True, 'stamped_headers': ['header', 'on_callback']}\n&gt;&gt;&gt; c.body.options['link_error'][0].options\n{'header': 'value', 'on_errback': True, 'stamped_headers': ['header', 'on_errback']}\n</code></pre>","path":["用户指南","画布：设计工作流"],"tags":[]},{"location":"user-guide/configuration/","level":1,"title":"配置和默认值","text":"<p>本文档描述了可用的配置选项。</p> <p>如果您使用默认加载器，必须创建 <code>celeryconfig.py</code> 模块，并确保它在 Python 路径中可用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_2","level":2,"title":"示例配置文件","text":"<p>这是一个示例配置文件，可以帮助您入门。它应该包含运行基本 Celery 设置所需的所有内容。</p> <pre><code>## Broker 设置。\nbroker_url = 'amqp://guest:guest@localhost:5672//'\n\n# Celery worker 启动时要导入的模块列表。\nimports = ('myapp.tasks',)\n\n## 使用数据库存储任务状态和结果。\nresult_backend = 'db+sqlite:///results.db'\n\ntask_annotations = {'tasks.add': {'rate_limit': '10/s'}}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_3","level":2,"title":"新的小写设置","text":"<p>版本 4.0 引入了新的小写设置和设置组织方式。</p> <p>与先前版本的主要区别，除了小写名称外，还包括一些前缀的重命名，例如 <code>celery_beat</code> 改为 <code>beat</code>，<code>celeryd</code> 改为 <code>worker</code>，并且大多数顶级 <code>celery</code> 设置已移至新的 <code>task</code> 前缀中。</p> <p>Warning</p> <p>Celery 在 Celery 6.0 之前仍能读取旧的配置文件。之后，对旧配置文件的支持将被移除。我们提供了 <code>celery upgrade</code> 命令，应该可以处理大多数情况。</p> <p>请尽快迁移到新的配置方案。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_4","level":2,"title":"配置选项","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_5","level":3,"title":"通用设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#accept_content","level":4,"title":"<code>accept_content</code>","text":"<p>默认值：<code>{'json'}</code>（Set、List 或 Tuple）。</p> <p>允许的内容类型/序列化器的白名单。</p> <p>如果接收到不在该列表中的消息，则该消息将被丢弃并报错。</p> <p>默认情况下仅启用 json，但可以添加任何内容类型，包括 pickle 和 yaml；在这种情况下，请确保不受信任的方无法访问您的代理。</p> <p>示例：</p> <pre><code># 使用序列化器名称\naccept_content = ['json']\n\n# 或实际的内容类型（MIME）\naccept_content = ['application/json']\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_accept_content","level":4,"title":"<code>result_accept_content</code>","text":"<p>默认值：<code>None</code>（可以设置为 Set、List 或 Tuple）。</p> <p>允许用于结果后端的内容类型/序列化器的白名单。</p> <p>如果接收到不在该列表中的消息，则该消息将被丢弃并报错。</p> <p>默认情况下，它与 <code>accept_content</code> 使用相同的序列化器。但是，可以为结果后端的接受内容指定不同的序列化器。通常在使用了签名消息传递且结果以未签名方式存储在结果后端时需要这样做。</p> <p>示例：</p> <pre><code># 使用序列化器名称\nresult_accept_content = ['json']\n\n# 或实际的内容类型（MIME）\nresult_accept_content = ['application/json']\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_6","level":3,"title":"时间和日期设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#enable_utc","level":4,"title":"<code>enable_utc</code>","text":"<p>默认值：自版本 3.0 起默认启用。</p> <p>如果启用，消息中的日期和时间将被转换为使用 UTC 时区。</p> <p>注意：运行 Celery 版本低于 2.5 的工作进程将假定所有消息使用本地时区，因此只有在所有工作进程都已升级后才启用此设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#timezone","level":4,"title":"<code>timezone</code>","text":"<p>默认值：<code>\"UTC\"</code>。</p> <p>配置 Celery 使用自定义时区。时区值可以是 ZoneInfo 库支持的任何时区。</p> <p>如果未设置，则使用 UTC 时区。为了向后兼容，还有一个 <code>enable_utc</code> 设置，当此设置设为 false 时，将使用系统本地时区。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_7","level":3,"title":"任务设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_annotations","level":4,"title":"<code>task_annotations</code>","text":"<p>默认值：<code>None</code>。</p> <p>此设置可用于从配置中重写任何任务属性。该设置可以是一个字典，或者是一个过滤任务并返回要更改的属性映射的注释对象列表。</p> <p>这将更改 <code>tasks.add</code> 任务的 <code>rate_limit</code> 属性：</p> <pre><code>task_annotations = {'tasks.add': {'rate_limit': '10/s'}}\n</code></pre> <p>或者为所有任务更改相同的属性：</p> <pre><code>task_annotations = {'*': {'rate_limit': '10/s'}}\n</code></pre> <p>您也可以更改方法，例如 <code>on_failure</code> 处理程序：</p> <pre><code>def my_on_failure(self, exc, task_id, args, kwargs, einfo):\n    print('Oh no! Task failed: {0!r}'.format(exc))\n\ntask_annotations = {'*': {'on_failure': my_on_failure}}\n</code></pre> <p>如果您需要更多灵活性，可以使用对象而不是字典来选择要注释的任务：</p> <pre><code>class MyAnnotate:\n\n    def annotate(self, task):\n        if task.name.startswith('tasks.'):\n            return {'rate_limit': '10/s'}\n\ntask_annotations = (MyAnnotate(), {other,})\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_compression","level":4,"title":"<code>task_compression</code>","text":"<p>默认值：<code>None</code></p> <p>用于任务消息的默认压缩方式。可以是 <code>gzip</code>、<code>bzip2</code>（如果可用），或者在 Kombu 压缩注册表中注册的任何自定义压缩方案。</p> <p>默认是发送未压缩的消息。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_protocol","level":4,"title":"<code>task_protocol</code>","text":"<p>默认值：2（自 4.0 版本起）。</p> <p>设置用于发送任务的默认任务消息协议版本。支持的协议：1 和 2。</p> <p>协议 2 由 3.1.24 和 4.x+ 版本支持。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_serializer","level":4,"title":"<code>task_serializer</code>","text":"<p>默认值：<code>\"json\"</code>（自 4.0 版本起，早期版本为：pickle）。</p> <p>标识要使用的默认序列化方法的字符串。可以是 <code>json</code>（默认）、<code>pickle</code>、<code>yaml</code>、<code>msgpack</code>，或者在 <code>kombu.serialization.registry</code> 中注册的任何自定义序列化方法。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_publish_retry","level":4,"title":"<code>task_publish_retry</code>","text":"<p>默认值：启用。</p> <p>决定在连接丢失或其他连接错误的情况下是否重试发布任务消息。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_publish_retry_policy","level":4,"title":"<code>task_publish_retry_policy</code>","text":"<p>默认值：请参阅 重试策略。</p> <p>定义在连接丢失或其他连接错误的情况下重试发布任务消息时的默认策略。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_8","level":3,"title":"任务执行设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_always_eager","level":4,"title":"<code>task_always_eager</code>","text":"<p>默认值：Disabled。</p> <p>如果设置为 <code>True</code>，所有任务将在本地通过阻塞方式执行，直到任务返回。<code>apply_async()</code> 和 <code>Task.delay()</code> 将返回一个 <code>celery.result.EagerResult</code> 实例，该实例模拟了 <code>celery.result.AsyncResult</code> 的 API 和行为，只是结果已经被评估。</p> <p>也就是说，任务将在本地执行，而不是被发送到队列中。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_eager_propagates","level":4,"title":"<code>task_eager_propagates</code>","text":"<p>默认值：Disabled。</p> <p>如果设置为 <code>True</code>，急切执行的任务（通过 <code>task.apply()</code> 应用，或者当 <code>task_always_eager</code> 设置启用时）将传播异常。</p> <p>这与始终使用 <code>throw=True</code> 运行 <code>apply()</code> 相同。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_store_eager_result","level":4,"title":"<code>task_store_eager_result</code>","text":"<p>默认值：Disabled。</p> <p>如果设置为 <code>True</code>，并且 <code>task_always_eager</code> 为 <code>True</code> 且 <code>task_ignore_result</code> 为 <code>False</code>，急切执行的任务结果将被保存到后端。</p> <p>默认情况下，即使 <code>task_always_eager</code> 设置为 <code>True</code> 且 <code>task_ignore_result</code> 设置为 <code>False</code>，结果也不会被保存。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_remote_tracebacks","level":4,"title":"<code>task_remote_tracebacks</code>","text":"<p>默认值：Disabled。</p> <p>如果启用，任务结果将在重新引发任务错误时包含工作进程的堆栈信息。</p> <p>这需要 <code>tblib</code> 库，可以使用 <code>pip</code> 安装：</p> <pre><code>pip install celery[tblib]\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_ignore_result","level":4,"title":"<code>task_ignore_result</code>","text":"<p>默认值：Disabled。</p> <p>是否存储任务返回值（墓碑）。如果您仍然希望存储错误，只是不存储成功的返回值，可以设置 <code>task_store_errors_even_if_ignored</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_store_errors_even_if_ignored","level":4,"title":"<code>task_store_errors_even_if_ignored</code>","text":"<p>默认值：Disabled。</p> <p>如果设置，工作进程将把所有任务错误存储在结果存储中，即使 <code>celery.app.task.Task.ignore_result</code> 已启用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_track_started","level":4,"title":"<code>task_track_started</code>","text":"<p>默认值：Disabled。</p> <p>如果设置为 <code>True</code>，任务在工作进程执行时将报告其状态为 'started'。默认值为 <code>False</code>，因为正常行为是不报告这种粒度的状态。任务要么是待处理、已完成，要么是等待重试。拥有 'started' 状态对于长时间运行的任务以及需要报告当前正在运行什么任务的情况很有用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_time_limit","level":4,"title":"<code>task_time_limit</code>","text":"<p>默认值：无时间限制。</p> <p>任务硬时间限制（以秒为单位）。当超过此限制时，处理该任务的工作进程将被终止并替换为新进程。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_allow_error_cb_on_chord_header","level":4,"title":"<code>task_allow_error_cb_on_chord_header</code>","text":"<p>默认值：Disabled。</p> <p>启用此标志将允许将错误回调链接到和弦头部，默认情况下在使用 <code>link_error()</code> 时不会链接，并且如果头部中的任何任务失败，将阻止和弦主体的执行。</p> <p>考虑以下禁用标志的画布（默认行为）：</p> <pre><code>header = group([t1, t2])\nbody = t3\nc = chord(header, body)\nc.link_error(error_callback_sig)\n</code></pre> <p>如果任何头部任务失败（<code>t1</code> 或 <code>t2</code>），默认情况下，和弦主体（<code>t3</code>）将不会执行，并且 <code>error_callback_sig</code> 将被调用一次（针对主体）。</p> <p>启用此标志将通过以下方式改变上述行为：</p> <ol> <li><code>error_callback_sig</code> 将被链接到 <code>t1</code> 和 <code>t2</code>（以及 <code>t3</code>）。</li> <li>如果任何头部任务失败，<code>error_callback_sig</code> 将被调用针对每个失败的头部任务和 <code>body</code>（即使主体没有运行）。</li> </ol> <p>现在考虑启用标志后的以下画布：</p> <pre><code>header = group([failingT1, failingT2])\nbody = t3\nc = chord(header, body)\nc.link_error(error_callback_sig)\n</code></pre> <p>如果所有头部任务都失败（<code>failingT1</code> 和 <code>failingT2</code>），那么和弦主体（<code>t3</code>）将不会执行，并且 <code>error_callback_sig</code> 将被调用3次（两次针对头部，一次针对主体）。</p> <p>最后，考虑启用标志后的以下画布：</p> <pre><code>header = group([failingT1, failingT2])\nbody = t3\nupgraded_chord = chain(header, body)\nupgraded_chord.link_error(error_callback_sig)\n</code></pre> <p>此画布的行为将与之前的完全相同，因为 <code>chain</code> 将在内部升级为 <code>chord</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_soft_time_limit","level":4,"title":"<code>task_soft_time_limit</code>","text":"<p>默认值：无软时间限制。</p> <p>任务软时间限制（以秒为单位）。</p> <p>当超过此限制时，将引发 <code>SoftTimeLimitExceeded</code> 异常。例如，任务可以捕获此异常以在硬时间限制到来之前进行清理：</p> <pre><code>from celery.exceptions import SoftTimeLimitExceeded\n\n@app.task\ndef mytask():\n    try:\n        return do_work()\n    except SoftTimeLimitExceeded:\n        cleanup_in_a_hurry()\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_acks_late","level":4,"title":"<code>task_acks_late</code>","text":"<p>默认值：Disabled。</p> <p>延迟确认意味着任务消息将在任务执行后被确认，而不是正好在执行前（默认行为）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_acks_on_failure_or_timeout","level":4,"title":"<code>task_acks_on_failure_or_timeout</code>","text":"<p>默认值：Enabled</p> <p>启用后，所有任务的消息都将被确认，即使它们失败或超时。</p> <p>配置此设置仅适用于在执行后被确认的任务，并且仅当 <code>task_acks_late</code> 已启用时。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_reject_on_worker_lost","level":4,"title":"<code>task_reject_on_worker_lost</code>","text":"<p>默认值：Disabled。</p> <p>即使 <code>task_acks_late</code> 已启用，当执行任务的工作进程突然退出或被信号中断（例如，<code>KILL</code>/<code>INT</code> 等）时，工作进程仍将确认任务。</p> <p>将此设置为 true 允许消息重新排队，以便任务可以由同一工作进程或其他工作进程再次执行。</p> <p>Warning</p> <p>启用此功能可能导致消息循环；请确保您知道自己在做什么。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_rate_limit","level":4,"title":"<code>task_default_rate_limit</code>","text":"<p>默认值：无速率限制。</p> <p>任务的全局默认速率限制。</p> <p>此值用于没有自定义速率限制的任务</p> <p>.. seealso:</p> <pre><code>`worker_disable_rate_limits` 设置可以禁用所有速率限制。\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_9","level":3,"title":"任务结果后端设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_backend","level":4,"title":"<code>result_backend</code>","text":"<p>默认值：默认未启用任何结果后端。</p> <p>用于存储任务结果（墓碑）的后端。可以是以下之一：</p> 后端 rpc database redis cache mongodb cassandra elasticsearch ironcache couchbase arangodb couchdb cosmosdbsql(实验性) filesystem consul azureblockblob s3 gcs <p>Warning</p> <p>虽然AMQP结果后端非常高效，但您必须确保 您只接收一次相同的结果。请参阅：:doc:<code>userguide/calling</code>)。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_backend_always_retry","level":4,"title":"<code>result_backend_always_retry</code>","text":"<p>默认值：<code>False</code></p> <p>如果启用，后端将在发生可恢复异常时尝试重试，而不是传播异常。它将在两次重试之间使用指数退避睡眠时间。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_backend_max_sleep_between_retries_ms","level":4,"title":"<code>result_backend_max_sleep_between_retries_ms</code>","text":"<p>默认值：10000</p> <p>这指定了两次后端操作重试之间的最大睡眠时间。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_backend_base_sleep_between_retries_ms","level":4,"title":"<code>result_backend_base_sleep_between_retries_ms</code>","text":"<p>默认值：10</p> <p>这指定了两次后端操作重试之间的基本睡眠时间量。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_backend_max_retries","level":4,"title":"<code>result_backend_max_retries</code>","text":"<p>默认值：Inf</p> <p>这是在可恢复异常情况下的最大重试次数。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_backend_thread_safe","level":4,"title":"<code>result_backend_thread_safe</code>","text":"<p>默认值：False</p> <p>如果为True，则后端对象在线程间共享。这对于使用共享连接池而不是为每个线程创建连接可能很有用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_backend_transport_options","level":4,"title":"<code>result_backend_transport_options</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>传递给底层传输的额外选项字典。</p> <p>有关支持的选项（如果有），请参阅您的传输用户手册。</p> <p>设置可见性超时的示例（Redis和SQS传输支持）：</p> <pre><code>result_backend_transport_options = {'visibility_timeout': 18000}  # 5小时\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_serializer","level":4,"title":"<code>result_serializer</code>","text":"<p>默认值：自4.0起为 <code>json</code>（早期：pickle）。</p> <p>结果序列化格式。</p> <p>有关支持的序列化格式的信息，请参阅：<code>calling-serializers</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_compression","level":4,"title":"<code>result_compression</code>","text":"<p>默认值：无压缩。</p> <p>用于任务结果的可选压缩方法。支持与 <code>task_compression</code>设置相同的选项。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_extended","level":4,"title":"<code>result_extended</code>","text":"<p>默认值：<code>False</code></p> <p>启用将扩展的任务结果属性（名称、参数、关键字参数、工作进程、重试次数、队列、投递信息）写入后端。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_expires","level":4,"title":"<code>result_expires</code>","text":"<p>默认值：1天后过期。</p> <p>存储的任务墓碑将被删除的时间（以秒为单位，或 <code>datetime.timedelta</code> 对象）。</p> <p>一个内置的周期性任务将在此时间后删除结果（<code>celery.backend_cleanup</code>），假设<code>celery beat</code>已启用。该任务每天凌晨4点运行。</p> <p><code>None</code>或0的值意味着结果永不过期（取决于后端规范）。</p> <p>Note</p> <p>目前这仅适用于AMQP、数据库、缓存、Couchbase、文件系统和Redis后端。</p> <p>当使用数据库或文件系统后端时，<code>celery beat</code>必须运行才能使结果过期。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_cache_max","level":4,"title":"<code>result_cache_max</code>","text":"<p>默认值：默认禁用。</p> <p>启用客户端结果缓存。</p> <p>这对于旧的已弃用的'amqp'后端可能很有用，其中结果在一个结果实例消费后立即不可用。</p> <p>这是在淘汰较旧结果之前要缓存的结果总数。值为 <code>0</code> 或 <code>None</code> 表示无限制，值为 <code>-1</code> 将禁用缓存。</p> <p>默认禁用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_chord_join_timeout","level":4,"title":"<code>result_chord_join_timeout</code>","text":"<p>默认值：3.0。</p> <p>在 chord 内连接组结果的超时时间（秒，int/float）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_chord_retry_interval","level":4,"title":"<code>result_chord_retry_interval</code>","text":"<p>默认值：1.0。</p> <p>重试 chord 任务的默认间隔。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#override_backends","level":4,"title":"<code>override_backends</code>","text":"<p>默认值：默认禁用。</p> <p>实现后端的类的路径。</p> <p>允许覆盖后端实现。如果您需要存储有关已执行任务的额外元数据，覆盖重试策略等，这可能很有用。</p> <p>示例：</p> <pre><code>override_backends = {\"db\": \"custom_module.backend.class\"}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_10","level":3,"title":"数据库后端设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#url","level":4,"title":"数据库 URL 示例","text":"<p>要使用数据库后端，您必须配置 <code>result_backend</code> 设置，使用连接 URL 和 <code>db+</code> 前缀：</p> <pre><code>result_backend = 'db+scheme://user:password@host:port/dbname'\n</code></pre> <p>示例：</p> <pre><code># sqlite (文件名)\nresult_backend = 'db+sqlite:///results.sqlite'\n\n# mysql\nresult_backend = 'db+mysql://scott:tiger@localhost/foo'\n\n# postgresql\nresult_backend = 'db+postgresql://scott:tiger@localhost/mydatabase'\n\n# oracle\nresult_backend = 'db+oracle://scott:tiger@127.0.0.1:1521/sidname'\n</code></pre> <p>请参阅 支持的数据库 获取支持的数据库列表，以及 连接字符串 获取有关连接字符串的更多信息（这是 URI 中 <code>db+</code> 前缀之后的部分）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#database_create_tables_at_setup","level":4,"title":"<code>database_create_tables_at_setup</code>","text":"<p>默认值：默认为 True。</p> <ul> <li>如果为 <code>True</code>，Celery 将在设置期间在数据库中创建表。</li> <li>如果为 <code>False</code>，Celery 将延迟创建表，即等待第一个任务执行后再创建表。</li> </ul> <p>Note</p> <p>在 celery 5.5 之前，表是延迟创建的，即相当于 <code>database_create_tables_at_setup</code> 设置为 False。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#database_engine_options","level":4,"title":"<code>database_engine_options</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>要指定额外的 SQLAlchemy 数据库引擎选项，您可以使用 <code>database_engine_options</code> 设置：</p> <pre><code># echo 启用 SQLAlchemy 的详细日志记录。\napp.conf.database_engine_options = {'echo': True}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#database_short_lived_sessions","level":4,"title":"<code>database_short_lived_sessions</code>","text":"<p>默认值：默认禁用。</p> <p>短生命周期会话默认禁用。如果启用，它们会显著降低性能，尤其是在处理大量任务的系统上。此选项对于低流量工作器很有用，这些工作器由于缓存的数据库连接因不活动而过时而遇到错误。例如，间歇性错误如 <code>(OperationalError) (2006, 'MySQL server has gone away')</code> 可以通过启用短生命周期会话来修复。此选项仅影响数据库后端。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#database_table_schemas","level":4,"title":"<code>database_table_schemas</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>当 SQLAlchemy 配置为结果后端时，Celery 会自动创建两个表来存储任务的结果元数据。此设置允许您自定义表的模式：</p> <pre><code># 为数据库结果后端使用自定义模式。\ndatabase_table_schemas = {\n    'task': 'celery',\n    'group': 'celery',\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#database_table_names","level":4,"title":"<code>database_table_names</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>当 SQLAlchemy 配置为结果后端时，Celery 会自动创建两个表来存储任务的结果元数据。此设置允许您自定义表名：</p> <pre><code># 为数据库结果后端使用自定义表名。\ndatabase_table_names = {\n    'task': 'myapp_taskmeta',\n    'group': 'myapp_groupmeta',\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#rpc","level":3,"title":"RPC 后端设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#result_persistent","level":4,"title":"<code>result_persistent</code>","text":"<p>默认值：默认禁用（瞬态消息）。</p> <p>如果设置为 <code>True</code>，结果消息将是持久化的。这意味着在代理重启后消息不会丢失。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_11","level":4,"title":"配置示例","text":"<pre><code>result_backend = 'rpc://'\nresult_persistent = False\n</code></pre> <p>请注意：使用此后端可能会触发 <code>celery.backends.rpc.BacklogLimitExceeded</code> 异常，如果任务墓碑过于陈旧。</p> <p>例如：</p> <pre><code>for i in range(10000):\n    r = debug_task.delay()\n\nprint(r.state)  # 这会引发 celery.backends.rpc.BacklogLimitExceeded\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_12","level":3,"title":"缓存后端设置","text":"<p>Note</p> <p>缓存后端支持 <code>pylibmc</code> 和 <code>python-memcached</code> 库。只有在 <code>pylibmc</code> 未安装时才会使用后者。</p> <p>使用单个 Memcached 服务器：</p> <pre><code>result_backend = 'cache+memcached://127.0.0.1:11211/'\n</code></pre> <p>使用多个 Memcached 服务器：</p> <pre><code>result_backend = \"cache+memcached://172.19.26.240:11211;172.19.26.242:11211/\".strip()\n</code></pre> <p>\"memory\" 后端仅将缓存存储在内存中：</p> <pre><code>result_backend = 'cache'\ncache_backend = 'memory'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cache_backend_options","level":4,"title":"<code>cache_backend_options</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>您可以使用 <code>cache_backend_options</code> 设置来配置 <code>pylibmc</code> 选项：</p> <pre><code>cache_backend_options = {\n    'binary': True,\n    'behaviors': {'tcp_nodelay': True},\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cache_backend","level":4,"title":"<code>cache_backend</code>","text":"<p>此设置不再用于 Celery 的内置后端，因为现在可以直接在 <code>result_backend</code> 设置中指定缓存后端。</p> <p>Note</p> <p><code>django-celery-results</code> 库使用 <code>cache_backend</code> 来选择 Django 缓存。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#mongodb","level":3,"title":"MongoDB 后端设置","text":"<p>Note</p> <p>MongoDB 后端需要 <code>pymongo</code> 库：http://github.com/mongodb/mongo-python-driver/tree/master</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#mongodb_backend_settings","level":4,"title":"mongodb_backend_settings","text":"<p>这是一个支持以下键的字典：</p> 键 描述 database 要连接的数据库名称。默认为 <code>celery</code>。 taskmeta_collection 存储任务元数据的集合名称。默认为 <code>celery_taskmeta</code>。 max_pool_size 作为 max_pool_size 传递给 PyMongo 的 Connection 或 MongoClient 构造函数。这是在给定时间保持与 MongoDB 的 TCP 连接的最大数量。如果打开的连接数超过 max_pool_size， 套 接字将在释放时关闭。默认为 10。 options 传递给 mongodb 连接构造函数的附加关键字参数。请参阅 <code>pymongo</code> 文档以查看支持的参数列表。 <p>Note</p> <p>在 pymongo&gt;=4.14 中，选项是区分大小写的，而之前是不区分大小写的。请参阅 <code>pymongo.mongo_client.MongoClient</code> 来确定正确的大小写。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_13","level":4,"title":"示例配置","text":"<pre><code>result_backend = 'mongodb://localhost:27017/'\nmongodb_backend_settings = {\n    'database': 'mydb',\n    'taskmeta_collection': 'my_taskmeta_collection',\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#conf-redis-result-backend","level":3,"title":"Redis 后端设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#url_1","level":4,"title":"配置后端 URL","text":"<p>Note</p> <p>Redis 后端需要 <code>redis</code> 库。</p> <p>要安装此包，请使用 <code>pip</code>:</p> <pre><code>pip install celery[redis]\n</code></pre> <p>此后端需要将 <code>result_backend</code> 设置设置为 Redis 或 Redis over TLS URL:</p> <pre><code>result_backend = 'redis://username:password@host:port/db'\n</code></pre> <p>例如:</p> <pre><code>result_backend = 'redis://localhost/0'\n</code></pre> <p>等同于:</p> <pre><code>result_backend = 'redis://'\n</code></pre> <p>使用 <code>rediss://</code> 协议通过 TLS 连接到 redis:</p> <pre><code>result_backend = 'rediss://username:password@host:port/db?ssl_cert_reqs=required'\n</code></pre> <p>请注意，<code>ssl_cert_reqs</code> 字符串应为 <code>required</code>、<code>optional</code> 或 <code>none</code> 之一（尽管为了向后兼容旧版 Celery，该字符串也可能是 <code>CERT_REQUIRED</code>、<code>CERT_OPTIONAL</code>、<code>CERT_NONE</code> 之一，但这些值仅适用于 Celery，不直接适用于 Redis）。</p> <p>如果应使用 Unix 套接字连接，URL 需要采用以下格式:</p> <pre><code>result_backend = 'socket:///path/to/redis.sock'\n</code></pre> <p>URL 的字段定义如下：</p> 字段 描述 <code>username</code>  用于连接数据库的用户名。 请注意，这仅在 Redis&gt;=6.0 和安装了 py-redis&gt;=3.4.0 时受支持。 如果您使用较旧的数据库版本或较旧的客户端版本， 可以省略用户名：  <pre><code>result_backend = 'redis://:password@host:port/db'\n</code></pre> <code>password</code> 用于连接数据库的密码。 <code>host</code> Redis 服务器的主机名或 IP 地址（例如，<code>localhost</code>）。 <code>port</code> Redis 服务器的端口。默认为 6379。 <code>db</code> 要使用的数据库编号。默认为 0。db 可以包含可选的前导斜杠。 <p>使用 TLS 连接（协议为 <code>rediss://</code>）时，您可以将 <code>broker_use_ssl</code> 中的所有值作为查询参数传递。证书路径必须进行 URL 编码，并且 <code>ssl_cert_reqs</code> 是必需的。示例：</p> <pre><code>result_backend = 'rediss://:password@host:port/db?\\\nssl_cert_reqs=required\\\n&amp;ssl_ca_certs=%2Fvar%2Fssl%2Fmyca.pem\\                  # /var/ssl/myca.pem\n&amp;ssl_certfile=%2Fvar%2Fssl%2Fredis-server-cert.pem\\     # /var/ssl/redis-server-cert.pem\n&amp;ssl_keyfile=%2Fvar%2Fssl%2Fprivate%2Fworker-key.pem'   # /var/ssl/private/worker-key.pem\n</code></pre> <p>请注意，<code>ssl_cert_reqs</code> 字符串应为 <code>required</code>、<code>optional</code> 或 <code>none</code> 之一（尽管为了向后兼容，该字符串也可能是 <code>CERT_REQUIRED</code>、<code>CERT_OPTIONAL</code>、<code>CERT_NONE</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_backend_health_check_interval","level":4,"title":"<code>redis_backend_health_check_interval</code>","text":"<p>默认：未配置</p> <p>Redis 后端支持健康检查。此值必须设置为一个整数，其值为健康检查之间的秒数。如果在健康检查期间遇到 ConnectionError 或 TimeoutError，连接将被重新建立，命令将精确重试一次。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_backend_use_ssl","level":4,"title":"<code>redis_backend_use_ssl</code>","text":"<p>默认：禁用。</p> <p>Redis 后端支持 SSL。此值必须以字典形式设置。有效的键值对与 <code>broker_use_ssl</code> 下的 <code>redis</code> 子节中提到的相同。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_backend_credential_provider","level":4,"title":"<code>redis_backend_credential_provider</code>","text":"<p>默认：禁用。</p> <p>Redis 后端支持凭据提供程序。此值必须设置为类路径字符串或类实例的形式。例如 <code>mymodule.myfile.myclass</code> 有关更多详细信息，请参阅 <code>RedisCredentialProvider</code> 文档。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_max_connections","level":4,"title":"<code>redis_max_connections</code>","text":"<p>默认：无限制。</p> <p>用于发送和检索结果的 Redis 连接池中可用的最大连接数。</p> <p>Warning</p> <p>如果并发连接数超过最大值，Redis 将引发 <code>ConnectionError</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_socket_connect_timeout","level":4,"title":"<code>redis_socket_connect_timeout</code>","text":"<p>默认：<code>None</code></p> <p>从结果后端连接到 Redis 的套接字超时时间，以秒为单位（整数/浮点数）</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_socket_timeout","level":4,"title":"<code>redis_socket_timeout</code>","text":"<p>默认：120.0 秒。</p> <p>与 Redis 服务器进行读/写操作的套接字超时时间，以秒为单位（整数/浮点数），由 redis 结果后端使用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_retry_on_timeout","level":4,"title":"<code>redis_retry_on_timeout</code>","text":"<p>默认：<code>False</code></p> <p>用于在发生 TimeoutError 时重试与 Redis 服务器的读/写操作，由 redis 结果后端使用。如果使用 Unix 套接字连接 Redis，不应设置此变量。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_socket_keepalive","level":4,"title":"<code>redis_socket_keepalive</code>","text":"<p>默认：<code>False</code></p> <p>套接字 TCP keepalive，用于保持与 Redis 服务器的连接健康，由 redis 结果后端使用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis_client_name","level":4,"title":"<code>redis_client_name</code>","text":"<p>默认：<code>None</code></p> <p>设置结果后端使用的 Redis 连接的客户端名称。这有助于在 Redis 监控工具中识别连接。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandraastradb","level":3,"title":"Cassandra/AstraDB 后端设置","text":"<p>Note</p> <p>此 Cassandra 后端驱动程序需要 <code>cassandra-driver</code>。</p> <p>此后端可以指常规的 Cassandra 安装或托管的 Astra DB 实例。根据具体情况，必须提供 <code>cassandra_servers</code> 和 <code>cassandra_secure_bundle_path</code> 设置中的一个（但不能同时提供两个）。</p> <p>要安装，请使用 <code>pip</code>：</p> <pre><code>pip install celery[cassandra]\n</code></pre> <p>此后端需要设置以下配置指令。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_servers","level":4,"title":"<code>cassandra_servers</code>","text":"<p>默认值：<code>[]</code>（空列表）。</p> <p><code>host</code> Cassandra 服务器列表。连接到 Cassandra 集群时必须提供此设置。传递此设置与 <code>cassandra_secure_bundle_path</code> 严格互斥。示例：：</p> <pre><code>cassandra_servers = ['localhost']\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_secure_bundle_path","level":4,"title":"<code>cassandra_secure_bundle_path</code>","text":"<p>默认值：None。</p> <p>连接到 Astra DB 实例的 secure-connect-bundle zip 文件的绝对路径。传递此设置与 <code>cassandra_servers</code> 严格互斥。 示例：：</p> <pre><code>cassandra_secure_bundle_path = '/home/user/bundles/secure-connect.zip'\n</code></pre> <p>连接到 Astra DB 时，必须指定纯文本认证提供程序以及相关的用户名和密码，这些分别取值为为 Astra DB 实例生成的有效令牌的客户端 ID 和客户端密钥。 请参阅下面的 Astra DB 配置示例。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_port","level":4,"title":"<code>cassandra_port</code>","text":"<p>默认值：9042。</p> <p>联系 Cassandra 服务器的端口。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_keyspace","level":4,"title":"<code>cassandra_keyspace</code>","text":"<p>默认值：None。</p> <p>存储结果的键空间。</p> <pre><code>cassandra_keyspace = 'tasks_keyspace'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_table","level":4,"title":"<code>cassandra_table</code>","text":"<p>默认值：None。</p> <p>存储结果的表（列族）。</p> <pre><code>cassandra_table = 'tasks'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_read_consistency","level":4,"title":"<code>cassandra_read_consistency</code>","text":"<p>默认值：None。</p> <p>使用的读取一致性。值可以是 <code>ONE</code>、<code>TWO</code>、<code>THREE</code>、<code>QUORUM</code>、<code>ALL</code>、<code>LOCAL_QUORUM</code>、<code>EACH_QUORUM</code>、<code>LOCAL_ONE</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_write_consistency","level":4,"title":"<code>cassandra_write_consistency</code>","text":"<p>默认值：None。</p> <p>使用的写入一致性。值可以是 <code>ONE</code>、<code>TWO</code>、<code>THREE</code>、<code>QUORUM</code>、<code>ALL</code>、<code>LOCAL_QUORUM</code>、<code>EACH_QUORUM</code>、<code>LOCAL_ONE</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_entry_ttl","level":4,"title":"<code>cassandra_entry_ttl</code>","text":"<p>默认值：None。</p> <p>状态条目的生存时间。它们将在添加后的指定秒数后过期并被删除。值为 <code>None</code>（默认）意味着它们永远不会过期。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_auth_provider","level":4,"title":"<code>cassandra_auth_provider</code>","text":"<p>默认值：<code>None</code>。</p> <p>要使用的 <code>cassandra.auth</code> 模块中的 AuthProvider 类。值可以是 <code>PlainTextAuthProvider</code> 或 <code>SaslAuthProvider</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_auth_kwargs","level":4,"title":"<code>cassandra_auth_kwargs</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>传递给认证提供程序的命名参数。例如：</p> <pre><code>cassandra_auth_kwargs = {\n    username: 'cassandra',\n    password: 'cassandra'\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra_options","level":4,"title":"<code>cassandra_options</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>传递给 <code>cassandra.cluster</code> 类的命名参数。</p> <pre><code>cassandra_options = {\n    'cql_version': '3.2.1'\n    'protocol_version': 3\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cassandra","level":4,"title":"示例配置（Cassandra）","text":"<pre><code>result_backend = 'cassandra://'\ncassandra_servers = ['localhost']\ncassandra_keyspace = 'celery'\ncassandra_table = 'tasks'\ncassandra_read_consistency = 'QUORUM'\ncassandra_write_consistency = 'QUORUM'\ncassandra_entry_ttl = 86400\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#astra-db","level":4,"title":"示例配置（Astra DB）","text":"<pre><code>result_backend = 'cassandra://'\ncassandra_keyspace = 'celery'\ncassandra_table = 'tasks'\ncassandra_read_consistency = 'QUORUM'\ncassandra_write_consistency = 'QUORUM'\ncassandra_auth_provider = 'PlainTextAuthProvider'\ncassandra_auth_kwargs = {\n  'username': '&lt;&lt;CLIENT_ID_FROM_ASTRA_DB_TOKEN&gt;&gt;',\n  'password': '&lt;&lt;CLIENT_SECRET_FROM_ASTRA_DB_TOKEN&gt;&gt;'\n}\ncassandra_secure_bundle_path = '/path/to/secure-connect-bundle.zip'\ncassandra_entry_ttl = 86400\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_14","level":4,"title":"附加配置","text":"<p>Cassandra 驱动程序在建立连接时，会经历与服务器协商协议版本的阶段。类似地，会自动提供负载均衡策略（默认为 <code>DCAwareRoundRobinPolicy</code>，它又有一个 <code>local_dc</code> 设置，也由驱动程序在连接时确定）。 在可能的情况下，应在配置中明确提供这些设置：此外，未来版本的 Cassandra 驱动程序将要求至少指定负载均衡策略（使用执行配置文件，如下所示）。</p> <p>因此，Cassandra 后端的完整配置将包含以下附加行：</p> <pre><code>from cassandra.policies import DCAwareRoundRobinPolicy\nfrom cassandra.cluster import ExecutionProfile\nfrom cassandra.cluster import EXEC_PROFILE_DEFAULT\n\nmyEProfile = ExecutionProfile(\n  load_balancing_policy=DCAwareRoundRobinPolicy(\n    local_dc='datacenter1', # 替换为您的 DC 名称\n  )\n)\n\ncassandra_options = {\n  'protocol_version': 5,    # 对于 Cassandra 4，根据需要更改\n  'execution_profiles': {EXEC_PROFILE_DEFAULT: myEProfile},\n}\n</code></pre> <p>类似地，对于 Astra DB：</p> <pre><code>from cassandra.policies import DCAwareRoundRobinPolicy\nfrom cassandra.cluster import ExecutionProfile\nfrom cassandra.cluster import EXEC_PROFILE_DEFAULT\n\nmyEProfile = ExecutionProfile(\n  load_balancing_policy=DCAwareRoundRobinPolicy(\n    local_dc='europe-west1',  # 对于 Astra DB，区域名称 = dc 名称\n  )\n)\n\ncassandra_options = {\n  'protocol_version': 4,      # 对于 Astra DB\n  'execution_profiles': {EXEC_PROFILE_DEFAULT: myEProfile},\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#s3","level":3,"title":"S3 后端设置","text":"<p>Note</p> <p>此 S3 后端驱动程序需要 <code>s3</code>。</p> <p>要安装，请使用 <code>s3</code></p> <pre><code>pip install celery[s3]\n</code></pre> <p>此后端需要设置以下配置指令。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#s3_access_key_id","level":4,"title":"<code>s3_access_key_id</code>","text":"<p>默认值：None。</p> <p>S3 访问密钥 ID。</p> <pre><code>s3_access_key_id = 'access_key_id'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#s3_secret_access_key","level":4,"title":"<code>s3_secret_access_key</code>","text":"<p>默认值：None。</p> <p>S3 秘密访问密钥。</p> <pre><code>s3_secret_access_key = 'access_secret_access_key'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#s3_bucket","level":4,"title":"<code>s3_bucket</code>","text":"<p>默认值：None。</p> <p>S3 存储桶名称。</p> <pre><code>s3_bucket = 'bucket_name'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#s3_base_path","level":4,"title":"<code>s3_base_path</code>","text":"<p>默认值：None。</p> <p>S3 存储桶中用于存储结果键的基础路径。</p> <pre><code>s3_base_path = '/prefix'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#s3_endpoint_url","level":4,"title":"<code>s3_endpoint_url</code>","text":"<p>默认值：None。</p> <p>自定义 S3 端点 URL。用于连接到自定义自托管的 S3 兼容后端（Ceph、Scality 等）。</p> <pre><code>s3_endpoint_url = 'https://.s3.custom.url'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#s3_region","level":4,"title":"<code>s3_region</code>","text":"<p>默认值：None。</p> <p>S3 AWS 区域。</p> <pre><code>s3_region = 'us-east-1'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_15","level":4,"title":"示例配置","text":"<pre><code>s3_access_key_id = 's3-access-key-id'\ns3_secret_access_key = 's3-secret-access-key'\ns3_bucket = 'mybucket'\ns3_base_path = '/celery_result_backend'\ns3_endpoint_url = 'https://endpoint_url'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azure-block-blob","level":3,"title":"Azure Block Blob 后端设置","text":"<p>要使用 <code>AzureBlockBlob</code>_ 作为结果后端，您只需使用正确的 URL 配置 <code>result_backend</code> 设置。</p> <p>所需的 URL 格式为 <code>azureblockblob://</code> 后跟存储连接字符串。您可以在 Azure 门户中存储帐户资源的 <code>访问密钥</code> 窗格中找到存储连接字符串。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_16","level":4,"title":"示例配置","text":"<pre><code>result_backend = 'azureblockblob://DefaultEndpointsProtocol=https;AccountName=somename;AccountKey=Lou...bzg==;EndpointSuffix=core.windows.net'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azureblockblob_container_name","level":4,"title":"<code>azureblockblob_container_name</code>","text":"<p>默认值：celery。</p> <p>用于存储结果的存储容器的名称。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azureblockblob_base_path","level":4,"title":"<code>azureblockblob_base_path</code>","text":"<p>默认值：None。</p> <p>存储容器中用于存储结果键的基本路径。</p> <pre><code>azureblockblob_base_path = 'prefix/'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azureblockblob_retry_initial_backoff_sec","level":4,"title":"<code>azureblockblob_retry_initial_backoff_sec</code>","text":"<p>默认值：2。</p> <p>第一次重试的初始回退间隔（以秒为单位）。后续重试采用指数策略。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azureblockblob_retry_increment_base","level":4,"title":"<code>azureblockblob_retry_increment_base</code>","text":"<p>默认值：2。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azureblockblob_retry_max_attempts","level":4,"title":"<code>azureblockblob_retry_max_attempts</code>","text":"<p>默认值：3。</p> <p>最大重试尝试次数。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azureblockblob_connection_timeout","level":4,"title":"<code>azureblockblob_connection_timeout</code>","text":"<p>默认值：20。</p> <p>建立 Azure Block Blob 连接的超时时间（以秒为单位）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#azureblockblob_read_timeout","level":4,"title":"<code>azureblockblob_read_timeout</code>","text":"<p>默认值：120。</p> <p>读取 Azure Block Blob 的超时时间（以秒为单位）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#gcs","level":3,"title":"GCS 后端设置","text":"<p>Note</p> <p>此 GCS 后端驱动程序需要 <code>google-cloud-storage</code> 和 <code>google-cloud-firestore</code>。</p> <p>要安装，请使用 <code>gcs</code>：</p> <pre><code>pip install celery[gcs]\n</code></pre> <p>有关组合多个扩展要求的信息，请参阅 :ref:<code>bundles</code>。</p> <p>GCS 可以通过 <code>result_backend</code> 中提供的 URL 进行配置，例如：：</p> <p><pre><code>result_backend = 'gs://mybucket/some-prefix?gcs_project=myproject&amp;ttl=600'\nresult_backend = 'gs://mybucket/some-prefix?gcs_project=myproject?firestore_project=myproject2&amp;ttl=600'\n</code></pre> 此后端需要设置以下配置指令：</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#gcs_bucket","level":4,"title":"<code>gcs_bucket</code>","text":"<p>默认值：None。</p> <p>GCS 存储桶名称。</p> <pre><code>gcs_bucket = 'bucket_name'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#gcs_project","level":4,"title":"<code>gcs_project</code>","text":"<p>默认值：None。</p> <p>GCS 项目名称。</p> <pre><code>gcs_project = 'test-project'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#gcs_base_path","level":4,"title":"<code>gcs_base_path</code>","text":"<p>默认值：None。</p> <p>在 GCS 存储桶中用于存储所有结果键的基本路径。</p> <pre><code>gcs_base_path = '/prefix'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#gcs_ttl","level":4,"title":"<code>gcs_ttl</code>","text":"<p>默认值：0。</p> <p>结果 blob 的生存时间（以秒为单位）。 需要启用\"删除\"对象生命周期管理操作的 GCS 存储桶。 用于从云存储存储桶中自动删除结果。</p> <p>例如，要在 24 小时后自动删除结果：</p> <pre><code>gcs_ttl = 86400\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#gcs_threadpool_maxsize","level":4,"title":"<code>gcs_threadpool_maxsize</code>","text":"<p>默认值：10。</p> <p>GCS 操作的线程池大小。相同的值定义了连接池大小。允许控制并发操作的数量。</p> <pre><code>gcs_threadpool_maxsize = 20\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#firestore_project","level":4,"title":"<code>firestore_project</code>","text":"<p>默认值：gcs_project。</p> <p>用于 Chord 引用计数的 Firestore 项目。允许本机 chord 引用计数。 如果未指定，则默认为 <code>gcs_project</code>。 例如：：</p> <pre><code>firestore_project = 'test-project2'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_17","level":4,"title":"示例配置","text":"<pre><code>gcs_bucket = 'mybucket'\ngcs_project = 'myproject'\ngcs_base_path = '/celery_result_backend'\ngcs_ttl = 86400\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#elasticsearch","level":3,"title":"Elasticsearch 后端设置","text":"<p>要将 <code>Elasticsearch</code>_ 用作结果后端，您只需使用正确的 URL 配置 <code>result_backend</code> 设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_18","level":4,"title":"示例配置","text":"<pre><code>result_backend = 'elasticsearch://example.com:9200/index_name/doc_type'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#elasticsearch_retry_on_timeout","level":4,"title":"<code>elasticsearch_retry_on_timeout</code>","text":"<p>默认值：<code>False</code></p> <p>超时是否应在不同节点上触发重试？</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#elasticsearch_max_retries","level":4,"title":"<code>elasticsearch_max_retries</code>","text":"<p>默认值：3。</p> <p>在异常传播之前最大重试次数。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#elasticsearch_timeout","level":4,"title":"<code>elasticsearch_timeout</code>","text":"<p>默认值：10.0 秒。</p> <p>全局超时时间，由 elasticsearch 结果后端使用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#elasticsearch_save_meta_as_text","level":4,"title":"<code>elasticsearch_save_meta_as_text</code>","text":"<p>默认值：<code>True</code></p> <p>元数据应保存为文本还是原生 json。结果始终序列化为文本。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#aws-dynamodb","level":3,"title":"AWS DynamoDB 后端设置","text":"<p>Note</p> <p>Dynamodb 后端需要 <code>boto3</code> 库。</p> <p>要安装此包，请使用 <code>pip</code>：</p> <pre><code>pip install celery[dynamodb]\n</code></pre> <p>Warning</p> <p>Dynamodb 后端与定义了排序键的表不兼容。</p> <p>如果您想基于分区键以外的内容查询结果表，请定义全局二级索引 (GSI)。</p> <p>此后端要求将 <code>result_backend</code> 设置设置为 DynamoDB URL:</p> <pre><code>result_backend = 'dynamodb://aws_access_key_id:aws_secret_access_key@region:port/table?read=n&amp;write=m'\n</code></pre> <p>例如，指定 AWS 区域和表名:</p> <pre><code>result_backend = 'dynamodb://@us-east-1/celery_results'\n</code></pre> <p>或者从环境变量中检索 AWS 配置参数，使用默认表名 (<code>celery</code>)并指定读取和写入预置吞吐量:</p> <pre><code>result_backend = 'dynamodb://@/?read=5&amp;write=5'\n</code></pre> <p>或者使用 DynamoDB 的 可下载版本 本地端点:</p> <pre><code>result_backend = 'dynamodb://@localhost:8000'\n</code></pre> <p>或者使用可下载版本或部署在任何主机上符合 API 的其他服务:</p> <pre><code>result_backend = 'dynamodb://@us-east-1'\ndynamodb_endpoint_url = 'http://192.168.0.40:8000'\n</code></pre> <p><code>result_backend</code> 中 DynamoDB URL 的字段定义如下：</p> 字段 描述 <code>aws_access_key_id</code> <code>aws_secret_access_key</code>  用于访问 AWS API 资源的凭据。这些也可以通过 `boto3` 库从各种来源解析， 如此处所述。  <code>region</code>  AWS 区域，例如 <code>us-east-1</code> 或用于 可下载版本 的 <code>localhost</code>。 有关定义选项，请参阅 <code>boto3</code> 库 文档。  <code>port</code>  本地 DynamoDB 实例的监听端口，如果您使用的是可下载版本。 如果您没有将 <code>region</code> 参数指定为 <code>localhost</code>， 设置此参数将无效。  <code>table</code>  要使用的表名。默认为 <code>celery</code>。 有关允许的字符和长度的信息，请参阅 DynamoDB 命名规则。  <code>read &amp; write</code>  创建的 DynamoDB 表的读取和写入容量单位。默认情况下，读取和写入均为 <code>1</code>。 更多详细信息可以在 预置吞吐量文档 中找到。  <code>ttl_seconds</code>  结果在过期前的生存时间（以秒为单位）。默认情况下，结果不会过期，同时保持 DynamoDB 表的生存时间设置不变。如果 <code>ttl_seconds</code> 设置为正值，结果将在指定的秒数后过期。将 <code>ttl_seconds</code> 设置为负值意味着结果不会过期，并且主动禁用 DynamoDB 表的生存时间设置。请注意，尝试在已有项目的表上启用生存时间将导致错误。更多详细信息可以在DynamoDB TTL 文档 中找到。","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#ironcache","level":3,"title":"IronCache 后端设置","text":"<p>Note</p> <p>IronCache 后端需要 <code>iron_celery</code> 库：</p> <p>要安装此包，请使用 <code>pip</code>：</p> <pre><code>pip install iron_celery\n</code></pre> <p>IronCache 通过 <code>result_backend</code> 中提供的 URL 进行配置，</p> <pre><code>result_backend = 'ironcache://project_id:token@'\n</code></pre> <p>或者更改缓存名称：</p> <pre><code>ironcache://project_id:token@/awesomecache\n</code></pre> <p>更多信息，请参阅：https://github.com/iron-io/iron_celery</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#couchbase","level":3,"title":"Couchbase 后端设置","text":"<p>Note</p> <p>Couchbase 后端需要 <code>couchbase</code> 库。</p> <p>要安装此包，请使用 <code>pip</code>：</p> <pre><code>pip install celery[couchbase]\n</code></pre> <p>可以通过将 <code>result_backend</code> 设置为 Couchbase URL 来配置此后端：</p> <pre><code>result_backend = 'couchbase://username:password@host:port/bucket'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#couchbase_backend_settings","level":4,"title":"<code>couchbase_backend_settings</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>这是一个支持以下键的字典：</p> 键 描述 <code>host</code> Couchbase 服务器的主机名。默认为 <code>localhost</code>。 <code>port</code> Couchbase 服务器正在监听的端口。默认为 <code>8091</code>。 <code>bucket</code> Couchbase 服务器写入的默认存储桶。默认为 <code>default</code>。 <code>username</code> 用于验证 Couchbase 服务器的用户名（可选）。 <code>password</code> 用于验证 Couchbase 服务器的密码（可选）。","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#arangodb","level":3,"title":"ArangoDB 后端设置","text":"<p>Note</p> <p>ArangoDB 后端需要 <code>pyArango</code> 库。</p> <p>要安装此包，请使用 <code>pip</code>：</p> <pre><code>pip install celery[arangodb]\n</code></pre> <p>此后端可以通过将 <code>result_backend</code> 设置为 ArangoDB URL 来配置：</p> <pre><code>result_backend = 'arangodb://username:password@host:port/database/collection'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#arangodb_backend_settings","level":4,"title":"<code>arangodb_backend_settings</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>这是一个支持以下键的字典：</p> 键 描述 <code>host</code> ArangoDB 服务器的主机名。默认为 <code>localhost</code>。 <code>port</code> ArangoDB 服务器监听的端口。默认为 <code>8529</code>。 <code>database</code> ArangoDB 服务器中写入的默认数据库。默认为 <code>celery</code>。 <code>collection</code> ArangoDB 服务器数据库中写入的默认集合。默认为 <code>celery</code>。 <code>username</code> 用于验证 ArangoDB 服务器的用户名（可选）。 <code>password</code> 用于验证 ArangoDB 服务器的密码（可选）。 <code>http_protocol</code> ArangoDB 服务器连接的 HTTP 协议。默认为 <code>http</code>。 <code>verify</code> 创建 ArangoDB 连接时的 HTTPS 验证检查。默认为 <code>False</code>。","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cosmosdb","level":3,"title":"CosmosDB 后端设置（实验性）","text":"<p>要将 <code>CosmosDB</code> 用作结果后端，您只需使用正确的 URL 配置 <code>result_backend</code> 设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_19","level":4,"title":"示例配置","text":"<pre><code>result_backend = 'cosmosdbsql://:{InsertAccountPrimaryKeyHere}@{InsertAccountNameHere}.documents.azure.com'\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cosmosdbsql_database_name","level":4,"title":"<code>cosmosdbsql_database_name</code>","text":"<p>默认值：celerydb。</p> <p>用于存储结果的数据库名称。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cosmosdbsql_collection_name","level":4,"title":"<code>cosmosdbsql_collection_name</code>","text":"<p>默认值：celerycol。</p> <p>用于存储结果的集合名称。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cosmosdbsql_consistency_level","level":4,"title":"<code>cosmosdbsql_consistency_level</code>","text":"<p>默认值：Session。</p> <p>表示 Azure Cosmos DB 客户端操作支持的一致性级别。</p> <p>一致性级别按强度顺序排列为：Strong、BoundedStaleness、Session、ConsistentPrefix 和 Eventual。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cosmosdbsql_max_retry_attempts","level":4,"title":"<code>cosmosdbsql_max_retry_attempts</code>","text":"<p>默认值：9。</p> <p>请求的最大重试次数。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#cosmosdbsql_max_retry_wait_time","level":4,"title":"<code>cosmosdbsql_max_retry_wait_time</code>","text":"<p>默认值：30。</p> <p>重试过程中等待请求的最大等待时间（秒）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#couchdb","level":3,"title":"CouchDB 后端设置","text":"<p>Note</p> <p>CouchDB 后端需要 <code>pycouchdb</code> 库：</p> <p>要安装此 Couchbase 包，请使用 <code>pip</code>：</p> <pre><code>pip install celery[couchdb]\n</code></pre> <p>此后端可以通过将 <code>result_backend</code> 设置为 CouchDB URL 来配置：</p> <pre><code>result_backend = 'couchdb://username:password@host:port/container'\n</code></pre> <p>URL 由以下部分组成：</p> 键 描述 <code>username</code> 用于验证 CouchDB 服务器的用户名（可选）。 <code>password</code> 用于验证 CouchDB 服务器的密码（可选）。 <code>host</code> CouchDB 服务器的主机名。默认为 <code>localhost</code>。 <code>port</code> CouchDB 服务器监听的端口。默认为 <code>8091</code>。 <code>container</code> CouchDB 服务器写入的默认容器。默认为 <code>default</code>。","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_20","level":3,"title":"文件系统后端设置","text":"<p>此后端可以使用文件 URL 进行配置</p> <pre><code>CELERY_RESULT_BACKEND = 'file:///var/celery/results'\n</code></pre> <p>配置的目录需要被所有使用该后端的服务器共享并可写入。</p> <p>如果您在单个系统上尝试使用 Celery，可以简单地使用该后端而无需进一步配置。对于较大的集群，您可以使用 NFS、GlusterFS、CIFS、HDFS（使用 FUSE）或任何其他文件系统。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#consul-kv","level":3,"title":"Consul K/V 存储后端设置","text":"<p>Note</p> <p>Consul 后端需要 <code>python-consul2</code> 库：</p> <p>要安装此包，请使用 <code>pip</code>：</p> <pre><code>pip install python-consul2\n</code></pre> <p>Consul 后端可以使用 URL 进行配置，例如：：</p> <pre><code>CELERY_RESULT_BACKEND = 'consul://localhost:8500/'\n</code></pre> <p>或者：：</p> <pre><code>result_backend = 'consul://localhost:8500/'\n</code></pre> <p>该后端将结果存储在 Consul 的 K/V 存储中作为单独的键。后端支持使用 Consul 中的 TTL 自动过期结果。URL 的完整语法是：</p> <pre><code>consul://host:port[?one_client=1]\n</code></pre> <p>URL 由以下部分组成：</p> 键 描述 <code>host</code> Consul 服务器的主机名。默认为 <code>localhost</code>。 <code>port</code> Consul 服务器监听的端口。默认为 <code>8500</code>。 <code>one_client</code> 默认情况下，为了正确性，后端为每个操作使用单独的客户端连接。在极端负载情况下，新连接的创建速率可能导致 Consul 服务器在负载下返回 HTTP 429 \"连接过多\" 错误响应。推荐的解决方法是使用 https://github.com/poppyred/python-consul2/pull/31 处的补丁在 <code>python-consul2</code> 中启用重试。或者，如果设置了 <code>one_client</code>，将使用单个客户端连接来处理所有操作。这应该可以消除 HTTP 429 错误，但后端存储结果可能会变得不可靠。","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_21","level":3,"title":"消息路由","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_queues","level":4,"title":"<code>task_queues</code>","text":"<p>默认值：<code>None</code>（从默认队列设置中获取队列）。</p> <p>大多数用户不需要指定此设置，而应该使用 自动路由功能。</p> <p>如果您确实想要配置高级路由，此设置应该是 worker 将从中消费的 <code>kombu.Queue</code> 对象列表。</p> <p>注意，可以通过 <code>celery worker -Q</code> 选项覆盖此设置，或者可以使用 <code>celery worker -X</code> 选项从此列表中排除单个队列（按名称）。</p> <p>另请参阅 路由基础知识 获取更多信息。</p> <p>默认是一个队列/交换/绑定键为 <code>celery</code>，交换类型为 <code>direct</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_routes","level":4,"title":"<code>task_routes</code>","text":"<p>默认值：<code>None</code>。</p> <p>用于将任务路由到队列的路由器列表或单个路由器。在决定任务的最终目的地时，会按顺序咨询路由器。</p> <p>路由器可以指定为以下任一形式：</p> <ul> <li>具有签名 <code>(name, args, kwargs, options, task=None, **kwargs)</code> 的函数</li> <li>提供路由器函数路径的字符串</li> <li>包含路由器规范的字典：将被转换为 <code>celery.routes.MapRoute</code> 实例</li> <li><code>(pattern, route)</code> 元组列表：将被转换为 <code>celery.routes.Map oute</code> 实例</li> </ul> <p>示例：</p> <pre><code>task_routes = {\n    'celery.ping': 'default',\n    'mytasks.add': 'cpu-bound',\n    'feed.tasks.*': 'feeds',                           # &lt;-- 通配符模式\n    re.compile(r'(image|video)\\.tasks\\..*'): 'media',  # &lt;-- 正则表达式\n    'video.encode': {\n        'queue': 'video',\n        'exchange': 'media',\n        'routing_key': 'media.video.encode',\n    },\n}\n\ntask_routes = ('myapp.tasks.route_task', {'celery.ping': 'default'})\n</code></pre> <p>其中 <code>myapp.tasks.route_task</code> 可以是：</p> <pre><code>def route_task(self, name, args, kwargs, options, task=None, **kw):\n    if task == 'celery.ping':\n        return {'queue': 'default'}\n</code></pre> <p><code>route_task</code> 可以返回字符串或字典。字符串表示它是 <code>task_queues</code> 中的队列名称，字典表示它是自定义路由。</p> <p>发送任务时，会按顺序咨询路由器。第一个不返回 <code>None</code> 的路由器就是要使用的路由。然后消息选项会与找到的路由设置合并，其中任务的设置具有优先级。</p> <p>如果 <code>celery.execute.apply_async</code> 有以下参数：</p> <pre><code>Task.apply_async(immediate=False, exchange='video', routing_key='video.compress')\n</code></pre> <p>而路由器返回：</p> <pre><code>{'immediate': True, 'exchange': 'urgent'}\n</code></pre> <p>最终的消息选项将是：</p> <pre><code>immediate=False, exchange='video', routing_key='video.compress'\n</code></pre> <p>（以及 <code>celery.app.task.Task</code> 类中定义的任何默认消息选项）</p> <p>合并两者时，<code>task_routes</code> 中定义的值优先于 <code>task_queues</code> 中定义的值。</p> <p>使用以下设置：</p> <pre><code>task_queues = {\n    'cpubound': {\n        'exchange': 'cpubound',\n        'routing_key': 'cpubound',\n    },\n}\n\ntask_routes = {\n    'tasks.add': {\n        'queue': 'cpubound',\n        'routing_key': 'tasks.add',\n        'serializer': 'json',\n    },\n}\n</code></pre> <p><code>tasks.add</code> 的最终路由选项将变为：</p> <pre><code>    {'exchange': 'cpubound',\n     'routing_key': 'tasks.add',\n     'serializer': 'json'}\n</code></pre> <p>请参阅 路由指南 获取更多示例。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_queue_max_priority","level":4,"title":"<code>task_queue_max_priority</code>","text":"<p>默认值：<code>None</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_priority","level":4,"title":"<code>task_default_priority</code>","text":"<p>默认值：<code>None</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_inherit_parent_priority","level":4,"title":"<code>task_inherit_parent_priority</code>","text":"<p>默认值：<code>False</code>。</p> <p>如果启用，子任务将继承父任务的优先级。</p> <pre><code># 链中的最后一个任务也将优先级设置为5。\nchain = celery.chain(add.s(2) | add.s(2).set(priority=5) | add.s(3))\n</code></pre> <p>当使用 <code>delay</code> 或 <code>apply_async</code> 从父任务调用子任务时，优先级继承也有效。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_direct","level":4,"title":"<code>worker_direct</code>","text":"<p>默认值：禁用。</p> <p>此选项启用后，每个 worker 都会有一个专用队列，以便可以将任务路由到特定的 worker。</p> <p>每个 worker 的队列名称基于 worker 主机名和 <code>.dq</code> 后缀自动生成，使用 <code>C.dq2</code> 交换。</p> <p>例如，节点名称为 <code>w1@example.com</code> 的 worker 的队列名称变为:</p> <pre><code>w1@example.com.dq\n</code></pre> <p>然后您可以通过将主机名指定为路由键和 <code>C.dq2</code> 交换来将任务路由到该 worker:</p> <pre><code>task_routes = {\n    'tasks.add': {'exchange': 'C.dq2', 'routing_key': 'w1@example.com'}\n}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_create_missing_queues","level":4,"title":"<code>task_create_missing_queues</code>","text":"<p>默认值：启用。</p> <p>如果启用（默认），任何在 <code>task_queues</code> 中未定义但指定的队列将自动创建。请参阅 :ref:<code>routing-automatic</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_create_missing_queue_type","level":4,"title":"<code>task_create_missing_queue_type</code>","text":"<p>默认值：<code>\"classic\"</code></p> <p>当 Celery 需要声明一个不存在的队列时（即当 <code>task_create_missing_queues</code> 启用时），此设置定义要创建的 RabbitMQ 队列类型。</p> <ul> <li><code>\"classic\"</code>（默认）：声明标准经典队列。</li> <li><code>\"quorum\"</code>：声明 RabbitMQ 仲裁队列（添加 <code>x-queue-type: quorum</code>）。</li> </ul>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_create_missing_queue_exchange_type","level":4,"title":"<code>task_create_missing_queue_exchange_type</code>","text":"<p>默认值：<code>None</code></p> <p>如果此选项为 None 或空字符串（默认），Celery 将保持交换与您的 <code>app.amqp.Queues.autoexchange</code> 钩子返回的完全相同。</p> <p>您可以将其设置为特定的交换类型，例如 <code>\"direct\"</code>、<code>\"topic\"</code> 或 <code>\"fanout\"</code>，以使用该交换类型创建缺失的队列。</p> <p>Tip</p> <p>将此设置与 task_create_missing_queue_type = \"quorum\" 结合使用以创建绑定到主题交换的仲裁队列，例如:</p> <pre><code>app.conf.task_create_missing_queues=True\napp.conf.task_create_missing_queue_type=\"quorum\"\napp.conf.task_create_missing_queue_exchange_type=\"topic\"\n</code></pre> <p>Note</p> <p>与上面的队列类型设置一样，此选项不会影响您在 <code>task_queues</code> 中明确定义的队列；它仅适用于在运行时隐式创建的队列。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_queue","level":4,"title":"<code>task_default_queue</code>","text":"<p>默认值：<code>\"celery\"</code>。</p> <p>如果消息没有路由或未指定自定义队列，<code>.apply_async</code> 使用的默认队列名称。</p> <p>此队列必须列在 <code>task_queues</code> 中。如果未指定 <code>task_queues</code>，则会自动创建包含一个队列条目，其中此名称用作该队列的名称。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_queue_type","level":4,"title":"<code>task_default_queue_type</code>","text":"<p>默认值：<code>\"classic\"</code>。</p> <p>此设置用于允许更改 <code>task_default_queue</code> 队列的默认队列类型。另一个可行的选项是 <code>\"quorum\"</code>，它仅受 RabbitMQ 支持，并使用 <code>x-queue-type</code> 队列参数将队列类型设置为 <code>quorum</code>。</p> <p>如果启用了 <code>worker_detect_quorum_queues</code> 设置，worker 将自动检测队列类型并相应地禁用全局 QoS。</p> <p>Warning</p> <p>仲裁队列需要启用确认发布。 使用 <code>broker_transport_options</code> 通过以下设置启用确认发布：</p> <pre><code>broker_transport_options = {\"confirm_publish\": True}\n</code></pre> <p>有关更多信息，请参阅 RabbitMQ 文档。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_exchange","level":4,"title":"<code>task_default_exchange</code>","text":"<p>默认值：使用为 <code>task_default_queue</code> 设置的值。</p> <p>当在 <code>task_queues</code> 设置中未为键指定自定义交换时使用的默认交换名称。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_exchange_type","level":4,"title":"<code>task_default_exchange_type</code>","text":"<p>默认值：<code>\"direct\"</code>。</p> <p>当在 <code>task_queues</code> 设置中未为键指定自定义交换类型时使用的默认交换类型。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_routing_key","level":4,"title":"<code>task_default_routing_key</code>","text":"<p>默认值：使用为 <code>task_default_queue</code> 设置的值。</p> <p>当在 <code>task_queues</code> 设置中未为键指定自定义路由键时使用的默认路由键。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_default_delivery_mode","level":4,"title":"<code>task_default_delivery_mode</code>","text":"<p>默认值：<code>\"persistent\"</code>。</p> <p>可以是 <code>transient</code>（消息不写入磁盘）或 <code>persistent</code>（写入磁盘）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#conf-broker-settings","level":3,"title":"Broker 设置","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_url","level":4,"title":"<code>broker_url</code>","text":"<p>默认值：<code>\"amqp://\"</code></p> <p>默认的 broker URL。这必须是一个格式如下的 URL：：</p> <pre><code>transport://userid:password@hostname:port/virtual_host\n</code></pre> <p>只有方案部分（<code>transport://</code>）是必需的，其余部分是可选的，并默认为特定传输的默认值。</p> <p>传输部分是使用的 broker 实现，默认是 <code>amqp</code>，（如果安装了 <code>librabbitmq</code> 则使用它，否则回退到 <code>pyamqp</code>）。还有其他可用的选择，包括：<code>redis://</code>、<code>sqs://</code> 和 <code>qpid://</code>。</p> <p>方案也可以是你自己传输实现的完全限定路径：</p> <pre><code>broker_url = 'proj.transports.MyTransport://localhost'\n</code></pre> <p>也可以指定多个相同传输的 broker URL。broker URL 可以作为分号分隔的单个字符串传递：</p> <pre><code>broker_url = 'transport://userid:password@hostname:port//;transport://userid:password@hostname:port//'\n</code></pre> <p>或作为列表：</p> <pre><code>broker_url = [\n    'transport://userid:password@localhost:port//',\n    'transport://userid:password@hostname:port//'\n]\n</code></pre> <p>然后这些 broker 将用于 <code>broker_failover_strategy</code>。</p> <p>有关更多信息，请参阅 Kombu 文档中的 连接 URL。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_read_url-broker_write_url","level":4,"title":"<code>broker_read_url</code> / <code>broker_write_url</code>","text":"<p>默认值：取自 <code>broker_url</code>。</p> <p>这些设置可以配置，以替代 <code>broker_url</code>，为用于消费和生产的 broker 连接指定不同的连接参数。</p> <p>示例：</p> <pre><code>broker_read_url = 'amqp://user:pass@broker.example.com:56721'\nbroker_write_url = 'amqp://user:pass@broker.example.com:56722'\n</code></pre> <p>这两个选项也可以指定为故障转移备选的列表，有关更多信息，请参阅 <code>broker_url</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_failover_strategy","level":4,"title":"<code>broker_failover_strategy</code>","text":"<p>默认值：<code>\"round-robin\"</code>。</p> <p>broker Connection 对象的默认故障转移策略。如果提供，可以映射到 'kombu.connection.failover_strategies' 中的一个键，或者是对从提供的列表中产生单个项目的任何方法的引用。</p> <p>示例：：</p> <pre><code># 随机故障转移策略\ndef random_failover_strategy(servers):\n    it = list(servers)  # 不要修改调用者的列表\n    shuffle = random.shuffle\n    for _ in repeat(None):\n        shuffle(it)\n        yield it[0]\n\nbroker_failover_strategy = random_failover_strategy\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_heartbeat","level":4,"title":"<code>broker_heartbeat</code>","text":"<p>默认值：<code>120.0</code>（由服务器协商）。</p> <p>注意：此值仅由 worker 使用，客户端目前不使用心跳。</p> <p>仅使用 TCP/IP 并不总是能够及时检测到连接丢失，因此 AMQP 定义了一种称为心跳的机制，由客户端和 broker 共同使用来检测连接是否已关闭。</p> <p>如果心跳值为 10 秒，则心跳将在 <code>broker_heartbeat_checkrate</code> 设置指定的间隔内进行监控（默认情况下，这设置为心跳值的双倍速率，因此对于 10 秒的心跳，每 5 秒检查一次心跳）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_heartbeat_checkrate","level":4,"title":"<code>broker_heartbeat_checkrate</code>","text":"<p>默认值：2.0。</p> <p>worker 会定期监控 broker 是否错过了太多心跳。检查的频率是通过将 <code>broker_heartbeat</code> 值除以该值来计算的，因此如果心跳为 10.0，速率为默认的 2.0，则每 5 秒执行一次检查（心跳发送速率的两倍）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_use_ssl","level":4,"title":"<code>broker_use_ssl</code>","text":"<p>默认值：禁用。</p> <p>切换 broker 连接上的 SSL 使用和 SSL 设置。</p> <p>此选项的有效值因传输而异。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#pyamqp","level":5,"title":"<code>pyamqp</code>","text":"<p>如果为 <code>True</code>，连接将使用默认 SSL 设置。如果设置为字典，将根据指定的策略配置 SSL 连接。使用的格式是 Python 的 <code>ssl.wrap_socket</code> 选项。</p> <p>请注意，SSL 套接字通常由 broker 在单独的端口上提供服务。</p> <p>提供客户端证书并根据自定义证书颁发机构验证服务器证书的示例：</p> <pre><code>import ssl\n\nbroker_use_ssl = {\n  'keyfile': '/var/ssl/private/worker-key.pem',\n  'certfile': '/var/ssl/amqp-server-cert.pem',\n  'ca_certs': '/var/ssl/myca.pem',\n  'cert_reqs': ssl.CERT_REQUIRED\n}\n</code></pre> <p>5.1</p> <p>从 Celery 5.1 开始，py-amqp 将始终验证从服务器接收的证书，不再需要手动将 <code>cert_reqs</code> 设置为 <code>ssl.CERT_REQUIRED</code>。</p> <p>之前的默认值 <code>ssl.CERT_NONE</code> 不安全，我们不鼓励使用它。 如果你想恢复到之前的不安全默认值，请将 <code>cert_reqs</code> 设置为 <code>ssl.CERT_NONE</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#redis","level":5,"title":"<code>redis</code>","text":"<p>该设置必须是一个包含以下键的字典：</p> <ul> <li><code>ssl_cert_reqs</code>（必需）：<code>SSLContext.verify_mode</code> 值之一：<ul> <li><code>ssl.CERT_NONE</code></li> <li><code>ssl.CERT_OPTIONAL</code></li> <li><code>ssl.CERT_REQUIRED</code></li> </ul> </li> <li><code>ssl_ca_certs</code>（可选）：CA 证书的路径</li> <li><code>ssl_certfile</code>（可选）：客户端证书的路径</li> <li><code>ssl_keyfile</code>（可选）：客户端密钥的路径</li> </ul>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_pool_limit","level":4,"title":"<code>broker_pool_limit</code>","text":"<p>默认值：10。</p> <p>连接池中可以打开的最大连接数。</p> <p>自版本 2.5 起，池默认启用，默认限制为十个连接。这个数字可以根据使用连接的线程/绿色线程（eventlet/gevent）的数量进行调整。例如，运行 eventlet 时，如果有 1000 个使用 broker 连接的 greenlet，可能会出现争用，你应该考虑增加限制。</p> <p>如果设置为 <code>None</code> 或 0，连接池将被禁用，每次使用都会建立和关闭连接。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_connection_timeout","level":4,"title":"<code>broker_connection_timeout</code>","text":"<p>默认值：4.0。</p> <p>在放弃建立与 AMQP 服务器的连接之前的默认超时时间（秒）。使用 gevent 时，此设置被禁用。</p> <p>Note</p> <p>broker 连接超时仅适用于尝试连接到 broker 的 worker。它不适用于生产者发送任务的情况，有关如何为该情况提供超时，请参阅 <code>broker_transport_options</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_connection_retry","level":4,"title":"<code>broker_connection_retry</code>","text":"<p>默认值：启用。</p> <p>如果初始连接建立后丢失，自动尝试重新建立与 AMQP broker 的连接。</p> <p>每次重试之间的时间都会增加，并且在超过 <code>broker_connection_max_retries</code> 之前不会耗尽重试次数。</p> <p>Warning</p> <p>broker_connection_retry 配置设置将不再决定在 Celery 6.0 及更高版本中是否在启动期间进行 broker 连接重试。 如果你希望在启动时不重试连接，你应该将 <code>broker_connection_retry_on_startup</code> 设置为 False。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_connection_retry_on_startup","level":4,"title":"<code>broker_connection_retry_on_startup</code>","text":"<p>默认值：启用。</p> <p>如果 AMQP broker 不可用，在 Celery 启动时自动尝试建立连接。</p> <p>每次重试之间的时间都会增加，并且在超过 <code>broker_connection_max_retries</code> 之前不会耗尽重试次数。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_connection_max_retries","level":4,"title":"<code>broker_connection_max_retries</code>","text":"<p>默认值：100。</p> <p>在放弃重新建立与 AMQP broker 的连接之前的最大重试次数。</p> <p>如果设置为 <code>None</code>，我们将永远重试。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_channel_error_retry","level":4,"title":"<code>broker_channel_error_retry</code>","text":"<p>默认值：禁用。</p> <p>如果返回了任何无效响应，自动尝试重新建立与 AMQP broker 的连接。</p> <p>重试计数和间隔与 <code>broker_connection_retry</code> 相同。 此外，当 <code>broker_connection_retry</code> 为 <code>False</code> 时，此选项不起作用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_login_method","level":4,"title":"<code>broker_login_method</code>","text":"<p>默认值：<code>\"AMQPLAIN\"</code>。</p> <p>设置自定义的 AMQP 登录方法。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_native_delayed_delivery_queue_type","level":4,"title":"<code>broker_native_delayed_delivery_queue_type</code>","text":"<p>:transports supported: <code>pyamqp</code></p> <p>默认值：<code>\"quorum\"</code>。</p> <p>此设置用于允许更改原生延迟传递队列的默认队列类型。另一个可行的选项是 <code>\"classic\"</code>，它仅由 RabbitMQ 支持，并使用 <code>x-queue-type</code> 队列参数将队列类型设置为 <code>classic</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#broker_transport_options","level":4,"title":"<code>broker_transport_options</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>传递给底层传输的附加选项字典。</p> <p>有关支持的选项（如果有），请参阅你的传输用户手册。</p> <p>设置可见性超时的示例（由 Redis 和 SQS 传输支持）：</p> <pre><code>broker_transport_options = {'visibility_timeout': 18000}  # 5 小时\n</code></pre> <p>设置生产者连接最大重试次数的示例（这样如果 broker 在第一次任务执行时不可用，生产者不会永远重试）：</p> <pre><code>broker_transport_options = {'max_retries': 5}\n</code></pre> <p>启用发布者确认的示例（由 <code>pyamqp</code> 传输支持）。如果没有这个，当 broker 达到资源限制时，消息可能会被静默丢弃：</p> <pre><code>broker_transport_options = {'confirm_publish': True}\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker","level":3,"title":"Worker","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#imports","level":4,"title":"<code>imports</code>","text":"<p>默认值：<code>[]</code>（空列表）。</p> <p>在 worker 启动时要导入的模块序列。</p> <p>这用于指定要导入的任务模块，同时也用于导入信号处理程序和额外的远程控制命令等。</p> <p>模块将按原始顺序导入。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#include","level":4,"title":"<code>include</code>","text":"<p>默认值：<code>[]</code>（空列表）。</p> <p>与 <code>imports</code> 具有完全相同的语义，但可以作为一种手段来拥有不同的导入类别。</p> <p>此设置中的模块在 <code>imports</code> 中的模块之后导入。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_deduplicate_successful_tasks","level":4,"title":"<code>worker_deduplicate_successful_tasks</code>","text":"<p>默认值：False</p> <p>在每次任务执行之前，指示 worker 检查此任务是否是重复消息。</p> <p>去重仅发生在具有相同标识符、启用了延迟确认、由消息代理重新传递并且在结果后端中状态为 <code>SUCCESS</code> 的任务上。</p> <p>为了避免用查询淹没结果后端，在查询结果后端之前会检查一个本地缓存的已成功执行的任务，以防该任务已经被接收该任务的同一 worker 成功执行。</p> <p>通过设置 <code>worker_state_db</code> 设置可以使此缓存持久化。</p> <p>如果结果后端不是持久化的（例如 RPC 后端），则忽略此设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_concurrency","level":4,"title":"<code>worker_concurrency</code>","text":"<p>默认值：CPU 核心数。</p> <p>执行任务的并发 worker 进程/线程/绿色线程的数量。</p> <p>如果您主要进行 I/O 操作，可以拥有更多进程，但如果主要是 CPU 密集型，请尝试保持接近机器上的 CPU 数量。如果未设置，将使用主机上的 CPU/核心数。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_prefetch_multiplier","level":4,"title":"<code>worker_prefetch_multiplier</code>","text":"<p>默认值：4。</p> <p>一次预取多少条消息乘以并发进程数。默认值为 4（每个进程四条消息）。默认设置通常是一个不错的选择，但是——如果您有非常长时间运行的任务在队列中等待，并且您必须启动 workers，请注意第一个启动的 worker 最初将收到四倍的消息数量。因此，任务可能不会公平地分配给 workers。</p> <p>要将代理限制为每次只向每个进程传递一条消息，请将 <code>worker_prefetch_multiplier</code> 设置为 1。将该设置更改为 0 将允许 worker 继续消费任意数量的消息。</p> <p>如果您需要在使用早期确认的同时完全禁用代理预取，请启用 <code>worker_disable_prefetch</code>。当启用此选项时，worker 仅在其某个进程可用时才从代理获取任务。</p> <p>Note</p> <p>此功能目前仅在使用 Redis 作为代理时受支持。</p> <p>您也可以通过 <code>celery worker --disable-prefetch</code> 命令行标志启用此功能。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_eta_task_limit","level":4,"title":"<code>worker_eta_task_limit</code>","text":"<p>默认值：无限制（None）。</p> <p>worker 可以一次在内存中保存的最大 ETA/倒计时任务数量。当达到此限制时，worker 将不会从代理接收新任务，直到一些现有的 ETA 任务被执行。</p> <p>当队列包含大量具有 ETA/倒计时值的任务时，此设置有助于防止内存耗尽，因为这些任务在内存中保存直到它们的执行时间。如果没有此限制，workers 可能会将数千个 ETA 任务提取到内存中，可能导致内存不足问题。</p> <p>Note</p> <p>具有 ETA/倒计时的任务不受预取限制的影响。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_disable_prefetch","level":4,"title":"<code>worker_disable_prefetch</code>","text":"<p>默认值：<code>False</code>。</p> <p>启用后，worker 仅在其有可用进程执行任务时才从代理消费消息。这在使用早期确认的同时禁用了预取，确保任务在 workers 之间公平分配。</p> <p>Note</p> <p>此功能目前仅在使用 Redis 作为代理时受支持。在其他代理上使用此设置将导致警告并且该设置将被忽略。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_enable_prefetch_count_reduction","level":4,"title":"<code>worker_enable_prefetch_count_reduction</code>","text":"<p>默认值：启用。</p> <p><code>worker_enable_prefetch_count_reduction</code> 设置控制在与消息代理的连接丢失后，预取计数恢复到其最大允许值的行为。默认情况下，此设置是启用的。</p> <p>在连接丢失时，Celery 将尝试自动重新连接到代理，前提是 <code>broker_connection_retry_on_startup</code> 或 <code>broker_connection_retry</code> 未设置为 False。在连接丢失期间，消息代理不会跟踪已获取的任务数量。因此，为了有效管理任务负载并防止过载，Celery 会根据当前正在运行的任务数量减少预取计数。</p> <p>预取计数是 worker 一次从代理获取的消息数量。减少的预取计数有助于确保在重新连接期间不会过度获取任务。</p> <p>当 <code>worker_enable_prefetch_count_reduction</code> 设置为其默认值（启用）时，每次在连接丢失前正在运行的任务完成时，预取计数将逐渐恢复到其最大允许值。此行为有助于在有效管理负载的同时保持任务在 workers 之间的平衡分配。</p> <p>要在重新连接时禁用预取计数的减少和恢复到其最大允许值，请将 <code>worker_enable_prefetch_count_reduction</code> 设置为 False。在需要固定预取计数来控制任务处理速率或管理 worker 负载的场景中，禁用此设置可能很有用，尤其是在连接不稳定的环境中。</p> <p><code>worker_enable_prefetch_count_reduction</code> 设置提供了一种方法来控制在连接丢失后预取计数的恢复行为，有助于在 workers 之间保持平衡的任务分配和有效的负载管理。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_lost_wait","level":4,"title":"<code>worker_lost_wait</code>","text":"<p>默认值：10.0 秒。</p> <p>在某些情况下，worker 可能会在没有适当清理的情况下被杀死，并且 worker 可能在终止之前发布了结果。此值指定在引发 <code>WorkerLostError</code> 异常之前我们等待任何缺失结果的时间。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_max_tasks_per_child","level":4,"title":"<code>worker_max_tasks_per_child</code>","text":"<p>池工作进程在被新进程替换之前可以执行的最大任务数。默认无限制。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_max_memory_per_child","level":4,"title":"<code>worker_max_memory_per_child</code>","text":"<p>默认值：无限制。 类型：int（千字节）</p> <p>在 worker 被新 worker 替换之前可以消耗的最大驻留内存量，以千字节（1024 字节）为单位。如果单个任务导致 worker 超过此限制，该任务将完成，然后 worker 将被替换。</p> <p>示例：</p> <pre><code>worker_max_memory_per_child = 12288  # 12 * 1024 = 12 MB\n</code></pre>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_disable_rate_limits","level":4,"title":"<code>worker_disable_rate_limits</code>","text":"<p>默认值：禁用（速率限制启用）。</p> <p>禁用所有速率限制，即使任务设置了明确的速率限制。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_state_db","level":4,"title":"<code>worker_state_db</code>","text":"<p>默认值：<code>None</code>。</p> <p>用于存储持久化 worker 状态（如已撤销任务）的文件名。 可以是相对路径或绝对路径，但请注意后缀 <code>.db</code> 可能会附加到文件名（取决于 Python 版本）。</p> <p>也可以通过 <code>celery worker --statedb</code> 参数设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_timer_precision","level":4,"title":"<code>worker_timer_precision</code>","text":"<p>默认值：1.0 秒。</p> <p>设置 ETA 调度器在重新检查调度之间可以休眠的最大时间（以秒为单位）。</p> <p>将此值设置为 1 秒意味着调度器的精度将为 1 秒。如果您需要接近毫秒的精度，可以将其设置为 0.1。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_enable_remote_control","level":4,"title":"<code>worker_enable_remote_control</code>","text":"<p>默认值：默认启用。</p> <p>指定是否启用 workers 的远程控制。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_proc_alive_timeout","level":4,"title":"<code>worker_proc_alive_timeout</code>","text":"<p>默认值：4.0。</p> <p>等待新 worker 进程启动的超时时间（以秒为单位，int/float）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_cancel_long_running_tasks_on_connection_loss","level":4,"title":"<code>worker_cancel_long_running_tasks_on_connection_loss</code>","text":"<p>默认值：默认禁用。</p> <p>在连接丢失时杀死所有启用了延迟确认的长时间运行任务。</p> <p>在连接丢失之前未被确认的任务无法再被确认，因为它们的通道已消失，并且任务被重新传递回队列。这就是为什么启用了延迟确认的任务必须是幂等的，因为它们可能被执行多次。在这种情况下，每次连接丢失时任务都会被执行两次（有时在其他 workers 中并行执行）。</p> <p>当启用此选项时，那些尚未完成的任务将被取消并终止其执行。在连接丢失之前以任何方式完成的任务都会在结果后端中记录，只要 <code>task_ignore_result</code> 未被启用。</p> <p>Warning</p> <p>此功能是作为未来的破坏性变更引入的。如果关闭此功能，Celery 将发出警告消息。</p> <p>在 Celery 6.0 中，<code>worker_cancel_long_running_tasks_on_connection_loss</code> 将默认设置为 <code>True</code>，因为当前行为带来的问题比解决的问题更多。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_detect_quorum_queues","level":4,"title":"<code>worker_detect_quorum_queues</code>","text":"<p>默认值：启用。</p> <p>自动检测 <code>task_queues</code> 中的任何队列是否为仲裁队列（包括 <code>task_default_queue</code>），如果检测到任何仲裁队列，则禁用全局 QoS。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_soft_shutdown_timeout","level":4,"title":"<code>worker_soft_shutdown_timeout</code>","text":"<p>默认值：0.0。</p> <p>标准的 软关闭 将在关闭之前等待所有任务完成，除非触发了冷关闭。软关闭 将在启动冷关闭之前添加一个等待时间。此设置指定 worker 在启动冷关闭并终止之前将等待多长时间。</p> <p>这也适用于 worker 在没有先进行热关闭的情况下启动 冷关闭 时。</p> <p>如果该值设置为 0.0，软关闭实际上将被禁用。无论值如何，如果没有任务正在运行，软关闭将被禁用（除非启用了 <code>worker_enable_soft_shutdown_on_idle</code>）。</p> <p>尝试使用此值来找到在 worker 终止之前任务优雅完成的最佳时间。推荐值可以是 10、30、60 秒。太高的值可能导致 worker 终止前等待时间过长，并触发 <code>KILL</code> 信号由主机系统强制终止 worker。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_enable_soft_shutdown_on_idle","level":4,"title":"<code>worker_enable_soft_shutdown_on_idle</code>","text":"<p>默认值：False。</p> <p>如果 <code>worker_soft_shutdown_timeout</code> 设置为大于 0.0 的值，如果没有任务正在运行，worker 将跳过 软关闭。此设置将启用软关闭，即使没有任务正在运行。</p> <p>Tip</p> <p>当 worker 接收到 ETA 任务，但 ETA 尚未到达，并且启动了关闭时，如果没有任务正在运行，worker 将跳过软关闭并立即启动冷关闭。这可能导致在 worker 拆卸期间重新排队 ETA 任务失败。为了缓解这种情况，启用此配置以确保 worker 无论如何都会等待，这为优雅关闭和成功重新排队 ETA 任务提供了足够的时间。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#events","level":3,"title":"Events","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_send_task_events","level":4,"title":"<code>worker_send_task_events</code>","text":"<p>默认值：默认禁用。</p> <p>发送任务相关事件，以便可以使用像 <code>flower</code> 这样的工具来监控任务。设置工作者的默认值 <code>celery worker -E</code> 参数。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#task_send_sent_event","level":4,"title":"<code>task_send_sent_event</code>","text":"<p>默认值：默认禁用。</p> <p>如果启用，将为每个任务发送一个 <code>task-sent</code> 事件，以便在任务被工作者消费之前可以跟踪它们。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#event_queue_ttl","level":4,"title":"<code>event_queue_ttl</code>","text":"<p>默认值：5.0 秒。</p> <p>消息过期时间（秒，整数/浮点数），用于当发送到监控客户端事件队列的消息被删除时（<code>x-message-ttl</code>）。</p> <p>例如，如果此值设置为 10，则传递到此队列的消息将在 10 秒后被删除。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#event_queue_expires","level":4,"title":"<code>event_queue_expires</code>","text":"<p>默认值：60.0 秒。</p> <p>过期时间（秒，整数/浮点数），用于在监控客户端事件队列将被删除时（<code>x-expires</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#event_queue_durable","level":4,"title":"<code>event_queue_durable</code>","text":"<p>默认值：<code>False</code></p> <p>如果启用，事件接收器的队列将被标记为 持久化，意味着它将在代理重启后继续存在。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#event_queue_exclusive","level":4,"title":"<code>event_queue_exclusive</code>","text":"<p>默认值：<code>False</code></p> <p>如果启用，事件队列将 独占 于当前连接，并在连接关闭时自动删除。</p> <p>Warning</p> <p>您 不能 同时将 <code>event_queue_durable</code> 和 <code>event_queue_exclusive</code> 设置为 <code>True</code>。 如果两者都设置，Celery 将引发 :exc:<code>ImproperlyConfigured</code> 错误。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#event_queue_prefix","level":4,"title":"<code>event_queue_prefix</code>","text":"<p>默认值：<code>\"celeryev\"</code>。</p> <p>用于事件接收器队列名称的前缀。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#event_exchange","level":4,"title":"<code>event_exchange</code>","text":"<p>默认值：<code>\"celeryev\"</code>。</p> <p>事件交换器的名称。</p> <p>Warning</p> <p>此选项处于实验阶段，请谨慎使用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#event_serializer","level":4,"title":"<code>event_serializer</code>","text":"<p>默认值：<code>\"json\"</code>。</p> <p>发送事件消息时使用的消息序列化格式。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#events_logfile","level":4,"title":"<code>events_logfile</code>","text":"<p>默认值：<code>None</code></p> <p><code>celery events</code> 用于记录日志的可选文件路径（默认为 <code>stdout</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#events_pidfile","level":4,"title":"<code>events_pidfile</code>","text":"<p>默认值：<code>None</code></p> <p><code>celery events</code> 用于创建/存储其 PID 文件的可选文件路径（默认为不创建 PID 文件）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#events_uid","level":4,"title":"<code>events_uid</code>","text":"<p>默认值：<code>None</code></p> <p>当事件 <code>celery events</code> 降低其权限时使用的可选用户 ID（默认为不更改 UID）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#events_gid","level":4,"title":"<code>events_gid</code>","text":"<p>默认值：<code>None</code></p> <p>当 <code>celery events</code> 守护进程降低其权限时使用的可选组 ID（默认为不更改 GID）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#events_umask","level":4,"title":"<code>events_umask</code>","text":"<p>默认值：<code>None</code></p> <p>当 <code>celery events</code> 在守护进程化时创建文件（日志、pid 等）时使用的可选 <code>umask</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#events_executable","level":4,"title":"<code>events_executable</code>","text":"<p>默认值：<code>None</code></p> <p><code>celery events</code> 在守护进程化时使用的可选 <code>python</code> 可执行文件路径（默认为 :data:<code>sys.executable</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_22","level":3,"title":"远程控制命令","text":"<p>Note</p> <p>要禁用远程控制命令，请参阅 <code>worker_enable_remote_control</code> 设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#control_queue_ttl","level":4,"title":"<code>control_queue_ttl</code>","text":"<p>默认值：300.0</p> <p>时间（以秒为单位），远程控制命令队列中的消息在过期之前的时间。</p> <p>如果使用默认的300秒，这意味着如果发送了远程控制命令，并且在300秒内没有工作进程拾取它，该命令将被丢弃。</p> <p>此设置也适用于远程控制回复队列。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#control_queue_expires","level":4,"title":"<code>control_queue_expires</code>","text":"<p>默认值：10.0</p> <p>时间（以秒为单位），未使用的远程控制命令队列从代理中删除之前的时间。</p> <p>此设置也适用于远程控制回复队列。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#control_exchange","level":4,"title":"<code>control_exchange</code>","text":"<p>默认值：<code>\"celery\"</code>。</p> <p>控制命令交换的名称。</p> <p>Warning</p> <p>此选项处于实验阶段，请谨慎使用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#control_queue_durable","level":3,"title":"<code>control_queue_durable</code>","text":"<p>默认值：<code>False</code></p> <p>类型：<code>bool</code></p> <p>如果设置为 <code>True</code>，控制交换机和队列将是持久的——它们将在代理重启后继续存在。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#control_queue_exclusive","level":3,"title":"<code>control_queue_exclusive</code>","text":"<p>默认值：<code>False</code></p> <p>类型：<code>bool</code></p> <p>如果设置为 <code>True</code>，控制队列将专属于单个连接。在分布式环境中通常不推荐这样做。</p> <p>Warning</p> <p>同时将 <code>control_queue_durable</code> 和 <code>control_queue_exclusive</code> 设置为 <code>True</code> 是不支持的，会引发错误。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_23","level":3,"title":"日志记录","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_hijack_root_logger","level":4,"title":"<code>worker_hijack_root_logger</code>","text":"<p>默认值：默认启用（劫持根日志记录器）。</p> <p>默认情况下，根日志记录器上任何先前配置的处理程序都将被移除。如果您想要自定义自己的日志处理程序，可以通过设置 <code>worker_hijack_root_logger = False</code> 来禁用此行为。</p> <p>Note</p> <p>日志记录也可以通过连接到 <code>celery.signals.setup_logging</code> 信号来自定义。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_log_color","level":4,"title":"<code>worker_log_color</code>","text":"<p>默认值：如果应用程序正在记录到终端，则启用。</p> <p>启用/禁用 Celery 应用程序日志输出中的颜色。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_log_format","level":4,"title":"<code>worker_log_format</code>","text":"<p>默认值：</p> <pre><code>\"[%(asctime)s: %(levelname)s/%(processName)s] %(message)s\"\n</code></pre> <p>用于日志消息的格式。</p> <p>有关日志格式的更多信息，请参阅 Python <code>logging</code> 模块。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_task_log_format","level":4,"title":"<code>worker_task_log_format</code>","text":"<p>默认值：</p> <pre><code>\"[%(asctime)s: %(levelname)s/%(processName)s]\n        %(task_name)s[%(task_id)s]: %(message)s\"\n</code></pre> <p>用于任务中记录的日志消息的格式。</p> <p>有关日志格式的更多信息，请参阅 Python <code>logging</code> 模块。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_redirect_stdouts","level":4,"title":"<code>worker_redirect_stdouts</code>","text":"<p>默认值：默认启用。</p> <p>如果启用，<code>stdout</code> 和 <code>stderr</code> 将被重定向到当前日志记录器。</p> <p>由 <code>celery worker</code> 和 <code>celery beat</code> 使用。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_redirect_stdouts_level","level":4,"title":"<code>worker_redirect_stdouts_level</code>","text":"<p>默认值：<code>WARNING</code>。</p> <p>输出到 <code>stdout</code> 和 <code>stderr</code> 的日志级别。可以是 <code>DEBUG</code>、<code>INFO</code>、<code>WARNING</code>、<code>ERROR</code> 或 <code>CRITICAL</code> 之一。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_24","level":3,"title":"安全","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#security_key","level":4,"title":"<code>security_key</code>","text":"<p>默认值: <code>None</code>.</p> <p>包含私钥的文件的相对或绝对路径，当使用 <code>message-signing</code> 时用于签名消息。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#security_key_password","level":4,"title":"<code>security_key_password</code>","text":"<p>默认值: <code>None</code>.</p> <p>当使用 <code>message-signing</code> 时用于解密私钥的密码。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#security_certificate","level":4,"title":"<code>security_certificate</code>","text":"<p>默认值: <code>None</code>.</p> <p>X.509 证书文件的相对或绝对路径，当使用 <code>message-signing</code> 时用于签名消息。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#security_cert_store","level":4,"title":"<code>security_cert_store</code>","text":"<p>默认值: <code>None</code>.</p> <p>包含用于 <code>message-signing</code> 的 X.509 证书的目录。可以是带有通配符的 glob 模式，（例如 <code>/etc/certs/*.pem</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#security_digest","level":4,"title":"<code>security_digest</code>","text":"<p>默认值: <code>sha256</code>.</p> <p>当使用 <code>message-signing</code> 时用于签名消息的加密摘要。 https://cryptography.io/en/latest/hazmat/primitives/cryptographic-hashes/#module-cryptography.hazmat.primitives.hashes</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#_25","level":3,"title":"自定义组件类（高级）","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_pool","level":4,"title":"<code>worker_pool</code>","text":"<p>Default: <code>\"prefork\"</code> (<code>celery.concurrency.prefork:TaskPool</code>).</p> <p>工作进程使用的池类名称。</p> <p>Eventlet/Gevent</p> <p>切勿使用此选项来选择 eventlet 或 gevent 池。您必须使用 <code>celery worker -P</code> 选项来 <code>celery worker</code>，以确保猴子补丁不会应用得太晚，导致以奇怪的方式出现问题。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_pool_restarts","level":4,"title":"<code>worker_pool_restarts</code>","text":"<p>Default: 默认禁用。</p> <p>如果启用，可以使用 <code>pool_restart</code> 远程控制命令重新启动工作进程池。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_autoscaler","level":4,"title":"<code>worker_autoscaler</code>","text":"<p>Default: <code>\"celery.worker.autoscale:Autoscaler\"</code>.</p> <p>要使用的自动缩放器类名称。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_consumer","level":4,"title":"<code>worker_consumer</code>","text":"<p>Default: <code>\"celery.worker.consumer:Consumer\"</code>.</p> <p>工作进程使用的消费者类名称。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_timer","level":4,"title":"<code>worker_timer</code>","text":"<p>Default: <code>\"kombu.asynchronous.hub.timer:Timer\"</code>.</p> <p>工作进程使用的 ETA 调度器类名称。默认由池实现设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_logfile","level":4,"title":"<code>worker_logfile</code>","text":"<p>Default: <code>None</code></p> <p><code>celery worker</code> 的可选文件路径，用于记录日志（默认为 <code>stdout</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_pidfile","level":4,"title":"<code>worker_pidfile</code>","text":"<p>Default: <code>None</code></p> <p>:<code>celery worker</code> 的可选文件路径，用于创建/存储其 PID 文件（默认为不创建 PID 文件）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_uid","level":4,"title":"<code>worker_uid</code>","text":"<p>Default: <code>None</code></p> <p>当 <code>celery worker</code> 守护进程降低其权限时使用的可选用户 ID（默认为不更改 UID）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_gid","level":4,"title":"<code>worker_gid</code>","text":"<p>Default: <code>None</code></p> <p>当 <code>celery worker</code> 守护进程降低其权限时使用的可选组 ID（默认为不更改 GID）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_umask","level":4,"title":"<code>worker_umask</code>","text":"<p>Default: <code>None</code></p> <p>当 <code>celery worker</code> 守护进程创建文件（日志、pid 等）时使用的可选 <code>umask</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#worker_executable","level":4,"title":"<code>worker_executable</code>","text":"<p>Default: <code>None</code></p> <p>:<code>celery worker</code> 在守护进程化时使用的可选 <code>python</code> 可执行文件路径（默认为 :data:<code>sys.executable</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat-settings-celery-beat","level":3,"title":"Beat Settings (<code>celery beat</code>)","text":"","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_schedule","level":4,"title":"<code>beat_schedule</code>","text":"<p>默认值：<code>{}</code>（空映射）。</p> <p>由 <code>celery.bin.beat</code> 使用的周期性任务计划。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_scheduler","level":4,"title":"<code>beat_scheduler</code>","text":"<p>默认值：<code>\"celery.beat:PersistentScheduler\"</code>。</p> <p>默认的调度器类。例如，如果与 <code>django-celery-beat</code> 扩展一起使用，可以设置为 <code>\"django_celery_beat.schedulers:DatabaseScheduler\"</code>。</p> <p>也可以通过 <code>celery beat -S</code> 参数设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_schedule_filename","level":4,"title":"<code>beat_schedule_filename</code>","text":"<p>默认值：<code>\"celerybeat-schedule\"</code>。</p> <p><code>PersistentScheduler</code> 用于存储周期性任务最后运行时间的文件名。可以是相对路径或绝对路径，但要注意后缀 <code>.db</code> 可能会附加到文件名上（取决于 Python 版本）。</p> <p>也可以通过 <code>celery beat --schedule</code> 参数设置。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_sync_every","level":4,"title":"<code>beat_sync_every</code>","text":"<p>默认值：0。</p> <p>在发出另一个数据库同步之前可以调用的周期性任务数量。值为 0（默认）表示基于时间的同步 - 由 scheduler.sync_every 确定的默认值为 3 分钟。如果设置为 1，beat 将在每个任务消息发送后调用同步。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_max_loop_interval","level":4,"title":"<code>beat_max_loop_interval</code>","text":"<p>默认值：0。</p> <p><code>celery.bin.beat</code> 在检查计划之间可以睡眠的最大秒数。</p> <p>此值的默认值取决于调度器。对于默认的 Celery beat 调度器，该值为 300（5 分钟），但对于 <code>django-celery-beat</code> 数据库调度器，它是 5 秒，因为计划可能会在外部更改，因此必须考虑对计划的更改。</p> <p>此外，当在 Jython 上作为线程运行嵌入式 Celery beat（<code>celery worker -B</code>）时，最大间隔会被覆盖并设置为 1，以便能够及时关闭。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_cron_starting_deadline","level":4,"title":"<code>beat_cron_starting_deadline</code>","text":"<p>默认值：None。</p> <p>使用 cron 时，<code>celery.bin.beat</code> 在决定 cron 计划是否到期时可以回溯的秒数。当设置为 <code>None</code> 时，过期的 cron 作业将始终立即运行。</p> <p>Warning</p> <p>强烈不建议将此值设置为高于 3600（1 小时）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_logfile","level":4,"title":"<code>beat_logfile</code>","text":"<p>默认值：<code>None</code></p> <p><code>celery beat</code> 用于记录日志的可选文件路径（默认为 <code>stdout</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_pidfile","level":4,"title":"<code>beat_pidfile</code>","text":"<p>默认值：<code>None</code></p> <p><code>celery beat</code> 用于创建/存储其 PID 文件的可选文件路径（默认为不创建 PID 文件）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_uid","level":4,"title":"<code>beat_uid</code>","text":"<p>默认值：<code>None</code></p> <p>当 <code>celery beat</code> 降低其权限时使用的可选用户 ID（默认为不更改 UID）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_gid","level":4,"title":"<code>beat_gid</code>","text":"<p>默认值：<code>None</code></p> <p>当 <code>celery beat</code> 守护进程降低其权限时使用的可选组 ID（默认为不更改 GID）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_umask","level":4,"title":"<code>beat_umask</code>","text":"<p>默认值：<code>None</code></p> <p>当 <code>celery beat</code> 在守护进程化时创建文件（日志、pid 等）时使用的可选 <code>umask</code>。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/configuration/#beat_executable","level":4,"title":"<code>beat_executable</code>","text":"<p>默认值：<code>None</code></p> <p><code>celery beat</code> 在守护进程化时使用的可选 <code>python</code> 可执行文件路径（默认为 <code>sys.executable</code>）。</p>","path":["用户指南","配置和默认值"],"tags":[]},{"location":"user-guide/daemonizing/","level":1,"title":"守护进程","text":"<p>如今大多数 Linux 发行版都使用 systemd 来管理系统和用户服务的生命周期。</p> <p>您可以通过输入以下命令来检查您的 Linux 发行版是否使用 systemd：</p> <pre><code>systemctl --version\nsystemd 249 (v249.9-1.fc35)\n+PAM +AUDIT +SELINUX -APPARMOR +IMA +SMACK +SECCOMP +GCRYPT +GNUTLS +OPENSSL +ACL +BLKID +CURL +ELFUTILS +FIDO2 +IDN2 -IDN +IPTC +KMOD +LIBCRYPTSETUP +LIBFDISK +PCRE2 +PWQUALITY +P11KIT +QRENCODE +BZIP2 +LZ4 +XZ +ZLIB +ZSTD +XKBCOMMON +UTMP +SYSVINIT default-hierarchy=unified\n</code></pre> <p>如果您有类似的输出，请参考 使用 systemd 获取指导。</p> <p>然而，init.d 脚本在这些 Linux 发行版中仍然应该有效，因为 systemd 提供了 systemd-sysv 兼容层，它会自动从我们提供的 init.d 脚本生成服务。</p> <p>如果您为多个 Linux 发行版打包 Celery，并且其中一些不支持 systemd，或者也面向其他 Unix 系统，您可能需要参考 通用初始化脚本。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#daemon-generic","level":2,"title":"通用初始化脚本","text":"<p>请参阅 Celery 发行版中的 extra/generic-init.d/ 目录。</p> <p>该目录包含用于 <code>celery worker</code> 程序的通用 bash 初始化脚本，这些脚本应该可以在 Linux、FreeBSD、OpenBSD 和其他类 Unix 平台上运行。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#celeryd","level":3,"title":"初始化脚本: <code>celeryd</code>","text":"<p>用法: <code>/etc/init.d/celeryd {start|stop|restart|status}</code></p> <p>配置文件: <code>/etc/default/celeryd</code></p> <p>要正确配置此脚本以运行 worker，您至少需要告诉它在启动时切换到哪个目录（以找到包含您的应用程序或配置模块的模块）。</p> <p>守护进程脚本由文件 <code>/etc/default/celeryd</code> 配置。这是一个 shell (<code>sh</code>) 脚本，您可以在其中添加环境变量，如下面的配置选项所示。要添加影响 worker 的实际环境变量，您还必须导出它们（例如，<code>export DISPLAY=\":0\"</code>）</p> <p>需要超级用户权限</p> <p>初始化脚本只能由 root 用户使用，并且 shell 配置文件也必须归 root 所有。</p> <p>非特权用户不需要使用初始化脚本，而是可以使用 <code>celery multi</code> 实用程序（或 <code>celery worker --detach</code>）：</p> <pre><code>celery -A proj multi start worker1 \\\n    --pidfile=\"$HOME/run/celery/%n.pid\" \\\n    --logfile=\"$HOME/log/celery/%n%I.log\"\n\ncelery -A proj multi restart worker1 \\\n    --logfile=\"$HOME/log/celery/%n%I.log\" \\\n    --pidfile=\"$HOME/run/celery/%n.pid\n\ncelery multi stopwait worker1 --pidfile=\"$HOME/run/celery/%n.pid\"\n</code></pre>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#_2","level":4,"title":"示例配置","text":"<p>这是一个 Python 项目的示例配置。</p> /etc/default/celeryd<pre><code># 要启动的节点名称\n#   大多数人只会启动一个节点：\nCELERYD_NODES=\"worker1\"\n#   但您也可以启动多个节点并在 CELERYD_OPTS 中为每个节点配置设置\n#CELERYD_NODES=\"worker1 worker2 worker3\"\n#   或者，您可以指定要启动的节点数量：\n#CELERYD_NODES=10\n\n# 'celery' 命令的绝对或相对路径：\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# 要使用的应用程序实例\n# 如果不使用应用程序，请注释掉此行\nCELERY_APP=\"proj\"\n# 或完全限定：\n#CELERY_APP=\"proj.tasks:app\"\n\n# 启动时要切换到的目录。\nCELERYD_CHDIR=\"/opt/Myproject/\"\n\n# 传递给 worker 的额外命令行参数\nCELERYD_OPTS=\"--time-limit=300 --concurrency=8\"\n# 通过将节点名称附加到参数来配置特定于节点的设置：\n#CELERYD_OPTS=\"--time-limit=300 -c 8 -c:worker2 4 -c:worker3 2 -Ofair:worker1\"\n\n# 将日志级别设置为 DEBUG\n#CELERYD_LOG_LEVEL=\"DEBUG\"\n\n# %n 将被替换为节点名称的第一部分。\nCELERYD_LOG_FILE=\"/var/log/celery/%n%I.log\"\nCELERYD_PID_FILE=\"/var/run/celery/%n.pid\"\n\n# Worker 应该以非特权用户身份运行。\n#   您需要手动创建此用户（或者您可以选择\n#   已经存在的用户/组组合（例如，nobody））。\nCELERYD_USER=\"celery\"\nCELERYD_GROUP=\"celery\"\n\n# 如果启用，将在缺失时创建 pid 和日志目录，\n# 并由配置的用户 ID/组拥有。\nCELERY_CREATE_DIRS=1\n</code></pre>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#shell","level":3,"title":"使用登录 shell","text":"<p>您可以通过使用登录 shell 来继承 <code>CELERYD_USER</code> 的环境：</p> <pre><code>CELERYD_SU_ARGS=\"-l\"\n</code></pre> <p>请注意，这不被推荐，您应该只在绝对必要时使用此选项。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#django","level":3,"title":"Django 示例配置","text":"<p>Django 用户现在使用与上面完全相同的模板，但请确保定义 Celery 应用程序实例的模块也为 <code>DJANGO_SETTINGS_MODULE</code> 设置了默认值，如 :ref:<code>django-first-steps</code> 中的示例 Django 项目所示。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#_3","level":3,"title":"可用选项","text":"选项 描述 <code>CELERY_APP</code>  要使用的应用程序实例（<code>celery --app</code> 参数的值）。  <code>CELERY_BIN</code> <code>celery</code> 程序的绝对或相对路径。 示例：  <code>celery</code> <code>/usr/local/bin/celery</code> <code>/virtualenvs/proj/bin/celery</code> <code>/virtualenvs/proj/bin/python -m celery</code> <code>CELERYD_NODES</code>  要启动的节点名称列表（用空格分隔）。  <code>CELERYD_OPTS</code>  worker 的额外命令行参数，请参阅 <code>celery worker --help</code> 获取列表。这也支持 <code>multi</code> 使用的扩展语法 来配置各个节点的设置。 请参阅 <code>celery multi --help</code> 获取一些多节点配置示例。  <code>CELERYD_CHDIR</code>  启动时要切换到的路径。默认是保持在当前目录。  <code>CELERYD_PID_FILE</code>  PID 文件的完整路径。默认是 /var/run/celery/%n.pid  <code>CELERYD_LOG_FILE</code>  worker 日志文件的完整路径。默认是 /var/log/celery/%n%I.log **注意**：在使用 prefork 池时，使用 <code>%I</code> 很重要，因为 多个进程共享同一个日志文件会导致竞争条件。  <code>CELERYD_LOG_LEVEL</code>  worker 日志级别。默认是 INFO。  <code>CELERYD_USER</code>  运行 worker 的用户。默认是当前用户。  <code>CELERYD_GROUP</code>  运行 worker 的组。默认是当前用户。  <code>CELERY_CREATE_DIRS</code>  始终创建目录（日志目录和 pid 文件目录）。 默认仅在未设置自定义日志文件/pid 文件时创建目录。  <code>CELERY_CREATE_RUNDIR</code>  始终创建 pid 文件目录。默认仅在未设置自定义 pid 文件位置时启用。  <code>CELERY_CREATE_LOGDIR</code>  始终创建日志文件目录。默认仅在未设置自定义日志文件位置时启用。","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#celerybeat","level":3,"title":"初始化脚本: <code>celerybeat</code>","text":"<p>用法: <code>/etc/init.d/celerybeat {start|stop|restart}</code></p> <p>配置文件: <code>/etc/default/celerybeat</code> 或 <code>/etc/default/celeryd</code>。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#_4","level":4,"title":"示例配置","text":"<p>这是一个 Python 项目的示例配置：</p> /etc/default/celerybeat<pre><code># 'celery' 命令的绝对或相对路径：\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# 要使用的应用程序实例\n# 如果不使用应用程序，请注释掉此行\nCELERY_APP=\"proj\"\n# 或完全限定：\n#CELERY_APP=\"proj.tasks:app\"\n\n# 启动时要切换到的目录。\nCELERYBEAT_CHDIR=\"/opt/Myproject/\"\n\n# 传递给 celerybeat 的额外参数\nCELERYBEAT_OPTS=\"--schedule=/var/run/celery/celerybeat-schedule\"\n</code></pre>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#django_1","level":4,"title":"Django 示例配置","text":"<p>您应该使用与上面相同的模板，但请确保 <code>DJANGO_SETTINGS_MODULE</code> 变量已设置（并导出），并且 <code>CELERYD_CHDIR</code> 设置为项目目录：</p> <pre><code>export DJANGO_SETTINGS_MODULE=\"settings\"\n\nCELERYD_CHDIR=\"/opt/MyProject\"\n</code></pre>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#_5","level":4,"title":"可用选项","text":"选项 描述 <code>CELERY_APP</code> 要使用的应用程序实例（<code>celery --app</code> 参数的值）。 <code>CELERYBEAT_OPTS</code> 传递给 <code>celery beat</code> 的额外参数，请参阅 <code>celery beat --help</code> 获取可用选项列表。 <code>CELERYBEAT_PID_FILE</code> PID 文件的完整路径。默认是 <code>/var/run/celeryd.pid</code>。 <code>CELERYBEAT_LOG_FILE</code> 日志文件的完整路径。默认是 <code>/var/log/celeryd.log</code>。 <code>CELERYBEAT_LOG_LEVEL</code> 要使用的日志级别。默认是 <code>INFO</code>。 <code>CELERYBEAT_USER</code> 运行 beat 的用户。默认是当前用户。 <code>CELERYBEAT_GROUP</code> 运行 beat 的组。默认是当前用户。 <code>CELERY_CREATE_DIRS</code> 始终创建目录（日志目录和 pid 文件目录）。默认仅在未设置自定义日志文件/pid 文件时创建目录。 <code>CELERY_CREATE_RUNDIR</code> 始终创建 pid 文件目录。默认仅在未设置自定义 pid 文件位置时启用。 <code>CELERY_CREATE_LOGDIR</code> 始终创建日志文件目录。默认仅在未设置自定义日志文件位置时启用。","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#_6","level":3,"title":"故障排除","text":"<p>如果无法使初始化脚本正常工作，您应该尝试在详细模式下运行它们：</p> <pre><code>sh -x /etc/init.d/celeryd start\n</code></pre> <p>这可以揭示服务无法启动的原因。</p> <p>如果 worker 以 \"OK\" 启动但几乎立即退出，并且日志文件中没有证据，那么可能存在错误，但由于守护进程的标准输出已经关闭，您将无法在任何地方看到它们。对于这种情况，您可以使用 <code>C_FAKEFORK</code> 环境变量跳过守护进程步骤：</p> <pre><code>C_FAKEFORK=1 sh -x /etc/init.d/celeryd start\n</code></pre> <p>现在您应该能够看到错误了。</p> <p>通常，此类错误是由文件读写权限不足、配置模块、用户模块、第三方库中的语法错误，甚至 Celery 本身引起的。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#daemon-systemd-generic","level":2,"title":"使用 <code>systemd</code>","text":"<p>用法: <code>systemctl {start|stop|restart|status} celery.service</code></p> <p>配置文件: <code>/etc/conf.d/celery</code></p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#celeryservice","level":3,"title":"服务文件: celery.service","text":"<p>这是一个示例的systemd文件：</p> /etc/systemd/system/celery.service<pre><code>[Unit]\nDescription=Celery Service\nAfter=network.target\n\n[Service]\nType=forking\nUser=celery\nGroup=celery\nEnvironmentFile=/etc/conf.d/celery\nWorkingDirectory=/opt/celery\nExecStart=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi start $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS'\nExecStop=/bin/sh -c '${CELERY_BIN} multi stopwait $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\"'\nExecReload=/bin/sh -c '${CELERY_BIN} -A $CELERY_APP multi restart $CELERYD_NODES \\\n    --pidfile=${CELERYD_PID_FILE} --logfile=${CELERYD_LOG_FILE} \\\n    --loglevel=\"${CELERYD_LOG_LEVEL}\" $CELERYD_OPTS'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>一旦你将该文件放入 <code>/etc/systemd/system</code>，你应该运行 <code>systemctl daemon-reload</code> 以便Systemd识别该文件。每次修改该文件时，你也应该运行该命令。如果你希望 celery 服务在系统（重新）启动时自动启动，请使用 <code>systemctl enable celery.service</code>。</p> <p>可选地，你可以为celery服务指定额外的依赖项：例如，如果你使用 RabbitMQ 作为代理，你可以在 <code>[Unit]</code> systemd部分 中的 <code>After=</code> 和 <code>Requires=</code> 中指定 <code>rabbitmq-server.service</code>。</p> <p>要配置用户、组、<code>chdir</code> 更改设置：在 <code>/etc/systemd/system/celery.service</code> 中定义的 <code>User</code>、<code>Group</code> 和 <code>WorkingDirectory</code>。</p> <p>你也可以使用 <code>systemd-tmpfiles</code> 来创建工作目录（用于日志和 pid 文件）。</p> /etc/tmpfiles.d/celery.conf<pre><code>d /run/celery 0755 celery celery -\nd /var/log/celery 0755 celery celery -\n</code></pre>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#_7","level":4,"title":"示例配置","text":"<p>这是一个Python项目的示例配置：</p> /etc/conf.d/celery<pre><code># 要启动的节点名称\n# 这里我们有一个单节点\nCELERYD_NODES=\"w1\"\n# 或者我们可以有三个节点：\n#CELERYD_NODES=\"w1 w2 w3\"\n\n# 'celery'命令的绝对或相对路径：\nCELERY_BIN=\"/usr/local/bin/celery\"\n#CELERY_BIN=\"/virtualenvs/def/bin/celery\"\n\n# 要使用的应用实例\n# 如果不使用应用，请注释掉这一行\nCELERY_APP=\"proj\"\n# 或者完全限定：\n#CELERY_APP=\"proj.tasks:app\"\n\n# 如何调用manage.py\nCELERYD_MULTI=\"multi\"\n\n# 工作进程的额外命令行参数\nCELERYD_OPTS=\"--time-limit=300 --concurrency=8\"\n\n# - %n 将被节点名称的第一部分替换。\n# - %I 将被当前子进程索引替换\n#   在使用prefork池时很重要，以避免竞争条件。\nCELERYD_PID_FILE=\"/var/run/celery/%n.pid\"\nCELERYD_LOG_FILE=\"/var/log/celery/%n%I.log\"\nCELERYD_LOG_LEVEL=\"INFO\"\n\n# 你可能希望为Celery Beat添加这些选项\nCELERYBEAT_PID_FILE=\"/var/run/celery/beat.pid\"\nCELERYBEAT_LOG_FILE=\"/var/log/celery/beat.log\"\n</code></pre>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#celerybeatservice","level":3,"title":"服务文件: celerybeat.service","text":"<p>这是一个Celery Beat的示例systemd文件：</p> /etc/systemd/system/celerybeat.service<pre><code>[Unit]\nDescription=Celery Beat Service\nAfter=network.target\n\n[Service]\nType=simple\nUser=celery\nGroup=celery\nEnvironmentFile=/etc/conf.d/celery\nWorkingDirectory=/opt/celery\nExecStart=/bin/sh -c '${CELERY_BIN} -A ${CELERY_APP} beat  \\\n    --pidfile=${CELERYBEAT_PID_FILE} \\\n    --logfile=${CELERYBEAT_LOG_FILE} --loglevel=${CELERYD_LOG_LEVEL}'\nRestart=always\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>一旦你将该文件放入 <code>/etc/systemd/system</code>，你应该运行 <code>systemctl daemon-reload</code> 以便 Systemd 识别该文件。每次修改该文件时，你也应该运行该命令。如果你希望 celery beat 服务在系统（重新）启动时自动启动，请使用 <code>systemctl enable celerybeat.service</code>。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/daemonizing/#root","level":2,"title":"使用超级用户权限（root）运行工作进程","text":"<p>使用超级用户权限运行工作进程是一种非常危险的做法。应该总是有避免以 root 身份运行的解决方案。Celery 可能会在通过 pickle 序列化的消息中运行任意代码 - 这是危险的，尤其是在以 root 身份运行时。</p> <p>默认情况下，Celery不会以root身份运行工作进程。相关的错误消息可能不会在日志中可见，但如果使用了 <code>C_FAKEFORK</code> 则可能会看到。</p> <p>要强制 Celery 以 root 身份运行工作进程，请使用 <code>C_FORCE_ROOT</code>。</p> <p>当以 root 身份运行但没有 <code>C_FORCE_ROOT</code> 时，工作进程将显示以 \"OK\" 启动，但随后立即退出且无明显错误。这个问题可能会在新的开发或生产环境中（无意中）以root身份运行项目时出现。</p>","path":["用户指南","守护进程"],"tags":[]},{"location":"user-guide/debugging/","level":1,"title":"调试","text":"","path":["用户指南","调试"],"tags":[]},{"location":"user-guide/debugging/#pdb","level":2,"title":"远程调试任务（使用 pdb）","text":"","path":["用户指南","调试"],"tags":[]},{"location":"user-guide/debugging/#_2","level":3,"title":"基础","text":"<p><code>celery.contrib.rdb</code> 是 <code>pdb</code> 的扩展版本，它允许对没有终端访问权限的进程进行远程调试。</p> <p>使用示例：</p> <pre><code>from celery import task\nfrom celery.contrib import rdb\n\n@task()\ndef add(x, y):\n    result = x + y\n    rdb.set_trace()  # &lt;- 设置断点\n    return result\n</code></pre> <p><code>celery.contrib.rdb.set_trace()</code> 在当前位置设置断点，并创建一个可以通过 telnet 连接的 socket，以便远程调试你的任务。</p> <p>调试器可能会被多个进程同时启动，因此调试器不会使用固定端口，而是从基础端口（默认为 6900）开始搜索可用端口。可以通过环境变量 <code>CELERY_RDB_PORT</code> 更改基础端口。</p> <p>默认情况下，调试器只能从本地主机访问，要启用外部访问，必须设置环境变量 <code>CELERY_RDB_HOST</code>。</p> <p>当工作进程遇到你的断点时，它将记录以下信息：</p> <pre><code>[INFO/MainProcess] Received task:\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8]\n[WARNING/PoolWorker-1] Remote Debugger:6900:\n    Please telnet 127.0.0.1 6900.  Type `exit` in session to continue.\n[2011-01-18 14:25:44,119: WARNING/PoolWorker-1] Remote Debugger:6900:\n    Waiting for client...\n</code></pre> <p>如果你 telnet 到指定的端口，你将看到一个 <code>pdb</code> shell：</p> <pre><code>$ telnet localhost 6900\nConnected to localhost.\nEscape character is '^]'.\n&gt; /opt/devel/demoapp/tasks.py(128)add()\n-&gt; return result\n(Pdb)\n</code></pre> <p>输入 <code>help</code> 获取可用命令列表，如果你从未使用过 <code>pdb</code>，阅读 Python 调试器手册 可能是个好主意。</p> <p>为了演示，我们将读取 <code>result</code> 变量的值，更改它并继续执行任务：</p> <pre><code>(Pdb) result\n4\n(Pdb) result = 'hello from rdb'\n(Pdb) continue\nConnection closed by foreign host.\n</code></pre> <p>我们的修改结果可以在工作进程日志中看到：</p> <pre><code>[2011-01-18 14:35:36,599: INFO/MainProcess] Task\n    tasks.add[d7261c71-4962-47e5-b342-2448bedd20e8] succeeded\n    in 61.481s: 'hello from rdb'\n</code></pre>","path":["用户指南","调试"],"tags":[]},{"location":"user-guide/debugging/#_3","level":3,"title":"提示","text":"","path":["用户指南","调试"],"tags":[]},{"location":"user-guide/debugging/#_4","level":4,"title":"启用断点信号","text":"<p>如果设置了环境变量 <code>CELERY_RDBSIG</code>，工作进程将在每次发送 <code>SIGUSR2</code> 信号时打开一个 rdb 实例。这适用于主进程和工作进程。</p> <p>例如，使用以下命令启动工作进程：</p> <pre><code>CELERY_RDBSIG=1 celery worker -l INFO\n</code></pre> <p>你可以通过执行以下命令为任何工作进程启动 rdb 会话：</p> <pre><code>kill -USR2 &lt;pid&gt;\n</code></pre>","path":["用户指南","调试"],"tags":[]},{"location":"user-guide/extending/","level":1,"title":"扩展和启动步骤","text":"","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_2","level":2,"title":"自定义消息消费者","text":"<p>您可能希望嵌入自定义的 Kombu 消费者来手动处理消息。</p> <p>为此，存在一个特殊的 <code>celery.bootstep.ConsumerStep</code> 启动步骤类，您只需要定义 <code>get_consumers</code> 方法，该方法必须返回一个 <code>kombu.Consumer</code> 对象列表，在连接建立时启动：</p> <pre><code>from celery import Celery\nfrom celery import bootsteps\nfrom kombu import Consumer, Exchange, Queue\n\nmy_queue = Queue('custom', Exchange('custom'), 'routing_key')\n\napp = Celery(broker='amqp://')\n\n\nclass MyConsumerStep(bootsteps.ConsumerStep):\n\n    def get_consumers(self, channel):\n        return [Consumer(channel,\n                         queues=[my_queue],\n                         callbacks=[self.handle_message],\n                         accept=['json'])]\n\n    def handle_message(self, body, message):\n        print('Received message: {0!r}'.format(body))\n        message.ack()\napp.steps['consumer'].add(MyConsumerStep)\n\ndef send_me_a_message(who, producer=None):\n    with app.producer_or_acquire(producer) as producer:\n        producer.publish(\n            {'hello': who},\n            serializer='json',\n            exchange=my_queue.exchange,\n            routing_key='routing_key',\n            declare=[my_queue],\n            retry=True,\n        )\n\n\nif __name__ == '__main__':\n    send_me_a_message('world!')\n</code></pre> <p>Note</p> <p>Kombu 消费者可以使用两种不同的消息回调分发机制。第一种是 <code>callbacks</code> 参数，它接受具有 <code>(body, message)</code> 签名的回调列表；第二种是 <code>on_message</code> 参数，它接受具有 <code>(message,)</code> 签名的单个回调。后者不会自动解码和反序列化有效载荷。</p> <pre><code>def get_consumers(self, channel):\n    return [Consumer(channel, queues=[my_queue],\n                     on_message=self.on_message)]\n\n\ndef on_message(self, message):\n    payload = message.decode()\n    print(\n        'Received message: {0!r} {props!r} rawlen={s}'.format(\n        payload, props=message.properties, s=len(message.body),\n    ))\n    message.ack()\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_3","level":2,"title":"蓝图","text":"<p>Bootsteps 是一种为工作器添加功能的技术。一个 bootstep 是一个自定义类，它定义了在工作器的不同阶段执行自定义操作的钩子。每个 bootstep 都属于一个蓝图，工作器目前定义了两个蓝图：Worker 和 Consumer</p>  Worker 和 Consumer 蓝图中的 Bootsteps。从下往上开始， worker 蓝图中的第一步是 Timer，最后一步是启动 Consumer 蓝图， 然后建立代理连接并开始消费消息。","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#worker","level":2,"title":"Worker","text":"<p>Worker 是第一个启动的蓝图，随之启动的还有主要组件，如事件循环、处理池以及用于 ETA 任务和其他定时事件的计时器。</p> <p>当 worker 完全启动后，它会继续执行 Consumer 蓝图，该蓝图设置了任务的执行方式，连接到 broker 并启动消息消费者。</p> <p><code>celery.worker.WorkController</code> 是核心的 worker 实现，包含您可以在 bootstep 中使用的多个方法和属性。</p>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_4","level":3,"title":"属性","text":"属性 描述 <code>app</code> 当前的 app 实例。 <code>hostname</code> worker 的节点名称（例如：<code>worker1@example.com</code>） <code>blueprint</code> 这是 worker 的 <code>celery.bootsteps.Blueprint</code>。 <code>hub</code>  事件循环对象 (<code>kombu.asynchronous.Hub</code>)。您可以使用它在事件循环中注册回调函数。 这仅受支持异步 I/O 的传输（amqp、redis）支持，在这种情况下，应设置 <code>worker.use_eventloop</code> 属性。 您的 worker bootstep 必须要求 Hub bootstep 才能使用此功能：  <pre><code>class WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Hub'}\n</code></pre> <code>pool</code>  当前进程/eventlet/gevent/线程池。参见 <code>celery.concurrency.base.BasePool</code>。 您的 worker bootstep 必须要求 Pool bootstep 才能使用此功能：  <pre><code>class WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Pool'}\n</code></pre> <code>timer</code> <code>kombu.asynchronous.timer.Timer</code> 用于调度函数。 您的 worker bootstep 必须要求 Timer bootstep 才能使用此功能：  <pre><code>class WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Timer'}\n</code></pre> <code>statedb</code> <code>celery.worker.state.Persistent</code> 用于在 worker 重启之间 持久化状态。 这仅在启用 <code>statedb</code> 参数时定义。 您的 worker bootstep 必须要求 <code>Statedb</code> bootstep 才能使用此功能：  <pre><code>class WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Statedb'}\n</code></pre> <code>autoscaler</code> <code>celery.worker.autoscaler.Autoscaler</code> 用于自动增长 和缩减池中的进程数量。 这仅在启用 <code>autoscale</code> 参数时定义。 您的 worker bootstep 必须要求 <code>Autoscaler</code> bootstep 才能使用此功能：  <pre><code>class WorkerStep(bootsteps.StartStopStep):\n    requires = ('celery.worker.components:Autoscaler',)\n</code></pre> <code>autoreloader</code> <code>celery.worker.autoreloader.Autoreloader</code> 用于在文件系统更改时自动重新加载使用代码。 这仅在启用 <code>autoreload</code> 参数时定义。 您的 worker bootstep 必须要求 <code>Autoreloader</code> bootstep 才能使用此功能：  <pre><code>class WorkerStep(bootsteps.StartStopStep):\n    requires = ('celery.worker.autoreloader:Autoreloader',)\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_5","level":3,"title":"示例","text":"<p>一个示例 Worker bootstep 可以是：</p> <pre><code>from celery import bootsteps\n\n\nclass ExampleWorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Pool'}\n\n    def __init__(self, worker, **kwargs):\n        print('Called when the WorkController instance is constructed')\n        print('Arguments to WorkController: {0!r}'.format(kwargs))\n\n    def create(self, worker):\n        # this method can be used to delegate the action methods\n        # to another object that implements `start` and `stop`.\n        return self\n\n    def start(self, worker):\n        print('Called when the worker is started.')\n\n    def stop(self, worker):\n        print('Called when the worker shuts down.')\n\n    def terminate(self, worker):\n        print('Called when the worker terminates')\n</code></pre> <p>每个方法都接收当前的 <code>WorkController</code> 实例作为第一个参数。</p> <p>另一个示例可以使用计时器定期唤醒：</p> <pre><code>from celery import bootsteps\n\n\nclass DeadlockDetection(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Timer'}\n\n    def __init__(self, worker, deadlock_timeout=3600):\n        self.timeout = deadlock_timeout\n        self.requests = []\n        self.tref = None\n\n    def start(self, worker):\n        # run every 30 seconds.\n        self.tref = worker.timer.call_repeatedly(\n            30.0, self.detect, (worker,), priority=10,\n        )\n\n    def stop(self, worker):\n        if self.tref:\n            self.tref.cancel()\n            self.tref = None\n\n    def detect(self, worker):\n        # update active requests\n        for req in worker.active_requests:\n            if req.time_start and time() - req.time_start &gt; self.timeout:\n                raise SystemExit()\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_6","level":3,"title":"自定义任务处理日志","text":"<p>Celery worker 会在任务生命周期的各个事件中向 Python 日志子系统发出消息。这些消息可以通过覆盖在 <code>celery/app/trace.py</code> 中定义的 <code>LOG_&lt;TYPE&gt;</code> 格式字符串来自定义。</p> <p>例如：</p> <pre><code>import celery.app.trace\n\ncelery.app.trace.LOG_SUCCESS = \"This is a custom message\"\n</code></pre> <p>各种格式字符串都提供了任务名称和 ID 用于 <code>%</code> 格式化，其中一些还接收额外的字段，如返回值或导致任务失败的异常。这些字段可以在自定义格式字符串中使用，如下所示：</p> <pre><code>import celery.app.trace\n\ncelery.app.trace.LOG_REJECTED = \"%(name)r is cursed and I won't run it: %(exc)s\"\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_7","level":2,"title":"消费者","text":"<p>Consumer 蓝图建立与代理（broker）的连接，并且每次连接丢失时都会重新启动。Consumer 启动步骤包括工作节点心跳、远程控制命令消费者，以及重要的任务消费者。</p> <p>当您创建 consumer 启动步骤时，必须考虑到必须能够重新启动您的蓝图。为 consumer 启动步骤定义了一个额外的 'shutdown' 方法，该方法在工作节点关闭时被调用。</p>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_8","level":3,"title":"属性","text":"属性 描述 <code>app</code>  当前的应用实例。  <code>controller</code>  创建此 consumer 的父级 <code>WorkController</code> 对象。  <code>hostname</code>  工作节点的名称（例如，<code>worker1@example.com</code>）  <code>blueprint</code>  这是工作节点的 <code>celery.bootsteps.Blueprint</code>。  <code>hub</code>  事件循环对象 (<code>kombu.asynchronous.Hub</code>)。您可以使用它在事件循环中注册回调函数。 这仅支持启用异步I/O的传输（amqp、redis），在这种情况下，应设置 <code>worker.use_eventloop</code> 属性。 您的工作节点启动步骤必须要求 <code>Hub</code> 启动步骤才能使用此功能：  <pre><code>class WorkerStep(bootsteps.StartStopStep):\n    requires = {'celery.worker.components:Hub'}\n</code></pre> <code>connection</code>  当前的代理连接 (<code>kombu.Connection</code>)。 consumer启动步骤必须要求 <code>Connection</code> 启动步骤才能使用此功能：  <pre><code>class Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.connection:Connection'}\n</code></pre> <code>event_dispatcher</code>  一个 <code>events.Dispatcher</code> 对象，可用于发送事件。 consumer 启动步骤必须要求 <code>Events</code> 启动步骤才能使用此功能。  <pre><code>class Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.events:Events'}\n</code></pre> <code>gossip</code>  工作节点之间的广播通信 (<code>celery.worker.consumer.gossip.Gossip</code>)。 consumer 启动步骤必须要求 <code>Gossip</code> 启动步骤才能使用此功能。  <pre><code>class RatelimitStep(bootsteps.StartStopStep):\n    \"\"\"基于集群中工作节点数量进行任务速率限制\"\"\"\n    requires = {'celery.worker.consumer.gossip:Gossip'}\n\n    def start(self, c):\n        self.c = c\n        self.c.gossip.on.node_join.add(self.on_cluster_size_change)\n        self.c.gossip.on.node_leave.add(self.on_cluster_size_change)\n        self.c.gossip.on.node_lost.add(self.on_node_lost)\n        self.tasks = [\n            self.app.tasks['proj.tasks.add']\n            self.app.tasks['proj.tasks.mul']\n        ]\n        self.last_size = None\n\n    def on_cluster_size_change(self, worker):\n        cluster_size = len(list(self.c.gossip.state.alive_workers()))\n        if cluster_size != self.last_size:\n            for task in self.tasks:\n                task.rate_limit = 1.0 / cluster_size\n            self.c.reset_rate_limits()\n            self.last_size = cluster_size\n\n    def on_node_lost(self, worker):\n        # 可能处理心跳过晚，因此尽快唤醒\n        # 以查看工作节点是否恢复\n        self.c.timer.call_after(10.0, self.on_cluster_size_change)\n</code></pre> 回调函数 <ul> <li> <code>&lt;set&gt; gossip.on.node_join</code>  每当新节点加入集群时调用，提供一个 <code>events.state.Worker</code> 实例。 </li> <li> <code>&lt;set&gt; gossip.on.node_leave</code>  每当新节点离开集群（关闭）时调用， 提供一个 <code>celery.events.state.Worker</code> 实例。 </li> <li> <code>&lt;set&gt; gossip.on.node_lost</code> 每当集群中的工作节点实例心跳丢失时调用（心跳未及时接收或处理），提供一个 <code>celery.events.state.Worker</code> 实例。 这并不一定意味着工作节点实际上已离线，因此如果默认的心跳超时不够，请使用超时机制。 </li> </ul> <code>pool</code>  当前的进程/eventlet/gevent/线程池。参见 <code>celery.concurrency.base.BasePool</code>。  <code>timer</code>  用于调度函数的 <code>celery.utils.timer2.Schedule</code>。  <code>heart</code>  负责发送工作节点事件心跳(<code>celery.worker.heartbeat.Heart</code>)。 您的 consumer 启动步骤必须要求 <code>Heart</code> 启动步骤才能使用此功能：  <pre><code>class Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.heart:Heart'}\n</code></pre> <code>task_consumer</code>  用于消费任务消息的 <code>kombu.Consumer</code> 对象。 您的 consumer 启动步骤必须要求 <code>Tasks</code> 启动步骤才能使用此功能：  <pre><code>class Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.tasks:Tasks'}\n</code></pre> <code>strategies</code>  每个注册的任务类型在此映射中都有一个条目，其中值用于执行此任务类型的传入消息（任务执行策略）。此映射由Tasks启动步骤在 consumer 启动时生成：  <pre><code>for name, task in app.tasks.items():\n    strategies[name] = task.start_strategy(app, consumer)\n    task.__trace__ = celery.app.trace.build_tracer(\n        name, task, loader, hostname\n    )\n</code></pre>  您的 consumer 启动步骤必须要求 <code>Tasks</code> 启动步骤才能使用此功能：  <pre><code>class Step(bootsteps.StartStopStep):\n    requires = {'celery.worker.consumer.tasks:Tasks'}\n</code></pre> <code>task_buckets</code>  一个 <code>collections.defaultdict</code>，用于按类型查找任务的速率限制。此字典中的条目可以是None（无限制）或实现 <code>consume(tokens)</code> 和 <code>expected_time(tokens)</code> 的 <code>~kombu.utils.limits.TokenBucket</code> 实例。 TokenBucket实现了[令牌桶算法](https://en.wikipedia.org/wiki/Token_bucket)，但任何算法 只要符合相同的接口并定义上述两个方法都可以使用。  <code>qos</code> <code>kombu.common.QoS</code> 对象可用于更改任务通道当前的 prefetch_count 值：  <pre><code># 在下个周期增加\nconsumer.qos.increment_eventually(1)\n# 在下个周期减少\nconsumer.qos.decrement_eventually(1)\nconsumer.qos.set(10)\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_9","level":3,"title":"方法","text":"方法 描述 <code>reset_rate_limits()</code> 更新所有注册任务类型的 <code>task_buckets</code> 映射。 <code>bucket_for_task(type, Bucket=TokenBucket)</code> 使用任务的 <code>task.rate_limit</code> 属性为任务创建速率限制桶。 <code>add_task_queue(name, exchange=None, exchange_type=None, routing_key=None, **options)</code> 添加新的队列以从中消费。这将在连接重启时持久化。 <code>cancel_task_queue(name)</code> 按名称停止从队列消费。这将在连接重启时持久化。 <code>apply_eta_task(request)</code> 根据 <code>request.eta</code> 属性调度ETA任务执行。 (<code>celery.worker.request.Request</code>)","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_10","level":2,"title":"安装启动步骤","text":"<p><code>app.steps['worker']</code> 和 <code>app.steps['consumer']</code> 可以被修改来添加新的启动步骤：</p> <pre><code>&gt;&gt;&gt; app = Celery()\n&gt;&gt;&gt; app.steps['worker'].add(MyWorkerStep)  # &lt; 添加类，不要实例化\n&gt;&gt;&gt; app.steps['consumer'].add(MyConsumerStep)\n\n&gt;&gt;&gt; app.steps['consumer'].update([StepA, StepB])\n\n&gt;&gt;&gt; app.steps['consumer']\n{step:proj.StepB{()}, step:proj.MyConsumerStep{()}, step:proj.StepA{()}\n</code></pre> <p>这里的步骤顺序并不重要，因为顺序是由产生的依赖图（<code>Step.requires</code>）决定的。</p> <p>为了说明如何安装启动步骤以及它们如何工作，这是一个示例步骤，打印一些无用的调试信息。它可以同时作为 worker 和 consumer 的启动步骤添加：</p> <pre><code>from celery import Celery\nfrom celery import bootsteps\n\nclass InfoStep(bootsteps.Step):\n\n    def __init__(self, parent, **kwargs):\n        # 在这里我们可以准备 Worker/Consumer 对象\n        # 以任何我们想要的方式，设置属性默认值等等。\n        print('{0!r} is in init'.format(parent))\n\n    def start(self, parent):\n        # 我们的步骤与所有其他 Worker/Consumer\n        # 启动步骤一起启动。\n        print('{0!r} is starting'.format(parent))\n\n    def stop(self, parent):\n        # Consumer 每次重启时（即连接丢失）以及关闭时都会调用 stop。\n        # Worker 仅在关闭时调用 stop。\n        print('{0!r} is stopping'.format(parent))\n\n    def shutdown(self, parent):\n        # shutdown 由 Consumer 在关闭时调用，\n        # Worker 不会调用它。\n        print('{0!r} is shutting down'.format(parent))\n\n    app = Celery(broker='amqp://')\n    app.steps['worker'].add(InfoStep)\n    app.steps['consumer'].add(InfoStep)\n</code></pre> <p>安装此步骤后启动 worker 将给我们以下日志：</p> <pre><code>&lt;Worker: w@example.com (initializing)&gt; is in init\n&lt;Consumer: w@example.com (initializing)&gt; is in init\n[2013-05-29 16:18:20,544: WARNING/MainProcess]\n    &lt;Worker: w@example.com (running)&gt; is starting\n[2013-05-29 16:18:21,577: WARNING/MainProcess]\n    &lt;Consumer: w@example.com (running)&gt; is starting\n&lt;Consumer: w@example.com (closing)&gt; is stopping\n&lt;Worker: w@example.com (closing)&gt; is stopping\n&lt;Consumer: w@example.com (terminating)&gt; is shutting down\n</code></pre> <p><code>print</code> 语句将在 worker 初始化后重定向到日志子系统，因此 \"is starting\" 行带有时间戳。您可能会注意到在关闭时不再发生这种情况，这是因为 <code>stop</code> 和 <code>shutdown</code> 方法在 信号处理器 内部调用，在这样的处理器中使用日志记录是不安全的。 Python 日志记录模块不是 <code>reentrant</code>：意味着您不能中断函数然后稍后再次调用它。重要的是您编写的 <code>stop</code> 和 <code>shutdown</code> 方法也是 <code>reentrant</code>。</p> <p>使用 <code>celery worker --loglevel</code> 启动 worker 将向我们显示有关启动过程的更多信息：</p> <pre><code>[2013-05-29 16:18:20,509: DEBUG/MainProcess] | Worker: Preparing bootsteps.\n[2013-05-29 16:18:20,511: DEBUG/MainProcess] | Worker: Building graph...\n&lt;celery.apps.worker.Worker object at 0x101ad8410&gt; is in init\n[2013-05-29 16:18:20,511: DEBUG/MainProcess] | Worker: New boot order:\n    {Hub, Pool, Timer, StateDB, Autoscaler, InfoStep, Beat, Consumer}\n[2013-05-29 16:18:20,514: DEBUG/MainProcess] | Consumer: Preparing bootsteps.\n[2013-05-29 16:18:20,514: DEBUG/MainProcess] | Consumer: Building graph...\n&lt;celery.worker.consumer.Consumer object at 0x101c2d8d0&gt; is in init\n[2013-05-29 16:18:20,515: DEBUG/MainProcess] | Consumer: New boot order:\n    {Connection, Mingle, Events, Gossip, InfoStep, Agent,\n     Heart, Control, Tasks, event loop}\n[2013-05-29 16:18:20,522: DEBUG/MainProcess] | Worker: Starting Hub\n[2013-05-29 16:18:20,522: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,522: DEBUG/MainProcess] | Worker: Starting Pool\n[2013-05-29 16:18:20,542: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,543: DEBUG/MainProcess] | Worker: Starting InfoStep\n[2013-05-29 16:18:20,544: WARNING/MainProcess]\n    &lt;celery.apps.worker.Worker object at 0x101ad8410&gt; is starting\n[2013-05-29 16:18:20,544: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,544: DEBUG/MainProcess] | Worker: Starting Consumer\n[2013-05-29 16:18:20,544: DEBUG/MainProcess] | Consumer: Starting Connection\n[2013-05-29 16:18:20,559: INFO/MainProcess] Connected to amqp://guest@127.0.0.1:5672//\n[2013-05-29 16:18:20,560: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:20,560: DEBUG/MainProcess] | Consumer: Starting Mingle\n[2013-05-29 16:18:20,560: INFO/MainProcess] mingle: searching for neighbors\n[2013-05-29 16:18:21,570: INFO/MainProcess] mingle: no one here\n[2013-05-29 16:18:21,570: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,571: DEBUG/MainProcess] | Consumer: Starting Events\n[2013-05-29 16:18:21,572: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,572: DEBUG/MainProcess] | Consumer: Starting Gossip\n[2013-05-29 16:18:21,577: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,577: DEBUG/MainProcess] | Consumer: Starting InfoStep\n[2013-05-29 16:18:21,577: WARNING/MainProcess]\n    &lt;celery.worker.consumer.Consumer object at 0x101c2d8d0&gt; is starting\n[2013-05-29 16:18:21,578: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,578: DEBUG/MainProcess] | Consumer: Starting Heart\n[2013-05-29 16:18:21,579: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,579: DEBUG/MainProcess] | Consumer: Starting Control\n[2013-05-29 16:18:21,583: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,583: DEBUG/MainProcess] | Consumer: Starting Tasks\n[2013-05-29 16:18:21,606: DEBUG/MainProcess] basic.qos: prefetch_count-&gt;80\n[2013-05-29 16:18:21,606: DEBUG/MainProcess] ^-- substep ok\n[2013-05-29 16:18:21,606: DEBUG/MainProcess] | Consumer: Starting event loop\n[2013-05-29 16:18:21,608: WARNING/MainProcess] celery@example.com ready.\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_11","level":2,"title":"命令行程序","text":"","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_12","level":3,"title":"添加新的命令行选项","text":"","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_13","level":4,"title":"命令特定选项","text":"<p>您可以通过修改应用程序实例的 <code>user_options</code> 属性来向 <code>worker</code>、<code>beat</code> 和 <code>events</code> 命令添加额外的命令行选项。</p> <p>Celery 命令使用 <code>click</code> 模块来解析命令行参数，因此要添加自定义参数，您需要向相关集合添加 <code>click.Option</code> 实例。</p> <p>向 <code>celery worker</code> 命令添加自定义选项的示例：</p> <pre><code>from celery import Celery\nfrom click import Option\n\napp = Celery(broker='amqp://')\n\napp.user_options['worker'].add(Option(('--enable-my-option',),\n                                      is_flag=True,\n                                      help='Enable custom option.'))\n</code></pre> <p>所有引导步骤现在都将此参数作为关键字参数传递给 <code>Bootstep.__init__</code>：</p> <pre><code>from celery import bootsteps\n\nclass MyBootstep(bootsteps.Step):\n\n    def __init__(self, parent, enable_my_option=False, **options):\n        super().__init__(parent, **options)\n        if enable_my_option:\n            party()\n\n\napp.steps['worker'].add(MyBootstep)\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#_14","level":4,"title":"预加载选项","text":"<p><code>celery</code> 伞形命令支持'预加载选项'的概念。这些是传递给所有子命令的特殊选项。</p> <p>您可以添加新的预加载选项，例如指定配置模板：</p> <pre><code>from celery import Celery\nfrom celery import signals\nfrom click import Option\n\napp = Celery()\n\napp.user_options['preload'].add(Option(('-Z', '--template'),\n                                       default='default',\n                                       help='Configuration template to use.'))\n\n@signals.user_preload_options.connect\ndef on_preload_parsed(options, **kwargs):\n    use_template(options['template'])\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#celery","level":5,"title":"添加新的 <code>celery</code> 子命令","text":"<p>可以通过使用 setuptools 入口点 向 <code>celery</code> 伞形命令添加新命令。</p> <p>入口点是特殊的元数据，可以添加到包的 <code>setup.py</code> 程序中，然后在安装后使用 <code>importlib</code> 模块从系统中读取。</p> <p>Celery 识别 <code>celery.commands</code> 入口点来安装额外的子命令，其中入口点的值必须指向有效的 click 命令。</p> <p>这就是 <code>Flower</code> 监控扩展如何通过向 <code>setup.py</code> 添加入口点来添加 <code>celery flower</code> 命令的方式：</p> <pre><code>setup(\n    name='flower',\n    entry_points={\n        'celery.commands': [\n           'flower = flower.command:flower',\n        ],\n    }\n)\n</code></pre> <p>命令定义由等号分隔为两部分，第一部分是子命令的名称（flower），第二部分是实现命令的函数的完全限定符号路径：</p> <pre><code>flower.command:flower\n</code></pre> <p>模块路径和属性名称应如上所示用冒号分隔。</p> <p>在 <code>flower/command.py</code> 模块中，命令函数可以定义如下：</p> <pre><code>import click\n\n@click.command()\n@click.option('--port', default=8888, type=int, help='Webserver port')\n@click.option('--debug', is_flag=True)\ndef flower(port, debug):\n    print('Running our command')\n</code></pre>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#worker-api","level":2,"title":"Worker API","text":"<p><code>kombu.asynchronous.Hub</code> - 工作者的异步事件循环</p> <p>当使用amqp或redis代理传输时，工作者使用异步I/O。最终目标是所有传输都使用事件循环，但这需要一些时间，因此其他传输仍然使用基于线程的解决方案。</p> Method Description <code>add(fd, callback, flags)</code> - <code>add_reader(fd, callback, *args)</code> 添加回调函数，当 <code>fd</code> 可读时调用。回调将保持注册状态，直到显式移除使用 <code>hub.remove(fd)</code>，或者文件描述符因不再有效而自动丢弃。注意，在任何给定的文件描述符上，一次只能注册一个回调函数，因此第二次调用 <code>add</code> 将移除之前为该文件描述符注册的任何回调函数。文件描述符可以是任何支持 <code>fileno</code> 方法的类文件对象，也可以是文件描述符编号（int）。 <code>add_writer(fd, callback, *args)</code> 添加回调函数，当 <code>fd</code> 可写时调用。另请参见上面的 <code>hub.add_reader</code> 注释。 <code>remove(fd)</code> 从循环中移除文件描述符 <code>fd</code> 的所有回调函数。","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/extending/#timer-","level":3,"title":"Timer - 调度事件","text":"Method <code>call_after(secs, callback, args=(), kwargs=(), priority=0)</code> <code>call_repeatedly(secs, callback, args=(), kwargs=(), priority=0)</code> <code>call_at(eta, callback, args=(), kwargs=(), priority=0)</code>","path":["用户指南","扩展和启动步骤"],"tags":[]},{"location":"user-guide/monitoring/","level":1,"title":"监控与管理","text":"","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_2","level":2,"title":"简介","text":"<p>有多种工具可用于监控和检查 Celery 集群。</p> <p>本文档介绍其中一些工具，以及与监控相关的功能，如事件和广播命令。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#workers","level":2,"title":"Workers","text":"","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspectcontrol","level":3,"title":"管理命令行工具 (<code>inspect</code>/<code>control</code>)","text":"<p><code>celery</code> 也可以用来检查和管理工作节点（以及在一定程度上管理任务）。</p> <p>要列出所有可用的命令，请执行：</p> <pre><code>celery --help\n</code></pre> <p>或者要获取特定命令的帮助，请执行：</p> <pre><code>celery &lt;command&gt; --help\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_3","level":3,"title":"命令","text":"","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#shell","level":4,"title":"shell","text":"<p>进入 Python shell。</p> <p>本地变量将包含 <code>celery</code> 变量：这是当前的应用。所有已知的任务也会自动添加到本地变量中（除非设置了 <code>celery shell --without-tasks</code> 标志）。</p> <p>如果已安装，将按以下顺序使用 <code>Ipython</code>、<code>bpython</code> 或常规的 <code>python</code>。 您可以使用以下选项强制使用特定的实现：<code>celery shell --ipython</code>、<code>celery shell --bpython</code> 或 <code>celery shell --python</code>。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#status","level":4,"title":"status","text":"<p>列出此集群中的活动节点</p> <pre><code>celery -A proj status\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#result","level":4,"title":"result","text":"<p>显示任务的结果</p> <pre><code>celery -A proj result -t tasks.add 4e196aa4-0141-4601-8138-7aa33db0f577\n</code></pre> <p>请注意，只要任务不使用自定义结果后端，您就可以省略任务名称。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#purge","level":4,"title":"purge","text":"<p>清除所有已配置任务队列中的消息。</p> <p>此命令将从 <code>CELERY_QUEUES</code> 设置中配置的队列中删除所有消息：</p> <p>此操作无法撤销，消息将被永久删除！</p> <pre><code>celery -A proj purge\n</code></pre> <p>您还可以使用 <code>-Q</code> 选项指定要清除的队列：</p> <pre><code>celery -A proj purge -Q celery,foo,bar\n</code></pre> <p>并使用 <code>-X</code> 选项排除队列不被清除：</p> <pre><code>celery -A proj purge -X celery\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspect-active","level":4,"title":"inspect active","text":"<p>列出活动任务</p> <pre><code>celery -A proj inspect active\n</code></pre> <p>这些是当前正在执行的所有任务。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspect-scheduled","level":4,"title":"inspect scheduled","text":"<p>列出已调度的 ETA 任务</p> <pre><code>celery -A proj inspect scheduled\n</code></pre> <p>这些是当任务设置了 <code>eta</code> 或 <code>countdown</code> 参数时由工作进程保留的任务。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspect-reserved","level":4,"title":"inspect reserved","text":"<p>列出保留任务</p> <pre><code>celery -A proj inspect reserved\n</code></pre> <p>这将列出工作进程已预取的所有任务，这些任务当前正在等待执行（不包括设置了 ETA 值的任务）。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspect-revoked","level":4,"title":"inspect revoked","text":"<p>列出已撤销任务的历史记录</p> <pre><code>celery -A proj inspect revoked\n</code></pre> <p>这将列出所有已被撤销的任务。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspect-registered","level":4,"title":"inspect registered","text":"<p>列出已注册任务</p> <pre><code>celery -A proj inspect registered\n</code></pre> <p>这将列出系统中注册的所有任务。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspect-stats","level":4,"title":"inspect stats","text":"<p>显示工作进程统计信息（参见 工作进程指南 - 统计信息）</p> <pre><code>celery -A proj inspect stats\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#inspect-query_task","level":4,"title":"inspect query_task","text":"<p>按 ID 显示任务信息。</p> <p>任何在此 ID 集合中有保留/活动任务的工作进程都将响应状态和信息。</p> <pre><code>celery -A proj inspect query_task e9f6c8f0-fec9-4ae8-a8c6-cf8c8451d4f8\n</code></pre> <p>您还可以查询多个任务的信息：</p> <pre><code>celery -A proj inspect query_task id1 id2 ... idN\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#control-enable_events","level":4,"title":"control enable_events","text":"<p>启用事件</p> <pre><code>celery -A proj control enable_events\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#control-disable_events","level":4,"title":"control disable_events","text":"<p>禁用事件</p> <pre><code>celery -A proj control disable_events\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#migrate","level":4,"title":"migrate","text":"<p>将任务从一个代理迁移到另一个代理（实验性）。</p> <pre><code>celery -A proj migrate redis://localhost amqp://localhost\n</code></pre> <p>此命令将把一个代理上的所有任务迁移到另一个代理。由于此命令是新的且具有实验性，您应该确保在继续之前备份数据。</p> <p>Note</p> <p>所有 <code>inspect</code> 和 <code>control</code> 命令都支持 <code>celery inspect --timeout</code> 参数，这是等待响应的秒数。如果由于延迟而无法获得响应，您可能需要增加此超时时间。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_4","level":4,"title":"指定目标节点","text":"<p>默认情况下，inspect 和 control 命令对所有工作进程进行操作。您可以使用 <code>celery inspect --destination</code> 参数指定单个或一组工作进程：</p> <pre><code>celery -A proj inspect -d w1@e.com,w2@e.com reserved\n\ncelery -A proj control -d w1@e.com,w2@e.com enable_events\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#flower-celery-web","level":3,"title":"Flower: 实时 Celery Web 监控器","text":"<p>Flower 是一个基于 Web 的实时监控和管理工具，专为 Celery 设计。它正在积极开发中，但已经是一个必不可少的工具。作为 Celery 的推荐监控器，它取代了 Django-Admin 监控器、<code>celerymon</code> 和基于 <code>ncurses</code> 的监控器。</p> <p>Flower 的发音类似于 \"flow\"，但如果您喜欢，也可以使用植物版本的发音。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_5","level":4,"title":"特性","text":"<ul> <li> <p>使用 Celery 事件进行实时监控</p> <ul> <li>任务进度和历史记录</li> <li>显示任务详细信息的能力（参数、开始时间、运行时间等）</li> <li>图表和统计信息</li> </ul> </li> <li> <p>远程控制</p> <ul> <li>查看工作器状态和统计信息</li> <li>关闭和重启工作器实例</li> <li>控制工作器池大小和自动缩放设置</li> <li>查看和修改工作器实例消费的队列</li> <li>查看当前运行的任务</li> <li>查看计划任务（ETA/倒计时）</li> <li>查看保留和撤销的任务</li> <li>应用时间和速率限制</li> <li>配置查看器</li> <li>撤销或终止任务</li> </ul> </li> <li> <p>HTTP API</p> <ul> <li>列出工作器</li> <li>关闭工作器</li> <li>重启工作器池</li> <li>扩展工作器池</li> <li>缩小工作器池</li> <li>自动缩放工作器池</li> <li>开始从队列消费</li> <li>停止从队列消费</li> <li>列出任务</li> <li>列出（已见到的）任务类型</li> <li>获取任务信息</li> <li>执行任务</li> <li>按名称执行任务</li> <li>获取任务结果</li> <li>更改任务的软硬时间限制</li> <li>更改任务的速率限制</li> <li>撤销任务</li> </ul> </li> <li> <p>OpenID 认证</p> </li> </ul> <p>截图</p> <p></p> <p>更多 截图：</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_6","level":4,"title":"使用方法","text":"<p>您可以使用 pip 安装 Flower：</p> <pre><code>pip install flower\n</code></pre> <p>运行 flower 命令将启动一个您可以访问的 Web 服务器：</p> <pre><code>celery -A proj flower\n</code></pre> <p>默认端口是 http://localhost:5555，但您可以使用 <code>--port</code> 参数更改此设置：</p> <pre><code>celery -A proj flower --port=5555\n</code></pre> <p>代理 URL 也可以通过 <code>celery --broker</code> 参数传递：</p> <pre><code>celery --broker=amqp://guest:guest@localhost:5672// flower\n# or\ncelery --broker=redis://guest:guest@localhost:6379/0 flower\n</code></pre> <p>然后，您可以在 Web 浏览器中访问 flower：</p> <pre><code>open http://localhost:5555\n</code></pre> <p>Flower 具有比此处详述的更多功能，包括授权选项。请查看 官方文档 以获取更多信息。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#celery-events-curses","level":3,"title":"celery events: Curses 监视器","text":"<p><code>celery events</code> 是一个简单的 curses 监视器，显示任务和工作者历史记录。您可以检查任务的结果和回溯信息，它还支持一些管理命令，如速率限制和关闭工作者。这个监视器最初是作为概念验证开始的，您可能更想使用 Flower 替代它。</p> <p>启动：</p> <pre><code>celery -A proj events\n</code></pre> <p>您应该会看到类似这样的屏幕：</p> <p></p> <p><code>celery events</code> 也用于启动快照相机（参见 :ref:<code>monitoring-snapshots</code>：</p> <pre><code>celery -A proj events --camera=&lt;camera-class&gt; --frequency=1.0\n</code></pre> <p>并且它包含一个将事件转储到 <code>stdout</code> 的工具：</p> <pre><code>celery -A proj events --dump\n</code></pre> <p>要获取完整的选项列表，请使用 <code>--help</code>：</p> <pre><code>celery events --help\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#rabbitmq","level":2,"title":"RabbitMQ","text":"<p>要管理 Celery 集群，了解如何监控 RabbitMQ 非常重要。</p> <p>RabbitMQ 自带了 <code>rabbitmqctl(1)</code> 命令，使用它可以列出队列、交换机、绑定关系、队列长度、每个队列的内存使用情况，以及管理用户、虚拟主机及其权限。</p> <p>Note</p> <p>这些示例中使用的是默认虚拟主机 (<code>\"/\"</code>)，如果您使用自定义虚拟主机，必须在命令中添加 <code>-p</code> 参数，例如：<code>rabbitmqctl list_queues -p my_vhost …</code></p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_7","level":3,"title":"检查队列","text":"<p>查找队列中的任务数量：</p> <pre><code>rabbitmqctl list_queues name messages messages_ready messages_unacknowledged\n</code></pre> <p>这里 <code>messages_ready</code> 是准备投递的消息数量（已发送但未接收），<code>messages_unacknowledged</code> 是已被工作进程接收但尚未确认的消息数量（意味着正在进行中，或已被保留）。<code>messages</code> 是准备和未确认消息的总和。</p> <p>查找当前从队列消费的工作进程数量：</p> <pre><code>rabbitmqctl list_queues name consumers\n</code></pre> <p>查找分配给队列的内存量：</p> <pre><code>rabbitmqctl list_queues name memory\n</code></pre> <p>向 <code>rabbitmqctl(1)</code> 添加 <code>-q</code> 选项可以使输出更易于解析。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#redis","level":2,"title":"Redis","text":"<p>如果您使用 Redis 作为代理，可以使用 <code>redis-cli(1)</code> 命令来监控 Celery 集群，列出队列的长度。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_8","level":3,"title":"检查队列","text":"<p>查找队列中的任务数量：</p> <pre><code>redis-cli -h HOST -p PORT -n DATABASE_NUMBER llen QUEUE_NAME\n</code></pre> <p>默认队列名为 <code>celery</code>。要获取所有可用的队列，请调用：</p> <pre><code>redis-cli -h HOST -p PORT -n DATABASE_NUMBER keys \\*\n</code></pre> <p>Note</p> <p>队列键仅在其中有任务时存在，因此如果某个键不存在，仅表示该队列中没有消息。这是因为在 Redis 中，没有元素的列表会自动被移除，因此它不会出现在 <code>keys</code> 命令的输出中，并且该列表的 <code>llen</code> 返回 0。</p> <p>此外，如果您将 Redis 用于其他目的，<code>keys</code> 命令的输出将包括数据库中存储的不相关值。推荐的解决方法是使用专用的 <code>DATABASE_NUMBER</code> 给 Celery，您也可以使用数据库编号来将 Celery 应用程序彼此分开（虚拟主机），但这不会影响监控事件，例如 Flower 使用的Redis pub/sub 命令是全局的，而不是基于数据库的。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#monitoring-munin","level":2,"title":"Munin","text":"<p>这是一个已知的Munin插件列表，在维护Celery集群时可能很有用。</p> <ul> <li>rabbitmq-munin: RabbitMQ的Munin插件。</li> <li>celery_tasks: 监控每种任务类型已被执行的次数   （需要 <code>celerymon</code>）。</li> <li>celery_tasks_states: 监控每种状态下任务的数量   （需要 <code>celerymon</code>）。</li> </ul>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_9","level":2,"title":"事件","text":"<p>工作器能够在事件发生时发送消息。这些事件随后被诸如 Flower 和 <code>celery events</code> 等工具捕获，用于监控集群。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#monitoring-snapshots","level":3,"title":"快照","text":"<p>即使单个工作器也能产生大量事件，因此在磁盘上存储所有事件的历史可能非常昂贵。</p> <p>一系列事件描述了该时间段内的集群状态，通过定期对此状态进行快照，您可以保留所有历史记录，但仍仅定期将其写入磁盘。</p> <p>要拍摄快照，您需要一个 Camera 类，通过它您可以定义每次捕获状态时应发生的情况；您可以将其写入数据库、通过电子邮件发送或完全执行其他操作。</p> <p>然后使用 <code>celery events</code> 通过摄像头拍摄快照，例如，如果您想每 2 秒使用摄像头 <code>myapp.Camera</code> 捕获状态，您可以使用以下参数运行 <code>celery events</code>：</p> <pre><code>celery -A proj events -c myapp.Camera --frequency=2.0\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_10","level":4,"title":"自定义摄像头","text":"<p>如果您需要以一定间隔捕获事件并对这些事件执行某些操作，摄像头会很有用。对于实时事件处理，您应该直接使用 :class:<code>@events.Receiver</code>，如 :ref:<code>event-real-time-example</code> 中所示。</p> <p>这是一个示例摄像头，将快照转储到屏幕：</p> <pre><code>from pprint import pformat\n\nfrom celery.events.snapshot import Polaroid\n\nclass DumpCam(Polaroid):\n    clear_after = True  # 刷新后清除（包括 state.event_count）。\n\n    def on_shutter(self, state):\n        if not state.event_count:\n            # 自上次快照以来没有新事件。\n            return\n        print('Workers: {0}'.format(pformat(state.workers, indent=4)))\n        print('Tasks: {0}'.format(pformat(state.tasks, indent=4)))\n        print('Total: {0.event_count} events, {0.task_count} tasks'.format(state))\n</code></pre> <p>有关状态对象的更多信息，请参阅 <code>celery.events.state</code> 的 API 参考。</p> <p>现在您可以通过指定 <code>celery events -c</code> 选项将此摄像头与 <code>celery events</code> 一起使用：</p> <pre><code>celery -A proj events -c myapp.DumpCam --frequency=2.0\n</code></pre> <p>或者您可以像这样以编程方式使用它：</p> <pre><code>from celery import Celery\nfrom myapp import DumpCam\n\ndef main(app, freq=1.0):\n    state = app.events.State()\n    with app.connection() as connection:\n        recv = app.events.Receiver(connection, handlers={'*': state.event})\n        with DumpCam(state, freq=freq):\n            recv.capture(limit=None, timeout=None)\n\nif __name__ == '__main__':\n    app = Celery(broker='amqp://guest@localhost//')\n    main(app)\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_11","level":3,"title":"实时处理","text":"<p>要实时处理事件，您需要以下内容：</p> <ul> <li> <p>事件消费者（这是 <code>Receiver</code>）</p> </li> <li> <p>事件到达时调用的一组处理程序。</p> <p>您可以为每种事件类型设置不同的处理程序，或者可以使用通配符处理程序（'*'）</p> </li> <li> <p>状态（可选）</p> </li> </ul> <p><code>State</code> 是集群中任务和工作器的便捷内存表示形式，随着事件的到来而更新。</p> <p>它封装了许多常见问题的解决方案，例如检查工作器是否仍然存活（通过验证心跳）、在事件到达时合并事件字段、确保时间戳同步等等。</p> <p>结合这些，您可以轻松地实时处理事件：</p> <pre><code>from celery import Celery\n\n\ndef my_monitor(app):\n    state = app.events.State()\n\n    def announce_failed_tasks(event):\n        state.event(event)\n        # 任务名称仅在 -received 事件中发送，状态\n        # 将为我们跟踪这一点。\n        task = state.tasks.get(event['uuid'])\n\n        print('TASK FAILED: %s[%s] %s' % (\n            task.name, task.uuid, task.info(),))\n\n    with app.connection() as connection:\n        recv = app.events.Receiver(connection, handlers={\n                'task-failed': announce_failed_tasks,\n                '*': state.event,\n        })\n        recv.capture(limit=None, timeout=None, wakeup=True)\n\nif __name__ == '__main__':\n    app = Celery(broker='amqp://guest@localhost//')\n    my_monitor(app)\n</code></pre> <p>Note</p> <p><code>capture</code> 的 <code>wakeup</code> 参数向所有工作器发送信号，强制它们发送心跳。这样，当监控器启动时，您可以立即看到工作器。</p> <p>您可以通过指定处理程序来监听特定事件：</p> <pre><code>from celery import Celery\n\ndef my_monitor(app):\n    state = app.events.State()\n\n    def announce_failed_tasks(event):\n        state.event(event)\n        # 任务名称仅在 -received 事件中发送，状态\n        # 将为我们跟踪这一点。\n        task = state.tasks.get(event['uuid'])\n\n        print('TASK FAILED: %s[%s] %s' % (\n            task.name, task.uuid, task.info(),))\n\n    with app.connection() as connection:\n        recv = app.events.Receiver(connection, handlers={\n                'task-failed': announce_failed_tasks,\n        })\n        recv.capture(limit=None, timeout=None, wakeup=True)\n\nif __name__ == '__main__':\n    app = Celery(broker='amqp://guest@localhost//')\n    my_monitor(app)\n</code></pre>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_12","level":2,"title":"事件参考","text":"<p>此列表包含工作进程发送的事件及其参数。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_13","level":3,"title":"任务事件","text":"","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-sent","level":4,"title":"task-sent","text":"<p><code>task-sent(uuid, name, args, kwargs, retries, eta, expires, queue, exchange, routing_key, root_id, parent_id)</code></p> <p>当任务消息发布且 <code>task_send_sent_event</code> 设置启用时发送。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-received","level":4,"title":"task-received","text":"<p><code>task-received(uuid, name, args, kwargs, retries, eta, hostname, timestamp, root_id, parent_id)</code></p> <p>当工作进程接收到任务时发送。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-started","level":4,"title":"task-started","text":"<p><code>task-started(uuid, hostname, timestamp, pid)</code></p> <p>在工作进程执行任务之前发送。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-succeeded","level":4,"title":"task-succeeded","text":"<p><code>task-succeeded(uuid, result, runtime, hostname, timestamp)</code></p> <p>如果任务执行成功则发送。</p> <p>运行时间是指使用池执行任务所需的时间。（从任务发送到工作进程池开始，到池结果处理程序回调被调用时结束）。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-failed","level":4,"title":"task-failed","text":"<p><code>task-failed(uuid, exception, traceback, hostname, timestamp)</code></p> <p>如果任务执行失败则发送。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-rejected","level":4,"title":"task-rejected","text":"<p><code>task-rejected(uuid, requeue)</code></p> <p>任务被工作进程拒绝，可能被重新排队或移动到死信队列。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-revoked","level":4,"title":"task-revoked","text":"<p><code>task-revoked(uuid, terminated, signum, expired)</code></p> <p>如果任务已被撤销则发送（请注意，这很可能由多个工作进程发送）。</p> 参数 描述 <code>terminated</code> 如果任务进程被终止则设置为 true，并且 <code>signum</code> 字段设置为使用的信号。 <code>expired</code> 如果任务已过期则设置为 true。","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#task-retried","level":4,"title":"task-retried","text":"<p><code>task-retried(uuid, exception, traceback, hostname, timestamp)</code></p> <p>如果任务失败但将在未来重试则发送。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_14","level":3,"title":"工作进程事件","text":"","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#worker-online","level":4,"title":"worker-online","text":"<p><code>worker-online(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys)</code></p> <p>工作进程已连接到代理并在线。</p> 参数 描述 <code>hostname</code> 工作进程的节点名。 <code>timestamp</code> 事件时间戳。 <code>freq</code> 心跳频率（秒，浮点数）。 <code>sw_ident</code> 工作进程软件名称（例如 <code>py-celery</code>）。 <code>sw_ver</code> 软件版本（例如 2.2.0）。 <code>sw_sys</code> 操作系统（例如 Linux/Darwin）。","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#worker-heartbeat","level":4,"title":"worker-heartbeat","text":"<p><code>worker-heartbeat(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys, active, processed)</code></p> <p>每分钟发送一次，如果工作进程在 2 分钟内未发送心跳，则被视为离线。</p> 参数 描述 <code>hostname</code> 工作进程的节点名。 <code>timestamp</code> 事件时间戳。 <code>freq</code> 心跳频率（秒，浮点数）。 <code>sw_ident</code> 工作进程软件名称（例如 <code>py-celery</code>）。 <code>sw_ver</code> 软件版本（例如 2.2.0）。 <code>sw_sys</code> 操作系统（例如 Linux/Darwin）。 <code>active</code> 当前正在执行的任务数。 <code>processed</code> 此工作进程处理的总任务数。","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#worker-offline","level":4,"title":"worker-offline","text":"<p><code>worker-offline(hostname, timestamp, freq, sw_ident, sw_ver, sw_sys)</code></p> <p>工作进程已与代理断开连接。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/monitoring/#_15","level":3,"title":"邮箱配置（高级）","text":"<p>Celery 内部使用 <code>kombu.pidbox.Mailbox</code> 向工作进程发送控制和广播命令。</p> <p>高级用户可以通过自定义邮箱的创建方式来配置其行为。<code>Mailbox</code> 现在支持以下参数：</p> 参数 描述 <code>durable</code> 默认 <code>False</code>，如果设置为 <code>True</code>，控制交换将在代理重启后继续存在。 <code>exclusive</code> 默认 <code>False</code>，如果设置为 <code>True</code>，交换将只能由一个连接使用。 <p>Warning</p> <p>同时设置 <code>durable=True</code> 和 <code>exclusive=True</code> 是不允许的，并且会引发错误，因为这两个选项在 AMQP 中是互不兼容的。</p> <p>有关高级配置，请参阅 <code>event_queue_durable</code> 和 <code>event_queue_exclusive</code>。</p>","path":["用户指南","监控与管理"],"tags":[]},{"location":"user-guide/optimizing/","level":1,"title":"优化","text":"","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#_2","level":2,"title":"引言","text":"<p>默认配置做了很多妥协。它对于任何单一情况都不是最优的，但在大多数情况下都能很好地工作。</p> <p>可以根据特定用例应用优化措施。</p> <p>优化可以应用于运行环境的不同属性，无论是任务执行所需的时间、使用的内存量，还是在高峰负载时的响应能力。</p>","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#_3","level":2,"title":"确保运行","text":"<p>在《编程珠玑》一书中，Jon Bentley通过提出以下问题介绍了信封背面计算的概念：</p> <p>❝ 密西西比河一天流出多少水？ ❞</p> <p>这个练习的重点<sup>1</sup>是表明系统在及时处理数据方面存在限制。信封背面计算可以作为一种提前规划的手段。</p> <p>在Celery中；如果一个任务需要10分钟才能完成，而每分钟有10个新任务进入，那么队列永远不会为空。这就是为什么监控队列长度非常重要！</p> <p>一种方法是使用 Munin。您应该设置警报，在任何队列达到不可接受的大小时立即通知您。这样您就可以采取适当的措施，比如添加新的工作节点，或撤销不必要的任务。</p>","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#_4","level":2,"title":"通用设置","text":"","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#_5","level":3,"title":"代理连接池","text":"<p>代理连接池自版本 2.5 起默认启用。</p> <p>您可以调整 <code>broker_pool_limit</code> 设置以最小化争用，该值应基于使用代理连接的活跃线程/绿色线程数量。</p>","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#_6","level":3,"title":"使用临时队列","text":"<p>Celery 创建的队列默认是持久化的。这意味着代理会将消息写入磁盘，以确保即使代理重启，任务也能被执行。</p> <p>但在某些情况下，消息丢失是可以接受的，因此并非所有任务都需要持久性。您可以为这些任务创建一个临时队列来提高性能：</p> <pre><code>from kombu import Exchange, Queue\n\ntask_queues = (\n    Queue('celery', routing_key='celery'),\n    Queue('transient', Exchange('transient', delivery_mode=1),\n          routing_key='transient', durable=False),\n)\n</code></pre> <p>或使用 <code>task_routes</code>：</p> <pre><code>task_routes = {\n    'proj.tasks.add': {'queue': 'celery', 'delivery_mode': 'transient'}\n}\n</code></pre> <p><code>delivery_mode</code> 更改了发送到此队列的消息的传递方式。值为 1 表示消息不会被写入磁盘，值为 2（默认值）表示消息可以被写入磁盘。</p> <p>要将任务定向到您的新临时队列，您可以指定队列参数（或使用 <code>task_routes</code> 设置）：</p> <pre><code>task.apply_async(args, queue='transient')\n</code></pre> <p>更多信息请参阅 路由指南。</p>","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#worker","level":2,"title":"Worker 设置","text":"","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#optimizing-prefetch-limit","level":3,"title":"预取限制","text":"<p>Prefetch（预取）是一个从 AMQP 继承而来的术语，经常被用户误解。</p> <p>预取限制是工作器可以为自己保留的任务（消息）数量的限制。如果为零，工作器将继续消耗消息，不考虑可能还有其他可用的工作器节点能够更快地处理它们 <sup>2</sup>，或者消息可能甚至无法放入内存。</p> <p>工作器的默认预取计数是 <code>worker_prefetch_multiplier</code> 设置乘以并发槽的数量 <sup>3</sup>（进程/线程/绿色线程）。</p> <p>如果您有许多长时间运行的任务，您希望乘数值为一：这意味着每个工作器进程一次只保留一个任务。</p> <p>然而——如果您有许多短时间运行的任务，并且吞吐量/往返延迟对您很重要，这个数字应该较大。如果消息已经被预取并可用在内存中，工作器能够每秒处理更多任务。您可能需要实验找到最适合您的最佳值。在这种情况下，像 50 或 150 这样的值可能是有意义的。比如 64 或 128。</p> <p>如果您有长时间运行和短时间运行任务的组合，最佳选择是使用两个分别配置的工作器节点，并根据运行时间路由任务（参见 路由指南）。</p>","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#_7","level":3,"title":"一次保留一个任务","text":"<p>任务消息只有在任务被 <code>acknowledged</code>（确认）后才会从队列中删除，因此如果工作器在确认任务之前崩溃，它可以被重新传递给另一个工作器（或在恢复后传递给同一个工作器）。</p> <p>请注意，异常在 Celery 中被视为正常操作，并且会被确认。 确认实际上用于防范无法通过 Python 异常系统正常处理的故障（即电源故障、内存损坏、硬件故障、致命信号等）。 对于正常异常，您应该使用 task.retry() 来重试任务。</p> <p>当使用默认的早期确认时，设置预取乘数为一，意味着工作器最多为每个工作器进程保留一个额外任务：换句话说，如果工作器以 <code>celery worker -c 10</code> 启动，工作器在任何时候最多可以保留 20 个任务（10 个正在执行的已确认任务，和 10 个未确认的保留任务）。</p> <p>用户经常询问是否可能禁用\"任务预取\"，这是可能的，但有一个条件。您可以让工作器只保留与工作器进程数量相同的任务，条件是它们被延迟确认（对于 <code>celery worker -c 10</code>，有 10 个正在执行的未确认任务）。</p> <p>为此，您需要启用 <code>late acknowledgment</code>（延迟确认）。使用此选项而不是默认行为意味着在电源故障或工作器实例突然被杀死的情况下，已经开始执行的任务将被重试，因此这也意味着任务必须是 <code>idempotent</code>（幂等）的。</p> <p>您可以通过以下配置选项启用此行为：</p> <pre><code>task_acks_late = True\nworker_prefetch_multiplier = 1\n</code></pre> <p>如果您的任务不能被延迟确认，您可以通过启用 <code>worker_disable_prefetch</code> 来禁用代理预取。使用此设置，工作器只有在执行槽空闲时才获取新任务，防止任务在繁忙的工作器上等待长时间运行的任务。这也可以通过命令行使用 <code>celery worker --disable-prefetch</code> 来设置。此功能目前仅在使用 Redis 作为代理时受支持。</p>","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/optimizing/#_8","level":3,"title":"内存使用","text":"<p>如果您在 prefork 工作器上遇到高内存使用情况，首先需要确定问题是否也发生在 Celery 主进程上。Celery 主进程的内存使用量在启动后不应继续急剧增加。如果您看到这种情况发生，可能表明存在内存泄漏错误，应报告给 Celery 问题跟踪器。</p> <p>如果只有您的子进程有高内存使用情况，这表明您的任务存在问题。</p> <p>请记住，Python 进程内存使用具有\"高水位线\"，并且直到子进程停止才会将内存返回给操作系统。这意味着单个高内存使用任务可能会永久增加子进程的内存使用量，直到它被重启。修复此问题可能需要向您的任务添加分块逻辑以减少峰值内存使用量。</p> <p>Celery 工作器有两种主要方法来帮助减少由于\"高水位线\"和/或子进程中的内存泄漏导致的内存使用：<code>worker_max_tasks_per_child</code> 和 <code>worker_max_memory_per_child</code> 设置。</p> <p>您必须小心不要将这些设置设置得太低，否则您的工作器将花费大部分时间重启子进程而不是处理任务。例如，如果您使用 <code>worker_max_tasks_per_child</code> 为 1，并且您的子进程需要 1 秒启动，那么该子进程每分钟最多只能处理 60 个任务（假设任务立即运行）。当您的任务总是超过 <code>worker_max_memory_per_child</code> 时，可能会出现类似的问题。</p> <ol> <li> <p>该章节可在此处免费阅读：信封背面。这本书是一本经典文本。强烈推荐。 ↩</p> </li> <li> <p>RabbitMQ 和其他代理以轮询方式传递消息，因此这不适用于活跃系统。如果没有预取限制并且您重启集群，节点启动之间会有时间延迟。如果有 3 个离线节点和一个活跃节点，所有消息都将被传递到活跃节点。 ↩</p> </li> <li> <p>这是并发设置 <code>worker_concurrency</code> 或 <code>celery worker -c</code> 选项。 ↩</p> </li> </ol>","path":["用户指南","优化"],"tags":[]},{"location":"user-guide/periodic-tasks/","level":1,"title":"周期性任务","text":"","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#_2","level":2,"title":"介绍","text":"<p><code>celery beat</code> 是一个调度器；它按固定的时间间隔启动任务，然后由集群中可用的工作节点执行这些任务。</p> <p>默认情况下，条目取自 <code>beat_schedule</code> 设置，但也可以使用自定义存储，例如将条目存储在 SQL 数据库中。</p> <p>您必须确保每个调度只有一个调度器在运行，否则会出现重复任务。使用集中式方法意味着调度不需要同步，服务可以在不使用锁的情况下运行。</p>","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#_3","level":2,"title":"时区","text":"<p>周期性任务调度默认使用 UTC 时区，但您可以使用 <code>timezone</code> 设置来更改使用的时区。</p> <p>一个示例时区可以是 <code>Europe/London</code>：</p> <pre><code>timezone = 'Europe/London'\n</code></pre> <p>此设置必须添加到您的应用程序中，可以通过直接配置使用 (<code>app.conf.timezone = 'Europe/London'</code>)，或者通过添加到您的配置模块（如果您已使用 <code>app.config_from_object</code> 设置了一个）。 有关配置选项的更多信息，请参阅 配置。</p> <p>默认调度器（将计划存储在 <code>celerybeat-schedule</code> 文件中）将自动检测到时区已更改，因此将重置计划本身，但其他调度器可能不那么智能（例如，Django 数据库调度器，见下文），在这种情况下，您必须手动重置计划。</p> Django 用户 <p>Celery 推荐并与 Django 1.4 中引入的 <code>USE_TZ</code> 设置兼容。</p> <p>对于 Django 用户，将使用 <code>TIME_ZONE</code> 设置中指定的时区， 或者您可以通过使用 :setting:<code>timezone</code> 设置单独为 Celery 指定自定义时区。</p> <p>数据库调度器在时区相关设置更改时不会重置，因此您必须手动执行此操作：</p> <pre><code>$ python manage.py shell\n&gt;&gt;&gt; from djcelery.models import PeriodicTask\n&gt;&gt;&gt; PeriodicTask.objects.update(last_run_at=None)\n</code></pre> <p>Django-Celery 仅支持 Celery 4.0 及以下版本，对于 Celery 4.0 及以上版本，请按以下方式操作：</p> <pre><code>$ python manage.py shell\n&gt;&gt;&gt; from django_celery_beat.models import PeriodicTask\n&gt;&gt;&gt; PeriodicTask.objects.update(last_run_at=None)\n</code></pre>","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#_4","level":2,"title":"条目","text":"<p>要定期调用任务，您必须向 beat 调度列表中添加一个条目。</p> <pre><code>from celery import Celery\nfrom celery.schedules import crontab\n\napp = Celery()\n\n@app.on_after_configure.connect\ndef setup_periodic_tasks(sender: Celery, **kwargs):\n    # 每10秒调用 test('hello')\n    sender.add_periodic_task(10.0, test.s('hello'), name='add every 10')\n\n    # 每30秒调用 test('hello')\n    # 它使用与前一个任务相同的签名，定义了一个显式名称\n    # 以避免此任务替换先前定义的任务\n    sender.add_periodic_task(30.0, test.s('hello'), name='add every 30')\n\n    # 每30秒调用 test('world')\n    sender.add_periodic_task(30.0, test.s('world'), expires=10)\n\n    # 每周一早上7:30执行\n    sender.add_periodic_task(\n        crontab(hour=7, minute=30, day_of_week=1),\n        test.s('Happy Mondays!'),\n    )\n\n@app.task\ndef test(arg):\n    print(arg)\n\n@app.task\ndef add(x, y):\n    z = x + y\n    print(z)\n</code></pre> <p>在 <code>on_after_configure</code> 处理程序内设置这些意味着在使用 <code>test.s()</code> 时我们不会在模块级别评估应用程序。请注意 <code>on_after_configure</code> 是在应用设置完成后发送的，因此位于应用声明模块之外的任务（例如，在由 <code>celery.Celery.autodiscover_tasks</code> 定位的 <code>tasks.py</code> 文件中）必须使用稍后的信号，例如 <code>on_after_finalize</code>。</p> <p><code>add_periodic_task</code> 函数将在后台将条目添加到 <code>beat_schedule</code> 设置中，相同的设置也可以用于手动设置周期性任务：</p> <p>示例：每30秒运行 <code>tasks.add</code> 任务。</p> <pre><code>app.conf.beat_schedule = {\n    'add-every-30-seconds': {\n        'task': 'tasks.add',\n        'schedule': 30.0,\n        'args': (16, 16)\n    },\n}\napp.conf.timezone = 'UTC'\n</code></pre> <p>Note</p> <p>如果您想知道这些设置应该放在哪里，请参阅 配置。您可以直接在您的应用上设置这些选项，也可以保留一个单独的配置模块。</p> <p>如果您想为 <code>args</code> 使用单元素元组，请不要忘记构造函数是一个逗号，而不是一对括号。</p> <p>使用 <code>timedelta</code> 作为调度意味着任务将以30秒的间隔发送（第一个任务将在 <code>celery beat</code> 启动后30秒发送，然后在每次运行后30秒发送）。</p> <p>还存在类似 Crontab 的调度，请参阅 <code>Crontab schedules</code> 部分。</p> <p>与 <code>cron</code> 类似，如果第一个任务在下一个任务开始前未完成，任务可能会重叠。如果这是一个问题，您应该使用锁定策略来确保一次只能运行一个实例。</p>","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#_5","level":3,"title":"可用字段","text":"字段 描述 <code>task</code>  要执行的任务名称。 任务名称在用户指南的 [任务名称](../user-guide/tasks.md#task-names){target=\"_blank\"} 部分中描述。 请注意，这不是任务的导入路径，即使默认 命名模式是这样构建的。  <code>schedule</code>  执行频率。 这可以是整数秒数、<code>timedelta</code> 或  <code>crontab</code>。您还可以通过扩展 <code>schedule</code> 的接口来定义自己的自定义调度类型。  <code>args</code>  位置参数（<code>list</code> 或 <code>tuple</code>）。  <code>kwargs</code>  关键字参数（<code>dict</code>）。  <code>options</code>  执行选项（<code>dict</code>）。 这可以是 <code>apply_async</code> 支持的 任何参数——`exchange`、`routing_key`、`expires` 等。  <code>relative</code>  如果 `relative` 为 true，<code>timedelta</code> 调度将按 \"时钟\"调度。这意味着频率将根据 <code>timedelta</code> 的 周期四舍五入到最接近的秒、分钟、小时或天。 默认情况下 <code>relative</code> 为 false，频率不会被四舍五入，并且将 相对于 <code>celery beat</code> 启动的时间。","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#crontab","level":2,"title":"Crontab 调度","text":"<p>如果您想对任务执行时间有更多控制，例如特定的时间点或星期几，您可以使用 <code>crontab</code> 调度类型：</p> <pre><code>from celery.schedules import crontab\n\napp.conf.beat_schedule = {\n    # 每周一早上7:30执行\n    'add-every-monday-morning': {\n        'task': 'tasks.add',\n        'schedule': crontab(hour=7, minute=30, day_of_week=1),\n        'args': (16, 16),\n    },\n}\n</code></pre> <p>这些 Crontab 表达式的语法非常灵活。</p> <p>一些示例：</p> 示例 含义 <code>crontab()</code> 每分钟执行。 <code>crontab(minute=0, hour=0)</code> 每天午夜执行。 <code>crontab(minute=0, hour='*/3')</code> 每三小时执行：午夜、凌晨3点、早上6点、上午9点、中午12点、下午3点、下午6点、晚上9点。 <code>crontab(minute=0, hour='0,3,6,9,12,15,18,21')</code> 同上。 <code>crontab(minute='*/15')</code> 每15分钟执行。 <code>crontab(day_of_week='sunday')</code> 每周日每分钟执行（！）。 <code>crontab(minute='*', hour='*', day_of_week='sun')</code> 同上。 <code>crontab(minute='*/10', hour='3,17,22', day_of_week='thu,fri')</code> 每十分钟执行，但仅在周四或周五的凌晨3-4点、下午5-6点、晚上10-11点之间执行。 <code>crontab(minute=0, hour='*/2,*/3')</code> 每偶数小时执行，以及每能被三整除的小时执行。这意味着：在每个小时执行，除了：凌晨1点、凌晨5点、早上7点、上午11点、下午1点、下午5点、晚上7点、晚上11点 <code>crontab(minute=0, hour='*/5')</code> 每能被五整除的小时执行。这意味着它在下午3点触发，而不是下午5点（因为下午3点等于24小时制中的\"15\"，可以被5整除）。 <code>crontab(minute=0, hour='*/3,8-17')</code> 每能被三整除的小时执行，以及在办公时间（上午8点-下午5点）的每个小时执行。 <code>crontab(0, 0, day_of_month='2')</code> 每月的第二天执行。 <code>crontab(0, 0, day_of_month='2-30/2')</code> 在每个偶数日执行。 <code>crontab(0, 0, day_of_month='1-7,15-21')</code> 在每月的第一周和第三周执行。 <code>crontab(0, 0, day_of_month='11', month_of_year='5')</code> 每年5月11日执行。 <code>crontab(0, 0, month_of_year='*/3')</code> 在每个季度的第一个月的每一天执行。 <p>有关更多文档，请参阅 <code>crontab</code>。</p>","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#solar","level":2,"title":"Solar 调度","text":"<p>如果你有一个任务需要根据日出、日落、黎明或黄昏来执行，你可以使用 <code>solar</code> 调度类型：</p> <pre><code>from celery.schedules import solar\n\napp.conf.beat_schedule = {\n    # 在墨尔本日落时执行\n    'add-at-melbourne-sunset': {\n        'task': 'tasks.add',\n        'schedule': solar('sunset', -37.81753, 144.96715),\n        'args': (16, 16),\n    },\n}\n</code></pre> <p>参数很简单：<code>solar(event, latitude, longitude)</code></p> <p>请确保使用正确的纬度和经度符号：</p> 符号 参数 含义 <code>+</code> <code>latitude</code> 北纬 <code>-</code> <code>latitude</code> 南纬 <code>+</code> <code>longitude</code> 东经 <code>-</code> <code>longitude</code> 西经 <p>可能的事件类型有：</p> 事件 含义 <code>dawn_astronomical</code> 在天色不再完全黑暗的时刻执行。此时太阳位于地平线以下18度。 <code>dawn_nautical</code> 在有足够阳光使地平线和某些物体可区分时执行；正式来说，当太阳位于地平线以下12度时。 <code>dawn_civil</code> 在有足够光线使物体可区分，从而可以开始户外活动时执行；正式来说，当太阳位于地平线以下6度时。 <code>sunrise</code> 在早晨太阳的上边缘出现在东方地平线上时执行。 <code>solar_noon</code> 在太阳当天达到地平线最高点时执行。 <code>sunset</code> 在傍晚太阳的后边缘消失在西方地平线上时执行。 <code>dusk_civil</code> 在民用黄昏结束时执行，此时物体仍然可区分，一些星星和行星可见。正式来说，当太阳位于地平线以下6度时。 <code>dusk_nautical</code> 在太阳位于地平线以下12度时执行。物体不再可区分，地平线也不再肉眼可见。 <code>dusk_astronomical</code> 在天色完全变暗的时刻之后执行；正式来说，当太阳位于地平线以下18度时。 <p>所有太阳事件都使用UTC时间计算，因此不受您时区设置的影响。</p> <p>在极地地区，太阳可能不会每天升起或落下。调度器能够处理这些情况（例如，在太阳不升起的日子，<code>sunrise</code> 事件不会运行）。唯一的例外是 <code>solar_noon</code>，它被正式定义为太阳穿过天球子午线的时刻，即使太阳在地平线以下，它也会每天发生。</p> <p>黄昏被定义为黎明和日出之间的时期；以及日落和黄昏之间的时期。您可以根据您对黄昏的定义（民用、航海或天文）以及您希望事件在黄昏开始还是结束时发生，使用上面列表中的适当事件来安排\"黄昏\"相关的事件。</p> <p>有关更多文档，请参阅 <code>solar</code>。</p>","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#starting-the-scheduler","level":2,"title":"启动调度器","text":"<p>要启动 <code>celery beat</code> 服务：</p> <pre><code>celery -A proj beat\n</code></pre> <p>你也可以通过启用工作器的 <code>celery worker -B</code> 选项将 <code>beat</code> 嵌入到工作器中，如果你永远不会运行超过一个工作节点，这很方便，但不常用，因此不推荐在生产环境中使用：</p> <pre><code>celery -A proj worker -B\n</code></pre> <p>Beat 需要将任务的最后运行时间存储在本地数据库文件中（默认名为 <code>celerybeat-schedule</code>），因此它需要访问当前目录的写入权限，或者你可以为此文件指定自定义位置：</p> <pre><code>celery -A proj beat -s /home/celery/var/run/celerybeat-schedule\n</code></pre> <p>Note</p> <p>要将 beat 守护进程化，请参阅 守护进程指南。</p>","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/periodic-tasks/#_6","level":3,"title":"使用自定义调度器类","text":"<p>自定义调度器类可以在命令行上指定（使用 <code>celery beat --scheduler</code> 参数）。</p> <p>默认调度器是 <code>celery.beat.PersistentScheduler</code>，它只是在本地 <code>shelve</code> 数据库文件中跟踪最后运行时间。</p> <p>还有 <code>django-celery-beat</code> 扩展，它将计划存储在 Django 数据库中，并提供了一个方便的管理界面来在运行时管理周期性任务。</p> <p>要安装和使用此扩展：</p> <ol> <li> <p>使用 <code>pip</code> 安装包：</p> <pre><code>pip install django-celery-beat\n</code></pre> </li> <li> <p>将 <code>django_celery_beat</code> 模块添加到 Django 项目的 <code>settings.py</code> 中的 <code>INSTALLED_APPS</code>：：</p> <pre><code>INSTALLED_APPS = (\n    ...,\n    'django_celery_beat',\n)\n</code></pre> <p>注意模块名称中没有破折号，只有下划线。</p> </li> <li> <p>应用 Django 数据库迁移以创建必要的表：</p> <pre><code>python manage.py migrate\n</code></pre> </li> <li> <p>使用 <code>django_celery_beat.schedulers:DatabaseScheduler</code> 调度器启动 <code>celery beat</code> 服务：</p> <pre><code>celery -A proj beat -l INFO --scheduler django_celery_beat.schedulers:DatabaseScheduler\n</code></pre> <p>注意：你也可以直接将其添加为 <code>beat_scheduler</code> 设置。</p> </li> <li> <p>访问 Django-Admin 界面设置一些周期性任务。</p> </li> </ol>","path":["用户指南","周期性任务"],"tags":[]},{"location":"user-guide/routing/","level":1,"title":"路由任务","text":"","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_1","level":2,"title":"基础","text":"","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#routing-automatic","level":3,"title":"自动路由","text":"<p>最简单的路由方式是使用 <code>task_create_missing_queues</code> 设置（默认启用）。</p> <p>启用此设置后，未在 <code>task_queues</code> 中定义的命名队列将自动创建。这使得执行简单的路由任务变得容易。</p> <p>假设您有两个服务器 <code>x</code> 和 <code>y</code> 处理常规任务，还有一个服务器 <code>z</code> 仅处理与 feed 相关的任务。您可以使用以下配置::</p> <pre><code>task_routes = {'feed.tasks.import_feed': {'queue': 'feeds'}}\n</code></pre> <p>启用此路由后，导入 feed 任务将被路由到 <code>\"feeds\"</code> 队列，而所有其他任务将被路由到默认队列（出于历史原因命名为 <code>\"celery\"</code>）。</p> <p>或者，您可以使用 glob 模式匹配，甚至正则表达式来匹配 <code>feed.tasks</code> 命名空间中的所有任务：</p> <pre><code>app.conf.task_routes = {'feed.tasks.*': {'queue': 'feeds'}}\n</code></pre> <p>如果匹配模式的顺序很重要，您应该改用 items 格式指定路由器：</p> <pre><code>task_routes = ([\n    ('feed.tasks.*', {'queue': 'feeds'}),\n    ('web.tasks.*', {'queue': 'web'}),\n    (re.compile(r'(video|image)\\.tasks\\..*'), {'queue': 'media'}),\n],)\n</code></pre> <p>Note</p> <p><code>task_routes</code> 设置可以是字典，也可以是路由器对象列表，因此在这种情况下，我们需要将设置指定为包含列表的元组。</p> <p>安装路由器后，您可以像这样启动服务器 <code>z</code> 以仅处理 feeds 队列：</p> <pre><code>celery -A proj worker -Q feeds\n</code></pre> <p>您可以指定任意数量的队列，因此您可以让此服务器也处理默认队列：</p> <pre><code>celery -A proj worker -Q feeds,celery\n</code></pre>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_2","level":4,"title":"更改默认队列的名称","text":"<p>您可以使用以下配置更改默认队列的名称：</p> <pre><code>app.conf.task_default_queue = 'default'\n</code></pre>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_3","level":4,"title":"队列是如何定义的","text":"<p>此功能的目的是为只有基本需求的用户隐藏复杂的 AMQP 协议。然而——您可能仍然对这些队列是如何声明的感兴趣。</p> <p>名为 <code>\"video\"</code> 的队列将使用以下设置创建：</p> <pre><code>{'exchange': 'video',\n 'exchange_type': 'direct',\n 'routing_key': 'video'}\n</code></pre> <p>像 <code>Redis</code> 或 <code>SQS</code> 这样的非 AMQP 后端不支持交换器，因此它们要求交换器与队列具有相同的名称。使用这种设计确保它也能适用于它们。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_4","level":3,"title":"手动路由","text":"<p>假设您有两个服务器 <code>x</code> 和 <code>y</code> 处理常规任务，还有一个服务器 <code>z</code> 仅处理与 feed 相关的任务，您可以使用以下配置：</p> <pre><code>from kombu import Queue\n\napp.conf.task_default_queue = 'default'\napp.conf.task_queues = (\n    Queue('default',    routing_key='task.#'),\n    Queue('feed_tasks', routing_key='feed.#'),\n)\napp.conf.task_default_exchange = 'tasks'\napp.conf.task_default_exchange_type = 'topic'\napp.conf.task_default_routing_key = 'task.default'\n</code></pre> <p><code>task_queues</code> 是 <code>kombu.entity.Queue</code> 实例的列表。 如果您没有为键设置交换器或交换器类型值，这些值将从 <code>task_default_exchange</code> 和 <code>task_default_exchange_type</code> 设置中获取。</p> <p>要将任务路由到 <code>feed_tasks</code> 队列，您可以在 <code>task_routes</code> 设置中添加一个条目：</p> <pre><code>task_routes = {\n    'feeds.tasks.import_feed': {\n        'queue': 'feed_tasks',\n        'routing_key': 'feed.import',\n    },\n}\n</code></pre> <p>您还可以使用 <code>apply_async()</code> 或 <code>send_task()</code> 的 <code>routing_key</code> 参数覆盖此设置：</p> <pre><code>&gt;&gt;&gt; from feeds.tasks import import_feed\n&gt;&gt;&gt; import_feed.apply_async(args=['http://cnn.com/rss'],\n...                         queue='feed_tasks',\n...                         routing_key='feed.import')\n</code></pre> <p>要使服务器 <code>z</code> 专门从 feed 队列消费，您可以使用 :option:<code>celery worker -Q</code> 选项启动它：</p> <pre><code>celery -A proj worker -Q feed_tasks --hostname=z@%h\n</code></pre> <p>服务器 <code>x</code> 和 <code>y</code> 必须配置为从默认队列消费：</p> <pre><code>celery -A proj worker -Q default --hostname=x@%h\ncelery -A proj worker -Q default --hostname=y@%h\n</code></pre> <p>如果您愿意，您甚至可以让您的 feed 处理工作器也处理常规任务，也许在工作量很大的时候：</p> <pre><code>celery -A proj worker -Q feed_tasks,default --hostname=z@%h\n</code></pre> <p>如果您有另一个队列但想要添加到另一个交换器，只需指定自定义交换器和交换器类型：</p> <pre><code>from kombu import Exchange, Queue\n\napp.conf.task_queues = (\n    Queue('feed_tasks',    routing_key='feed.#'),\n    Queue('regular_tasks', routing_key='task.#'),\n    Queue('image_tasks',   exchange=Exchange('mediatasks', type='direct'),\n                           routing_key='image.compress'),\n)\n</code></pre> <p>如果您对这些术语感到困惑，您应该阅读 AMQP 的相关资料。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_5","level":2,"title":"特殊路由选项","text":"","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#rabbitmq","level":3,"title":"RabbitMQ 消息优先级","text":"<p>可以通过设置 <code>x-max-priority</code> 参数来配置队列以支持优先级：</p> <pre><code>from kombu import Exchange, Queue\n\napp.conf.task_queues = [\n    Queue('tasks', Exchange('tasks'), routing_key='tasks',\n          queue_arguments={'x-max-priority': 10}),\n]\n</code></pre> <p>可以使用 <code>task_queue_max_priority</code> 设置来为所有队列设置默认值：</p> <pre><code>app.conf.task_queue_max_priority = 10\n</code></pre> <p>也可以使用 <code>task_default_priority</code> 设置来为所有任务指定默认优先级：</p> <pre><code>app.conf.task_default_priority = 5\n</code></pre>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#redis","level":3,"title":"Redis 消息优先级","text":"<p>虽然 Celery Redis 传输确实尊重优先级字段，但 Redis 本身没有优先级的概念。在尝试使用 Redis 实现优先级之前，请阅读此说明，因为您可能会遇到一些意外行为。</p> <p>要开始基于优先级调度任务，您需要配置 queue_order_strategy 传输选项。</p> <pre><code>app.conf.broker_transport_options = {\n    'queue_order_strategy': 'priority',\n}\n</code></pre> <p>优先级支持是通过为每个队列创建 n 个列表来实现的。这意味着即使有 10 个（0-9）优先级级别，默认情况下这些级别会被合并为 4 个级别以节省资源。这意味着名为 celery 的队列实际上会被拆分为 4 个队列。</p> <p>最高优先级的队列将被命名为 celery，而其他队列将有一个分隔符（默认为 <code>\\x06\\x16</code>）并在队列名称后附加其优先级编号。</p> <pre><code>['celery', 'celery\\x06\\x163', 'celery\\x06\\x166', 'celery\\x06\\x169']\n</code></pre> <p>如果您想要更多的优先级级别或不同的分隔符，可以设置 priority_steps 和 sep 传输选项：</p> <pre><code>app.conf.broker_transport_options = {\n    'priority_steps': list(range(10)),\n    'sep': ':',\n    'queue_order_strategy': 'priority',\n}\n</code></pre> <p>上面的配置将为您提供这些队列名称：</p> <pre><code>['celery', 'celery:1', 'celery:2', 'celery:3', 'celery:4', 'celery:5', 'celery:6', 'celery:7', 'celery:8', 'celery:9']\n</code></pre> <p>也就是说，请注意这永远不会像在代理服务器级别实现的优先级那样好，最多只能是近似值。但它可能仍然足够满足您的应用程序需求。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#amqp","level":2,"title":"AMQP 基础","text":"","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_6","level":3,"title":"消息","text":"<p>一条消息由头部和主体组成。Celery 使用头部来存储消息的内容类型和内容编码。内容类型通常是用于序列化消息的序列化格式。主体包含要执行的任务名称、任务ID（UUID）、应用任务的参数以及一些额外的元数据——比如重试次数或预计到达时间（ETA）。</p> <p>这是一个表示为Python字典的任务消息示例：</p> <pre><code>{'task': 'myapp.tasks.add',\n 'id': '54086c5e-6193-4575-8308-dbab76798756',\n 'args': [4, 4],\n 'kwargs': {}}\n</code></pre>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_7","level":3,"title":"生产者、消费者和代理","text":"<p>发送消息的客户端通常称为发布者或生产者，而接收消息的实体称为消费者。</p> <p>代理是消息服务器，负责将消息从生产者路由到消费者。</p> <p>在AMQP相关材料中，你很可能会经常看到这些术语。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_8","level":3,"title":"交换机、队列和路由键","text":"<ol> <li>消息被发送到交换机。</li> <li>交换机将消息路由到一个或多个队列。存在几种交换机类型，提供不同的路由方式，或实现不同的消息传递场景。</li> <li>消息在队列中等待，直到有人消费它。</li> <li>当消息被确认后，它会被从队列中删除。</li> </ol> <p>发送和接收消息所需的步骤是：</p> <ol> <li>创建一个交换机</li> <li>创建一个队列</li> <li>将队列绑定到交换机</li> </ol> <p>Celery 会自动创建 <code>task_queues</code> 中队列工作所需的实体（除非队列的 <code>auto_declare</code> 设置设为 <code>False</code>）。</p> <p>这是一个包含三个队列的队列配置示例；一个用于视频，一个用于图像，还有一个默认队列用于其他所有内容：</p> <pre><code>from kombu import Exchange, Queue\n\napp.conf.task_queues = (\n    Queue('default', Exchange('default'), routing_key='default'),\n    Queue('videos',  Exchange('media'),   routing_key='media.video'),\n    Queue('images',  Exchange('media'),   routing_key='media.image'),\n)\napp.conf.task_default_queue = 'default'\napp.conf.task_default_exchange_type = 'direct'\napp.conf.task_default_routing_key = 'default'\n</code></pre>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_9","level":3,"title":"交换机类型","text":"<p>交换机类型定义了消息如何通过交换机进行路由。标准中定义的交换机类型有 <code>direct</code>、<code>topic</code>、<code>fanout</code> 和 <code>headers</code>。此外，非标准的交换机类型也可作为 RabbitMQ 的插件使用，比如 Michael Bridgen 的 last-value-cache 插件。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_10","level":4,"title":"直连交换机","text":"<p>直连交换机通过精确的路由键进行匹配，因此绑定到路由键 <code>video</code> 的队列只会接收具有该路由键的消息。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_11","level":4,"title":"主题交换机","text":"<p>主题交换机使用点分隔的单词和通配符字符来匹配路由键：<code>*</code>（匹配单个单词）和 <code>#</code>（匹配零个或多个单词）。</p> <p>对于像 <code>usa.news</code>、<code>usa.weather</code>、<code>norway.news</code> 和 <code>norway.weather</code> 这样的路由键，绑定可以是 <code>*.news</code>（所有新闻）、<code>usa.#</code>（美国的所有项目）或 <code>usa.weather</code>（所有美国天气项目）。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#api","level":4,"title":"相关API命令","text":"<p>exchange.declare(exchange_name, type, passive, durable, auto_delete, internal)</p> <p>通过名称声明一个交换机。</p> 关键字 描述 passive 被动模式意味着不会创建交换机，但你可以使用它来检查交换机是否已存在。 durable 持久化交换机是持久的（即，它们在代理重启后仍然存在）。 auto_delete 这意味着当没有更多队列使用该交换机时，代理将删除它。 <p>queue.declare(queue_name, passive, durable, exclusive, auto_delete)</p> <p>通过名称声明一个队列。</p> <p>独占队列只能由当前连接消费。独占也意味着 <code>auto_delete</code>。</p> <p>queue.bind(queue_name, exchange_name, routing_key)</p> <p>使用路由键将队列绑定到交换机。</p> <p>未绑定的队列不会接收消息，因此这是必要的。</p> <p>参见 <code>amqp.channel.Channel.queue_bind</code></p> <p>queue.delete(name, if_unused=False, if_empty=False)</p> <p>删除一个队列及其绑定。</p> <p>参见 <code>amqp.channel.Channel.queue_delete</code></p> <p>exchange.delete(name, if_unused=False)</p> <p>删除一个交换机。</p> <p>参见 <code>amqp.channel.Channel.exchange_delete</code></p> <p>Note</p> <p>声明并不一定意味着\"创建\"。当你声明时，你断言该实体存在且可操作。没有规则规定谁应该最初创建交换机/队列/绑定，无论是消费者还是生产者。通常，第一个需要它的人将是创建它的人。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#api_1","level":3,"title":"动手实践API","text":"<p>Celery 附带了一个名为 <code>celery amqp</code> 的工具，用于通过命令行访问 AMQP API，可以执行管理任务，如创建/删除队列和交换机、清空队列或发送消息。它也可以用于非 AMQP 代理，但不同的实现可能不支持所有命令。</p> <p>你可以直接在 <code>celery amqp</code> 的参数中写入命令，或者不带参数启动它以进入 shell 模式：</p> <pre><code>celery -A proj amqp\n-&gt; connecting to amqp://guest@localhost:5672/.\n-&gt; connected.\n1&gt;\n</code></pre> <p>这里的 <code>1&gt;</code> 是提示符。数字 1 表示你到目前为止执行的命令数量。输入 <code>help</code> 查看可用的命令列表。 它还支持自动补全，因此你可以开始输入命令，然后按 <code>tab</code> 键显示可能的匹配列表。</p> <p>让我们创建一个可以发送消息的队列：</p> <pre><code>celery -A proj amqp\n1&gt; exchange.declare testexchange direct\nok.\n2&gt; queue.declare testqueue\nok. queue:testqueue messages:0 consumers:0.\n3&gt; queue.bind testqueue testexchange testkey\nok.\n</code></pre> <p>这创建了直连交换机 <code>testexchange</code> 和一个名为 <code>testqueue</code> 的队列。该队列使用路由键 <code>testkey</code> 绑定到交换机。</p> <p>从现在开始，所有发送到交换机 <code>testexchange</code> 且路由键为 <code>testkey</code> 的消息都将被移动到该队列。你可以使用 <code>basic.publish</code> 命令发送消息：</p> <pre><code>4&gt; basic.publish 'This is a message!' testexchange testkey\nok.\n</code></pre> <p>现在消息已发送，你可以再次检索它。你可以使用 <code>basic.get</code> 命令，它以同步方式轮询队列中的新消息（这对于维护任务来说是可以的，但对于服务，你应该使用 <code>basic.consume</code>）。</p> <p>从队列中弹出一条消息：</p> <pre><code>5&gt; basic.get testqueue\n{'body': 'This is a message!',\n 'delivery_info': {'delivery_tag': 1,\n                   'exchange': u'testexchange',\n                   'message_count': 0,\n                   'redelivered': False,\n                   'routing_key': u'testkey'},\n 'properties': {}}\n</code></pre> <p>AMQP 使用确认来表示消息已成功接收和处理。如果消息未被确认且消费者通道关闭，该消息将被传递给另一个消费者。</p> <p>注意上面结构中列出的投递标签；在连接通道内，每个接收到的消息都有一个唯一的投递标签，该标签用于确认消息。还要注意投递标签在连接之间不是唯一的，因此在另一个客户端中，投递标签 <code>1</code> 可能指向与此通道中不同的消息。</p> <p>你可以使用 <code>basic.ack</code> 确认你收到的消息：</p> <pre><code>6&gt; basic.ack 1\nok.\n</code></pre> <p>测试会话结束后，你应该删除创建的实体以进行清理：</p> <pre><code>7&gt; queue.delete testqueue\nok. 0 messages deleted.\n8&gt; exchange.delete testexchange\nok.\n</code></pre>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_12","level":2,"title":"路由任务","text":"","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_13","level":3,"title":"定义队列","text":"<p>在 Celery 中，可用队列由 <code>task_queues</code> 设置定义。</p> <p>这是一个包含三个队列的示例配置；一个用于视频，一个用于图像，还有一个默认队列用于其他所有任务：</p> <pre><code>default_exchange = Exchange('default', type='direct')\nmedia_exchange = Exchange('media', type='direct')\n\napp.conf.task_queues = (\n    Queue('default', default_exchange, routing_key='default'),\n    Queue('videos', media_exchange, routing_key='media.video'),\n    Queue('images', media_exchange, routing_key='media.image')\n)\napp.conf.task_default_queue = 'default'\napp.conf.task_default_exchange = 'default'\napp.conf.task_default_routing_key = 'default'\n</code></pre> <p>在这里，<code>task_default_queue</code> 将用于路由没有显式路由的任务。</p> <p>默认的交换机、交换机类型和路由键将用作任务的默认路由值，以及 <code>task_queues</code> 中条目的默认值。</p> <p>还支持对单个队列的多个绑定。这是一个两个路由键都绑定到同一个队列的示例：</p> <pre><code>from kombu import Exchange, Queue, binding\n\nmedia_exchange = Exchange('media', type='direct')\n\nCELERY_QUEUES = (\n    Queue('media', [\n        binding(media_exchange, routing_key='media.video'),\n        binding(media_exchange, routing_key='media.image'),\n    ]),\n)\n</code></pre>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_14","level":3,"title":"指定任务目的地","text":"<p>任务的目的地由以下因素决定（按顺序）：</p> <ol> <li><code>apply_async()</code> 的路由参数</li> <li>在 <code>Task</code> 本身上定义的路由相关属性</li> <li><code>task_routes</code> 中定义的 <code>routers</code></li> </ol> <p>最佳实践是不硬编码这些设置，而是通过使用 <code>routers</code> 将其作为配置选项；这是最灵活的方法，但仍然可以将合理的默认值设置为任务属性。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_15","level":3,"title":"路由器","text":"<p>路由器是一个决定任务路由选项的函数。</p> <p>定义新路由器只需要定义一个具有以下签名的函数 <code>(name, args, kwargs, options, task=None, **kw)</code>：</p> <pre><code>def route_task(name, args, kwargs, options, task=None, **kw):\n    if name == 'myapp.tasks.compress_video':\n        return {'exchange': 'video', 'exchange_type': 'topic', 'routing_key': 'video.compress'}\n</code></pre> <p>如果您返回 <code>queue</code> 键，它将与 <code>task_queues</code> 中该队列的已定义设置一起展开：</p> <pre><code>{'queue': 'video', 'routing_key': 'video.compress'}\n</code></pre> <p>变成 --&gt;</p> <pre><code>{'queue': 'video',\n 'exchange': 'video',\n 'exchange_type': 'topic',\n 'routing_key': 'video.compress'}\n</code></pre> <p>您可以通过将路由器类添加到 <code>task_routes</code> 设置中来安装它们：</p> <pre><code>task_routes = (route_task,)\n</code></pre> <p>路由器函数也可以通过名称添加：</p> <pre><code>task_routes = ('myapp.routers.route_task',)\n</code></pre> <p>对于像上面路由器示例那样的简单任务名称 -&gt; 路由映射，您可以简单地将字典放入 <code>task_routes</code> 以获得相同的行为：</p> <pre><code>task_routes = {\n    'myapp.tasks.compress_video': {\n        'queue': 'video',\n        'routing_key': 'video.compress',\n    },\n}\n</code></pre> <p>然后路由器将按顺序遍历，将在第一个返回真值的路由器处停止，并将其用作任务的最终路由。</p> <p>您还可以定义多个路由器序列：</p> <pre><code>task_routes = [\n    route_task,\n    {\n        'myapp.tasks.compress_video': {\n            'queue': 'video',\n            'routing_key': 'video.compress',\n        }\n    },\n]\n</code></pre> <p>然后路由器将依次访问，第一个返回值的路由器将被选择。</p> <p>如果您使用 Redis 或 RabbitMQ，还可以在路由中指定队列的默认优先级。</p> <pre><code>task_routes = {\n    'myapp.tasks.compress_video': {\n        'queue': 'video',\n        'routing_key': 'video.compress',\n        'priority': 10,\n    },\n}\n</code></pre> <p>类似地，在任务上调用 <code>apply_async</code> 将覆盖该默认优先级。</p> <pre><code>task.apply_async(priority=0)\n</code></pre> <p>优先级顺序和集群响应性</p> <p>需要注意的是，由于工作进程预取，如果同时提交一批任务，它们最初可能不按优先级顺序排列。禁用工作进程预取将防止此问题，但可能导致小型快速任务的性能不理想。在大多数情况下，简单地将 <code>worker_prefetch_multiplier</code> 减少到 1 是增加系统响应性的更简单、更干净的方法，而无需承担完全禁用预取的成本。</p> <p>请注意，使用 redis 代理时，优先级值是反向排序的：0 为最高优先级。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/routing/#_16","level":3,"title":"广播","text":"<p>Celery 还支持广播路由。 这是一个将任务副本发送给连接到它的所有工作进程的交换机 <code>broadcast_tasks</code> 的示例：</p> <pre><code>from kombu.common import Broadcast\n\napp.conf.task_queues = (Broadcast('broadcast_tasks'),)\napp.conf.task_routes = {\n    'tasks.reload_cache': {\n        'queue': 'broadcast_tasks',\n        'exchange': 'broadcast_tasks'\n    }\n}\n</code></pre> <p>现在 <code>tasks.reload_cache</code> 任务将被发送给从此队列消费的每个工作进程。</p> <p>这是另一个广播路由的示例，这次使用 <code>celery beat</code> 调度：</p> <pre><code>from kombu.common import Broadcast\nfrom celery.schedules import crontab\n\napp.conf.task_queues = (Broadcast('broadcast_tasks'),)\n\napp.conf.beat_schedule = {\n    'test-task': {\n        'task': 'tasks.reload_cache',\n        'schedule': crontab(minute=0, hour='*/3'),\n        'options': {'exchange': 'broadcast_tasks'}\n    },\n}\n</code></pre> <p>广播和结果</p> <p>请注意，Celery 结果没有定义如果两个任务具有相同的 task_id 会发生什么。如果同一个任务被分发给多个工作进程，则状态历史可能不会被保留。</p> <p>在这种情况下，设置 <code>task.ignore_result</code> 属性是一个好主意。</p>","path":["用户指南","路由任务"],"tags":[]},{"location":"user-guide/security/","level":1,"title":"安全","text":"","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#_2","level":2,"title":"介绍","text":"<p>虽然 Celery 在设计时考虑了安全性，但仍应将其视为不安全的组件。</p> <p>根据您的安全策略，可以采取各种步骤来使您的 Celery 安装更加安全。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#_3","level":2,"title":"关注领域","text":"","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#broker","level":3,"title":"代理 (Broker)","text":"<p>必须保护代理免受不必要的访问，尤其是在可公开访问的情况下。默认情况下，工作进程信任从代理获取的数据未被篡改。</p> <p>第一道防线应该是在代理前面设置防火墙，只允许白名单中的机器访问它。</p> <p>请记住，防火墙配置错误和临时禁用防火墙在现实世界中都很常见。健全的安全策略包括监控防火墙设备以检测它们是否被禁用，无论是意外还是故意。</p> <p>换句话说，也不应盲目信任防火墙。</p> <p>如果您的代理支持细粒度访问控制，例如 RabbitMQ，您应该考虑启用此功能。例如，请参阅 http://www.rabbitmq.com/access-control.html。</p> <p>如果您的代理后端支持，可以使用 <code>broker_use_ssl</code> 启用端到端 SSL 加密和身份验证。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#client","level":3,"title":"客户端 (Client)","text":"<p>在 Celery 中，“客户端”指的是任何向代理发送消息的东西，例如应用任务的 Web 服务器。</p> <p>如果可以通过客户端发送任意消息，那么正确保护代理就没有意义。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#worker","level":3,"title":"工作进程 (Worker)","text":"<p>在工作进程内部运行的任务的默认权限与工作进程本身的权限相同。这适用于资源，例如：内存、文件系统和设备。</p> <p>此规则的一个例外是使用基于多进程的任务池（当前为默认设置）。在这种情况下，任务将有权访问由于 <code>fork()</code> 调用而复制的任何内存，以及在同一工作进程子进程中由父任务写入的内存内容。</p> <p>可以通过在每个任务中启动子进程（<code>fork()</code> + <code>execve()</code>）来限制对内存内容的访问。</p> <p>可以通过使用 chroot、jail、沙盒、虚拟机或平台或附加软件启用的其他机制来限制文件系统和设备访问。</p> <p>还要注意，在工作进程中执行的任何任务都将具有与其运行的机器相同的网络访问权限。如果工作进程位于内部网络上，建议为出站流量添加防火墙规则。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#serializers","level":2,"title":"序列化器 (Serializers)","text":"<p>自版本 4.0 起，默认的序列化器是 JSON，但由于它仅支持有限的一组类型，您可能需要考虑使用 pickle 进行序列化。</p> <p><code>pickle</code> 序列化器很方便，因为它可以序列化几乎任何 Python 对象，甚至经过一些处理后可以序列化函数，但出于同样的原因，<code>pickle</code> 本质上是不安全的，应避免在客户端不受信任或未经验证时使用。</p> <p>您可以通过在 <code>accept_content</code> 设置中指定接受的内容类型的白名单来禁用不受信任的内容：</p> <p>Note</p> <p>此设置在版本 3.0.18 中首次支持。如果您运行的是早期版本，它将被忽略，因此请确保您运行的版本支持它。</p> <pre><code>accept_content = ['json']\n</code></pre> <p>这接受序列化器名称和内容类型的列表，因此您也可以为 json 指定内容类型：</p> <pre><code>accept_content = ['application/json']\n</code></pre> <p>Celery 还附带了一个特殊的 <code>auth</code> 序列化器，用于验证 Celery 客户端和工作进程之间的通信，确保消息来自可信来源。 使用公钥密码学，<code>auth</code> 序列化器可以验证发送者的真实性。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#_4","level":2,"title":"消息签名","text":"<p>Celery 可以使用 <code>cryptography</code> 库通过 <code>公钥密码学</code> 来签名消息，其中客户端发送的消息使用私钥签名，然后由工作进程使用公钥证书进行验证。</p> <p>最佳情况下，证书应由官方的证书颁发机构签名，但也可以使用自签名证书。</p> <p>要启用此功能，您应将 <code>task_serializer</code> 设置配置为使用 <code>auth</code> 序列化器。要强制工作进程仅接受签名消息，应将 <code>accept_content</code> 设置为 <code>['auth']</code>。 对于事件协议的额外签名，将 <code>event_serializer</code> 设置为 <code>auth</code>。 还需要配置文件系统中用于定位私钥和证书的路径：分别是 <code>security_key</code>、<code>security_certificate</code> 和 <code>security_cert_store</code> 设置。 您可以使用 <code>security_digest</code> 调整签名算法。 如果使用加密的私钥，可以通过 <code>security_key_password</code> 配置密码。</p> <p>配置这些后，还需要调用 <code>setup_security()</code> 函数。请注意，这也会禁用所有不安全的序列化器，以便工作进程不会接受不受信任内容类型的消息。</p> <p>这是一个使用 <code>auth</code> 序列化器的配置示例，私钥和证书文件位于 <code>/etc/ssl</code> 目录中。</p> <pre><code>app = Celery()\napp.conf.update(\n    security_key='/etc/ssl/private/worker.key'\n    security_certificate='/etc/ssl/certs/worker.pem'\n    security_cert_store='/etc/ssl/certs/*.pem',\n    security_digest='sha256',\n    task_serializer='auth',\n    event_serializer='auth',\n    accept_content=['auth']\n)\napp.setup_security()\n</code></pre> <p>Note</p> <p>虽然不禁止使用相对路径，但建议对这些文件使用绝对路径。</p> <p>另请注意，<code>auth</code> 序列化器不会加密消息内容，因此如果需要，必须单独启用加密功能。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#_5","level":2,"title":"入侵检测","text":"<p>在防御系统免受入侵者攻击时，最重要的部分是能够检测系统是否已被入侵。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#_6","level":3,"title":"日志","text":"<p>日志通常是查找安全漏洞证据的第一个地方，但如果日志可以被篡改，它们就毫无用处。</p> <p>一个好的解决方案是设置带有专用日志服务器的集中式日志记录。应限制对其的访问。除了将所有日志放在一个地方之外，如果配置正确，它可以使入侵者更难篡改您的日志。</p> <p>使用 syslog（另请参阅 syslog-ng 和 rsyslog）应该相当容易设置。Celery 使用 <code>logging</code> 库，并且已经支持使用 syslog。</p> <p>对于偏执狂的一个提示是使用 UDP 发送日志，并切断日志服务器的网络电缆的传输部分 :-)</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/security/#tripwire","level":3,"title":"Tripwire","text":"<p>Tripwire 是一个（现在是商业的）数据完整性工具，有多个开源实现，用于在文件系统中保存文件的加密哈希值，以便在文件更改时向管理员发出警报。这样，当损害已经造成并且您的系统已被入侵时，您可以准确知道入侵者更改了哪些文件（密码文件、日志、后门、rootkit 等）。通常这是您能够检测到入侵的唯一方法。</p> <p>一些开源实现包括：</p> <ul> <li>OSSEC</li> <li>Samhain</li> <li>Open Source Tripwire</li> <li>AIDE</li> </ul> <p>此外，ZFS 文件系统带有内置的完整性检查功能，可以使用。</p>","path":["用户指南","安全"],"tags":[]},{"location":"user-guide/signals/","level":1,"title":"信号","text":"<p>信号允许解耦的应用程序在应用程序的其他地方发生某些操作时接收通知。</p> <p>Celery 附带了许多信号，您的应用程序可以连接到这些信号来增强某些操作的行为。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#_2","level":2,"title":"基础","text":"<p>多种类型的事件会触发信号，您可以连接到这些信号以在它们触发时执行操作。</p> <p>连接到 <code>after_task_publish</code> 信号的示例：</p> <pre><code>from celery.signals import after_task_publish\n\n@after_task_publish.connect\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # 关于任务的信息位于任务消息的头部中\n    # 使用任务协议版本 2\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    ))\n</code></pre> <p>某些信号还有一个发送者可以进行过滤。例如 <code>after_task_publish</code> 信号使用任务名称作为发送者，因此通过向 <code>celery.utils.dispatch.signal.Signal.connect</code> 提供 <code>sender</code> 参数，您可以将处理程序连接到每次发布名为 <code>\"proj.tasks.add\"</code> 的任务时被调用：</p> <pre><code>@after_task_publish.connect(sender='proj.tasks.add')\ndef task_sent_handler(sender=None, headers=None, body=None, **kwargs):\n    # 关于任务的信息位于任务消息的头部中\n    # 使用任务协议版本 2\n    info = headers if 'task' in headers else body\n    print('after_task_publish for task id {info[id]}'.format(\n        info=info,\n    ))\n</code></pre> <p>信号使用与 <code>django.core.dispatch</code> 相同的实现。因此，其他关键字参数（例如，signal）默认会传递给所有信号处理程序。</p> <p>信号处理程序的最佳实践是接受任意关键字参数（即 <code>**kwargs</code>）。这样，新的 Celery 版本可以添加额外的参数而不会破坏用户代码。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#signals","level":2,"title":"Signals","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#_3","level":3,"title":"任务信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#before_task_publish","level":4,"title":"<code>before_task_publish</code>","text":"<p>在任务发布之前触发。注意：此信号在发送任务的进程中执行。</p> <p>发送者是正在发送的任务名称。</p> 参数 描述 <code>body</code> 任务消息体。这是一个包含任务消息字段的映射。 <code>exchange</code> 要发送到的交换器名称或 <code>kombu.Exchange</code> 对象。 <code>routing_key</code> 发送消息时使用的路由键。 <code>headers</code> 应用程序头部映射（可以修改）。 <code>properties</code> 消息属性（可以修改）。 <code>declare</code> 在发布消息之前要声明的实体列表（<code>kombu.Exchange</code>、<code>kombu.Queue</code> 或 <code>kombu.binding</code>）。可以修改。 <code>retry_policy</code> 重试选项的映射。可以是 <code>kombu.Connection.ensure</code> 的任何参数，并且可以修改。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#after_task_publish","level":4,"title":"<code>after_task_publish</code>","text":"<p>当任务已发送到代理时触发。注意：此信号在发送任务的进程中执行。</p> <p>发送者是正在发送的任务名称。</p> 参数 描述 <code>headers</code> 任务消息头部。 <code>body</code> 任务消息体。 <code>exchange</code> 使用的交换器名称或 <code>kombu.Exchange</code> 对象。 <code>routing_key</code> 使用的路由键。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_prerun","level":4,"title":"<code>task_prerun</code>","text":"<p>在任务执行之前触发。</p> <p>发送者是正在执行的任务对象。</p> 参数 描述 <code>task_id</code> 要执行的任务ID。 <code>task</code> 正在执行的任务。 <code>args</code> 任务的位置参数。 <code>kwargs</code> 任务的关键字参数。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_postrun","level":4,"title":"<code>task_postrun</code>","text":"<p>在任务执行之后触发。</p> <p>发送者是被执行的任务对象。</p> 参数 描述 <code>task_id</code> 要执行的任务ID。 <code>task</code> 正在执行的任务。 <code>args</code> 任务的位置参数。 <code>kwargs</code> 任务的关键字参数。 <code>retval</code> 任务的返回值。 <code>state</code> 结果状态的名称。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_retry","level":4,"title":"<code>task_retry</code>","text":"<p>当任务将要重试时触发。</p> <p>发送者是任务对象。</p> 参数 描述 <code>request</code> 当前任务请求。 <code>reason</code> 重试原因（通常是一个异常实例，但总是可以强制转换为 <code>str</code>）。 <code>einfo</code> 详细的异常信息，包括回溯（一个 <code>billiard.einfo.ExceptionInfo</code> 对象）。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_success","level":4,"title":"<code>task_success</code>","text":"<p>当任务成功时触发。</p> <p>发送者是被执行的任务对象。</p> 参数 描述 <code>result</code> 任务的返回值。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_failure","level":4,"title":"<code>task_failure</code>","text":"<p>当任务失败时触发。</p> <p>发送者是被执行的任务对象。</p> 参数 描述 <code>task_id</code> 任务的ID。 <code>exception</code> 引发的异常实例。 <code>args</code> 任务调用时使用的位置参数。 <code>kwargs</code> 任务调用时使用的关键字参数。 <code>traceback</code> 堆栈跟踪对象。 <code>einfo</code> <code>billiard.einfo.ExceptionInfo</code> 实例。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_internal_error","level":4,"title":"<code>task_internal_error</code>","text":"<p>在执行任务时发生内部Celery错误时触发。</p> <p>发送者是被执行的任务对象。</p> 参数 描述 <code>task_id</code> 任务的ID。 <code>args</code> 任务调用时使用的位置参数。 <code>kwargs</code> 任务调用时使用的关键字参数。 <code>request</code> 原始请求字典。提供此参数是因为在异常引发时 <code>task.request</code> 可能尚未准备好。 <code>exception</code> 引发的异常实例。 <code>traceback</code> 堆栈跟踪对象。 <code>einfo</code> <code>billiard.einfo.ExceptionInfo</code> 实例。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_received","level":4,"title":"<code>task_received</code>","text":"<p>当从代理接收到任务并准备好执行时触发。</p> <p>发送者是消费者对象。</p> 参数 描述 <code>request</code> 这是一个 <code>celery.worker.request.Request</code> 实例，而不是 <code>task.request</code>。在使用prefork池时，此信号在父进程中触发，因此 <code>task.request</code> 不可用且不应使用。请改用此对象，因为它们共享许多相同的字段。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_revoked","level":4,"title":"<code>task_revoked</code>","text":"<p>当任务被工作器撤销/终止时触发。</p> <p>发送者是被撤销/终止的任务对象。</p> 参数 描述 <code>request</code> 这是一个 <code>celery.app.task.Context</code> 实例，而不是 <code>task.request</code>。在使用prefork池时，此信号在父进程中触发，因此 <code>task.request</code> 不可用且不应使用。请改用此对象，因为它们共享许多相同的字段。 <code>terminated</code> 如果任务被终止，则设置为 <code>True</code>。 <code>signum</code> 用于终止任务的信号编号。如果此值为 <code>None</code> 且 terminated 为 <code>True</code>，则应假定为 <code>TERM</code>。 <code>expired</code> 如果任务已过期，则设置为 <code>True</code>。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_unknown","level":4,"title":"<code>task_unknown</code>","text":"<p>当工作器接收到未注册任务的消息时触发。</p> <p>发送者是工作器的 <code>celery.worker.consumer.Consumer</code>。</p> 参数 描述 <code>name</code> 注册表中未找到的任务名称。 <code>id</code> 消息中找到的任务ID。 <code>message</code> 原始消息对象。 <code>exc</code> 发生的错误。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_rejected","level":4,"title":"<code>task_rejected</code>","text":"<p>当工作器在其任务队列之一接收到未知类型的消息时触发。</p> <p>发送者是工作器的 <code>celery.worker.consumer.Consumer</code>。</p> 参数 描述 <code>message</code> 原始消息对象。 <code>exc</code> 发生的错误（如果有）。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#_4","level":3,"title":"应用信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#import_modules","level":4,"title":"<code>import_modules</code>","text":"<p>当程序（worker、beat、shell等）请求导入 <code>include</code> 和 <code>imports</code> 设置中的模块时发送此信号。</p> <p>发送者是应用实例。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker","level":3,"title":"Worker 信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#celeryd_after_setup","level":4,"title":"<code>celeryd_after_setup</code>","text":"<p>此信号在 worker 实例设置完成后但在调用 run 之前发送。这意味着来自 <code>celery worker -Q</code> 选项的任何队列都已启用，日志记录已设置等等。</p> <p>它可以用于添加应始终从中消费的自定义队列，忽略 <code>celery worker -Q</code> 选项。以下是一个为每个 worker 设置直接队列的示例，这些队列随后可用于将任务路由到任何特定的 worker：</p> <pre><code>from celery.signals import celeryd_after_setup\n\n@celeryd_after_setup.connect\ndef setup_direct_queue(sender, instance, **kwargs):\n    queue_name = '{0}.dq'.format(sender)  # sender is the nodename of the worker\n    instance.app.amqp.queues.select_add(queue_name)\n</code></pre> <p>提供的参数：</p> 参数 描述 <code>sender</code> Worker 的节点名称。 <code>instance</code> 这是要初始化的 <code>celery.apps.worker.Worker</code> 实例。请注意，到目前为止只设置了 <code>app</code> 和 <code>hostname</code>（节点名）属性，<code>__init__</code> 的其余部分尚未执行。 <code>conf</code> 当前应用的配置。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#celeryd_init","level":4,"title":"<code>celeryd_init</code>","text":"<p>这是 <code>celery worker</code> 启动时发送的第一个信号。<code>sender</code> 是 worker 的主机名，因此此信号可用于设置特定于 worker 的配置：</p> <pre><code>from celery.signals import celeryd_init\n\n@celeryd_init.connect(sender='worker12@example.com')\ndef configure_worker12(conf=None, **kwargs):\n    conf.task_default_rate_limit = '10/m'\n</code></pre> <p>或者要为多个 worker 设置配置，您可以在连接时省略指定 sender：</p> <pre><code>from celery.signals import celeryd_init\n\n@celeryd_init.connect\ndef configure_workers(sender=None, conf=None, **kwargs):\n    if sender in ('worker1@example.com', 'worker2@example.com'):\n        conf.task_default_rate_limit = '10/m'\n    if sender == 'worker3@example.com':\n        conf.worker_prefetch_multiplier = 0\n</code></pre> <p>提供的参数：</p> 参数 描述 <code>sender</code> Worker 的节点名称。 <code>instance</code> 这是要初始化的 <code>celery.apps.worker.Worker</code> 实例。请注意，到目前为止只设置了 <code>app</code> 和 <code>hostname</code>（节点名）属性，<code>__init__</code> 的其余部分尚未执行。 <code>conf</code> 当前应用的配置。 <code>options</code> 从命令行参数（包括默认值）传递给 worker 的选项。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker_init","level":4,"title":"<code>worker_init</code>","text":"<p>在 worker 启动之前分发。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker_before_create_process","level":4,"title":"<code>worker_before_create_process</code>","text":"<p>在父进程中分发，就在 prefork 池中创建新的子进程之前。它可以用于清理在 fork 时行为不佳的实例。</p> <pre><code>@signals.worker_before_create_process.connect\ndef clean_channels(**kwargs):\n    grpc_singleton.clean_channel()\n</code></pre>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker_ready","level":4,"title":"<code>worker_ready</code>","text":"<p>当 worker 准备好接受工作时分发。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#heartbeat_sent","level":4,"title":"<code>heartbeat_sent</code>","text":"<p>当 Celery 发送 worker 心跳时分发。</p> <p>发送者是 <code>celery.worker.heartbeat.Heart</code> 实例。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker_shutting_down","level":4,"title":"<code>worker_shutting_down</code>","text":"<p>当 worker 开始关闭过程时分发。</p> <p>提供的参数：</p> 参数 描述 <code>sig</code> 接收到的 POSIX 信号。 <code>how</code> 关闭方法，warm 或 cold。 <code>exitcode</code> 主进程退出时将使用的退出代码。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker_process_init","level":4,"title":"<code>worker_process_init</code>","text":"<p>在所有池子进程启动时分发。</p> <p>请注意，附加到此信号的处理程序阻塞时间不得超过 4 秒，否则进程将被杀死，假设启动失败。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker_process_shutdown","level":4,"title":"<code>worker_process_shutdown</code>","text":"<p>在所有池子进程退出之前分发。</p> <p>注意：不能保证此信号会被分发，类似于 <code>finally</code> 块，无法保证在关闭时会调用处理程序，如果被调用，可能会在过程中被中断。</p> <p>提供的参数：</p> 参数 描述 <code>pid</code> 即将关闭的子进程的 pid。 <code>exitcode</code> 子进程退出时将使用的退出代码。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#worker_shutdown","level":4,"title":"<code>worker_shutdown</code>","text":"<p>当 worker 即将关闭时分发。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#beat","level":3,"title":"Beat 信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#beat_init","level":4,"title":"<code>beat_init</code>","text":"<p>当 <code>celery beat</code> 启动时（独立运行或嵌入式）发送。</p> <p>发送者是 <code>celery.beat.Service</code> 实例。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#beat_embedded_init","level":4,"title":"<code>beat_embedded_init</code>","text":"<p>当 <code>celery beat</code> 作为嵌入式进程启动时，除了 <code>beat_init</code> 信号外还会发送此信号。</p> <p>发送者是 <code>celery.beat.Service</code> 实例。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#eventlet","level":3,"title":"Eventlet 信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#eventlet_pool_started","level":4,"title":"<code>eventlet_pool_started</code>","text":"<p>当 eventlet 池启动后发送。</p> <p>发送者是 <code>celery.concurrency.eventlet.TaskPool</code> 实例。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#eventlet_pool_preshutdown","level":4,"title":"<code>eventlet_pool_preshutdown</code>","text":"<p>在 worker 关闭时发送，就在 eventlet 池被要求等待剩余 worker 之前。</p> <p>发送者是 <code>celery.concurrency.eventlet.TaskPool</code> 实例。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#eventlet_pool_postshutdown","level":4,"title":"<code>eventlet_pool_postshutdown</code>","text":"<p>当池已加入且 worker 准备关闭时发送。</p> <p>发送者是 <code>celery.concurrency.eventlet.TaskPool</code> 实例。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#eventlet_pool_apply","level":4,"title":"<code>eventlet_pool_apply</code>","text":"<p>每当任务被应用到池时发送。</p> <p>发送者是 <code>celery.concurrency.eventlet.TaskPool</code> 实例。</p> 参数 描述 <code>target</code> 目标函数。 <code>args</code> 位置参数。 <code>kwargs</code> 关键字参数。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#_5","level":3,"title":"日志信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#setup_logging","level":4,"title":"<code>setup_logging</code>","text":"<p>如果连接了此信号，Celery 将不会配置日志记录器，因此您可以使用此信号完全用自己的日志配置覆盖默认配置。</p> <p>如果您想增强 Celery 设置的日志配置，可以使用 <code>after_setup_logger</code> 和 <code>after_setup_task_logger</code> 信号。</p> 参数 描述 <code>loglevel</code> 日志对象的级别。 <code>logfile</code> 日志文件的名称。 <code>format</code> 日志格式字符串。 <code>colorize</code> 指定日志消息是否着色。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#after_setup_logger","level":4,"title":"<code>after_setup_logger</code>","text":"<p>在每个全局日志记录器（非任务日志记录器）设置后发送。用于增强日志配置。</p> 参数 描述 <code>logger</code> 日志记录器对象。 <code>loglevel</code> 日志对象的级别。 <code>logfile</code> 日志文件的名称。 <code>format</code> 日志格式字符串。 <code>colorize</code> 指定日志消息是否着色。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#after_setup_task_logger","level":4,"title":"<code>after_setup_task_logger</code>","text":"<p>在每个单独的任务日志记录器设置后发送。用于增强日志配置。</p> 参数 描述 <code>logger</code> 日志记录器对象。 <code>loglevel</code> 日志对象的级别。 <code>logfile</code> 日志文件的名称。 <code>format</code> 日志格式字符串。 <code>colorize</code> 指定日志消息是否着色。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#_6","level":3,"title":"命令信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#user_preload_options","level":4,"title":"<code>user_preload_options</code>","text":"<p>此信号在任何 Celery 命令行程序完成解析用户预加载选项后发送。</p> <p>它可以用于向 <code>celery</code> 伞式命令添加额外的命令行参数：</p> <pre><code>from celery import Celery\nfrom celery import signals\nfrom celery.bin.base import Option\n\napp = Celery()\napp.user_options['preload'].add(Option(\n    '--monitoring', action='store_true',\n    help='Enable our external monitoring utility, blahblah',\n))\n\n@signals.user_preload_options.connect\ndef handle_preload_options(options, **kwargs):\n    if options['monitoring']:\n        enable_monitoring()\n</code></pre> <p>发送者是 <code>celery.bin.base.Command</code> 实例，其值取决于被调用的程序（例如，对于伞式命令，它将是 <code>celery.bin.celery.CeleryCommand</code>) 对象）。</p> <p>提供参数：</p> 参数 描述 <code>app</code> 应用实例。 <code>options</code> 已解析的用户预加载选项的映射（包含默认值）。","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#_7","level":3,"title":"已弃用信号","text":"","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/signals/#task_sent","level":4,"title":"<code>task_sent</code>","text":"<p>此信号已弃用，请改用 <code>after_task_publish</code>。</p>","path":["用户指南","信号"],"tags":[]},{"location":"user-guide/tasks/","level":1,"title":"任务","text":"<p>任务是 Celery 应用程序的构建块。</p> <p>任务是一个可以从任何可调用对象创建的类。它扮演双重角色，既定义了任务被调用时会发生什么（发送消息），也定义了工作进程接收到该消息时会发生什么。</p> <p>每个任务类都有一个唯一的名称，这个名称在消息中被引用，以便工作进程可以找到正确的函数来执行。</p> <p>任务消息在被工作进程 <code>确认</code> 之前不会从队列中移除。工作进程可以提前保留许多消息，即使工作进程被杀死——由于电源故障或其他原因——消息也会被重新传递给另一个工作进程。</p> <p>理想情况下，任务函数应该是 <code>幂等</code> 的：意味着即使使用相同的参数多次调用该函数，也不会导致意外的副作用。由于工作进程无法检测您的任务是否幂等，默认行为是在执行之前提前确认消息，这样已经启动的任务调用永远不会再次执行。</p> <p>如果您的任务是幂等的，您可以设置 <code>acks_late</code> 选项，让工作进程在任务返回 之后 确认消息。另请参阅常见问题解答条目 我应该使用 retry 还是 acks_late？。</p> <p>请注意，即使启用了 <code>acks_late</code>，如果执行任务的子进程被终止（无论是由于任务调用 <code>sys.exit()</code> 还是信号），工作进程也会确认消息。这种行为是有意为之的，因为...</p> <ol> <li>我们不想重新运行那些迫使内核向进程发送 <code>SIGSEGV</code>（段错误）或类似信号的任务。</li> <li>我们假设系统管理员故意杀死任务时，不希望它自动重启。</li> <li>分配过多内存的任务有触发内核 OOM killer 的危险，同样的情况可能会再次发生。</li> <li>重新传递时总是失败的任务可能会导致高频消息循环，从而拖垮系统。</li> </ol> <p>如果您确实希望在这些情况下重新传递任务，您应该考虑启用 <code>task_reject_on_worker_lost</code> 设置。</p> <p>Warning</p> <p>无限期阻塞的任务最终可能会阻止工作进程实例执行任何其他工作。</p> <p>如果您的任务执行 I/O 操作，请确保为这些操作添加超时，例如使用 <code>requests</code> 库为 Web 请求添加超时：</p> <pre><code>connect_timeout, read_timeout = 5.0, 30.0\nresponse = requests.get(URL, timeout=(connect_timeout, read_timeout))\n</code></pre> <p>工作进程指南 - 时间限制 对于确保所有任务及时返回很方便，但时间限制事件实际上会强制杀死进程，因此仅在没有使用手动超时的情况下使用它们来检测问题。</p> <p>在以前的版本中，默认的 prefork 池调度器对长时间运行的任务不友好，因此如果您有运行几分钟/小时的任务，建议启用 <code>-Ofair &lt;celery worker -O&gt;</code> 命令行参数给 <code>celery worker</code>。然而，从版本 4.0 开始，-Ofair 现在是默认的调度策略。有关更多信息，请参阅 优化指南 - 预取限制，为了获得最佳性能，请将长时间运行和短时间运行的任务路由到专用工作进程 路由指南 - 自动路由。</p> <p>如果您的 worker 挂起，请在提交问题之前调查正在运行的任务，因为挂起很可能是由于一个或多个任务在网络操作上挂起引起的。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_2","level":2,"title":"基础","text":"<p>您可以通过使用 <code>task()</code> 装饰器轻松地从任何可调用对象创建任务：</p> <pre><code>from .models import User\n\n@app.task\ndef create_user(username, password):\n    User.objects.create(username=username, password=password)\n</code></pre> <p>还有许多 选项 可以为任务设置，这些可以作为装饰器的参数指定：</p> <pre><code>@app.task(serializer='json')\ndef create_user(username, password):\n    User.objects.create(username=username, password=password)\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_3","level":3,"title":"如何导入任务装饰器？","text":"<p>任务装饰器可在您的 <code>Celery()</code> 应用程序实例上使用，如果您不知道这是什么，请阅读 快速上手。</p> <p>如果您正在使用 Django（参见 与 Django 一起使用），或者您是库的作者，那么您可能想要使用 <code>shared_task()</code> 装饰器：</p> <pre><code>from celery import shared_task\n\n@shared_task\ndef add(x, y):\n    return x + y\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_4","level":3,"title":"多个装饰器","text":"<p>当将多个装饰器与任务装饰器结合使用时，您必须确保 <code>task</code> 装饰器最后应用（奇怪的是，在 Python 中这意味着它必须在列表的最前面）：</p> <pre><code>@app.task\n@decorator2\n@decorator1\ndef add(x, y):\n    return x + y\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_5","level":3,"title":"绑定任务","text":"<p>任务被绑定意味着任务的第一个参数将始终是任务实例（<code>self</code>），就像 Python 的绑定方法一样：</p> <pre><code>logger = get_task_logger(__name__)\n\n@app.task(bind=True)\ndef add(self, x, y):\n    logger.info(self.request.id)\n</code></pre> <p>绑定任务对于重试（使用 <code>Task.retry()</code>）、访问当前任务请求的信息以及您添加到自定义任务基类的任何附加功能都是必需的。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_6","level":3,"title":"任务继承","text":"<p>任务装饰器的 <code>base</code> 参数指定任务的基类：</p> <pre><code>import celery\n\nclass MyTask(celery.Task):\n\n    def on_failure(self, exc, task_id, args, kwargs, einfo):\n        print('{0!r} failed: {1!r}'.format(task_id, exc))\n\n@app.task(base=MyTask)\ndef add(x, y):\n    raise KeyError()\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#task-names","level":2,"title":"名称","text":"<p>每个任务都必须具有唯一的名称。</p> <p>如果没有提供明确的名称，任务装饰器将为您生成一个名称，该名称将基于：任务定义所在的模块，以及任务函数的名称。</p> <p>设置明确名称的示例：</p> <pre><code>&gt;&gt;&gt; @app.task(name='sum-of-two-numbers')\n&gt;&gt;&gt; def add(x, y):\n...     return x + y\n\n&gt;&gt;&gt; add.name\n'sum-of-two-numbers'\n</code></pre> <p>最佳实践是使用模块名称作为命名空间，这样如果另一个模块中已经定义了同名任务，名称就不会冲突。</p> <pre><code>&gt;&gt;&gt; @app.task(name='tasks.add')\n&gt;&gt;&gt; def add(x, y):\n...     return x + y\n</code></pre> <p>您可以通过检查任务的 <code>.name</code> 属性来了解任务的名称：</p> <pre><code>&gt;&gt;&gt; add.name\n'tasks.add'\n</code></pre> <p>我们在此指定的名称（<code>tasks.add</code>）与如果任务在名为 <code>tasks.py</code> 的模块中定义时自动生成的名称完全相同：</p> tasks.py<pre><code>@app.task\ndef add(x, y):\n    return x + y\n</code></pre> <pre><code>&gt;&gt;&gt; from tasks import add\n&gt;&gt;&gt; add.name\n'tasks.add'\n</code></pre> <p>Note</p> <p>您可以在 worker 中使用 <code>inspect</code> 命令查看所有已注册任务的名称。请参阅用户指南的 监控指南 部分中的 <code>inspect registered</code> 命令。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_7","level":3,"title":"更改自动命名行为","text":"<p>在某些情况下，默认的自动命名并不合适。考虑在许多不同模块中有许多任务的情况：</p> <pre><code>project\n├── __init__.py\n├── celery.py\n├── moduleA\n│   ├── __init__.py\n│   └── tasks.py\n└── moduleB\n    ├── __init__.py\n    └── tasks.py\n</code></pre> <p>使用默认的自动命名，每个任务将具有类似 <code>moduleA.tasks.taskA</code>、<code>moduleA.tasks.taskB</code>、<code>moduleB.tasks.test</code> 等的生成名称。您可能希望在所有任务名称中去掉 <code>tasks</code>。如上所述，您可以为所有任务明确指定名称，或者可以通过重写 <code>gen_task_name()</code> 来更改自动命名行为。继续上面的示例，<code>celery.py</code> 可能包含：</p> <pre><code>from celery import Celery\n\nclass MyCelery(Celery):\n\n    def gen_task_name(self, name, module):\n        if module.endswith('.tasks'):\n            module = module[:-6]\n        return super().gen_task_name(name, module)\n\napp = MyCelery('main')\n</code></pre> <p>这样每个任务将具有类似 <code>moduleA.taskA</code>、<code>moduleA.taskB</code> 和 <code>moduleB.test</code> 的名称。</p> <p>Warning</p> <p>请确保您的 <code>gen_task_name()</code> 是一个纯函数：意味着对于相同的输入，它必须始终返回相同的输出。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_8","level":2,"title":"请求","text":"<p><code>Task.request()</code> 包含与当前正在执行的任务相关的信息和状态。</p> <p>请求定义了以下属性：</p> 属性 描述 id 执行任务的唯一ID。 group 任务的 画布指南 的唯一ID（如果此任务是成员）。 chord 此任务所属的chord的唯一ID（如果任务是header的一部分）。 correlation_id 用于去重等用途的自定义ID。 args 位置参数。 kwargs 关键字参数。 origin 发送此任务的主机名。 retries 当前任务已重试的次数。从 <code>0</code> 开始的整数。 is_eager 如果任务在客户端本地执行而不是由工作进程执行，则设置为 <code>True</code>。 eta 任务的原始ETA（如果有）。这是UTC时间（取决于 <code>enable_utc</code> 设置）。 expires 任务的原始过期时间（如果有）。这是UTC时间（取决于 <code>enable_utc</code> 设置）。 hostname 执行任务的工作进程实例的节点名称。 delivery_info 额外的消息传递信息。这是一个包含用于传递此任务的交换机和路由键的映射。例如 <code>Task.retry()</code> 使用它来将任务重新发送到相同的目标队列。此字典中键的可用性取决于所使用的消息代理。 reply_to 用于发送回复的队列名称（例如，与RPC结果后端一起使用）。 called_directly 如果任务不是由工作进程执行的，则此标志设置为true。 timelimit 当前对此任务生效的 <code>(soft, hard)</code> 时间限制元组（如果有）。 callbacks 如果此任务成功返回，则要调用的签名列表。 errbacks 如果此任务失败，则要调用的签名列表。 utc 如果调用者启用了UTC，则设置为true（<code>enable_utc</code>）。 headers 与此任务消息一起发送的消息头映射（可能为 <code>None</code>）。 reply_to 发送回复的位置（队列名称）。 correlation_id 通常与任务ID相同，通常在amqp中用于跟踪回复的用途。 root_id 此任务所属工作流中第一个任务的唯一ID（如果有）。 parent_id 调用此任务的任务的唯一ID（如果有）。 chain 形成链的任务的反向列表（如果有）。此列表中的最后一项将是当前任务之后的下一个任务。如果使用任务协议的版本一，链任务将在 <code>request.callbacks</code> 中。 properties 与此任务消息一起接收的消息属性映射（可能为 <code>None</code> 或 <code>{}</code>） replaced_task_nesting 任务被替换的次数（如果有的话）（可能为 <code>0</code>）","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_9","level":3,"title":"示例","text":"<p>一个访问上下文中信息的示例任务是：</p> <pre><code>@app.task(bind=True)\ndef dump_context(self, x, y):\n    print('Executing task id {0.id}, args: {0.args!r} kwargs: {0.kwargs!r}'.format(\n            self.request))\n</code></pre> <p><code>bind</code> 参数意味着该函数将是一个\"绑定方法\"，因此您可以访问任务类型实例上的属性和方法。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_10","level":2,"title":"日志记录","text":"<p>工作器会自动为您设置日志记录，或者您可以手动配置日志记录。</p> <p>有一个特殊的日志记录器名为 \"celery.task\"，您可以继承此日志记录器以自动将任务名称和唯一ID作为日志的一部分。</p> <p>最佳实践是在模块顶部为所有任务创建一个公共的日志记录器：</p> <pre><code>from celery.utils.log import get_task_logger\n\nlogger = get_task_logger(__name__)\n\n@app.task\ndef add(x, y):\n    logger.info('Adding {0} + {1}'.format(x, y))\n    return x + y\n</code></pre> <p>Celery 使用标准的 Python 日志记录器库，文档可以在 <code>logging</code> 找到。</p> <p>您也可以使用 <code>print()</code>，因为写入标准输出/错误输出的任何内容都将重定向到日志记录系统（您可以禁用此功能，请参阅 <code>worker_redirect_stdouts</code>）。</p> <p>Note</p> <p>如果您在任务或任务模块中的某个地方创建了日志记录器实例，工作器不会更新重定向。</p> <p>如果您想将 <code>sys.stdout</code> 和 <code>sys.stderr</code> 重定向到自定义日志记录器，您必须手动启用此功能，例如：</p> <pre><code>import sys\n\nlogger = get_task_logger(__name__)\n\n@app.task(bind=True)\ndef add(self, x, y):\n    old_outs = sys.stdout, sys.stderr\n    rlevel = self.app.conf.worker_redirect_stdouts_level\n    try:\n        self.app.log.redirect_stdouts_to_logger(logger, rlevel)\n        print('Adding {0} + {1}'.format(x, y))\n        return x + y\n    finally:\n        sys.stdout, sys.stderr = old_outs\n</code></pre> <p>Note</p> <p>如果您需要的特定 Celery 日志记录器没有发出日志，您应该检查日志记录器是否正确传播。在此示例中，启用了 \"celery.app.trace\" 以便发出 \"succeeded in\" 日志：</p> <pre><code>import celery\nimport logging\n\n@celery.signals.after_setup_logger.connect\ndef on_after_setup_logger(**kwargs):\n    logger = logging.getLogger('celery')\n    logger.propagate = True\n    logger = logging.getLogger('celery.app.trace')\n    logger.propagate = True\n</code></pre> <p>Note</p> <p>如果您想完全禁用 Celery 日志记录配置，请使用 <code>setup_logging</code> 信号：</p> <pre><code>import celery\n\n@celery.signals.setup_logging.connect\ndef on_setup_logging(**kwargs):\n    pass\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_11","level":3,"title":"参数检查","text":"<p>Celery 会在您调用任务时验证传递的参数，就像 Python 在调用普通函数时一样：</p> <pre><code>&gt;&gt;&gt; @app.task\n... def add(x, y):\n...     return x + y\n\n# 使用两个参数调用任务可以正常工作：\n&gt;&gt;&gt; add.delay(8, 8)\n&lt;AsyncResult: f59d71ca-1549-43e0-be41-4e8821a83c0c&gt;\n\n# 只使用一个参数调用任务会失败：\n&gt;&gt;&gt; add.delay(8)\nTraceback (most recent call last):\n  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;\n  File \"celery/app/task.py\", line 376, in delay\n    return self.apply_async(args, kwargs)\n  File \"celery/app/task.py\", line 485, in apply_async\n    check_arguments(*(args or ()), **(kwargs or {}))\nTypeError: add() takes exactly 2 arguments (1 given)\n</code></pre> <p>您可以通过将任务的 <code>typing</code> 属性设置为 <code>False</code> 来禁用任何任务的参数检查：</p> <pre><code>&gt;&gt;&gt; @app.task(typing=False)\n... def add(x, y):\n...     return x + y\n\n# 在本地工作，但接收任务的工作器会引发错误。\n&gt;&gt;&gt; add.delay(8)\n&lt;AsyncResult: f59d71ca-1549-43e0-be41-4e8821a83c0c&gt;\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_12","level":3,"title":"隐藏参数中的敏感信息","text":"<p>当使用 <code>task_protocol</code> 2 或更高版本（自 4.0 起默认）时，您可以使用 <code>argsrepr</code> 和 <code>kwargsrepr</code> 调用参数来覆盖位置参数和关键字参数在日志和监控事件中的表示方式：</p> <pre><code>&gt;&gt;&gt; add.apply_async((2, 3), argsrepr='(&lt;secret-x&gt;, &lt;secret-y&gt;)')\n\n&gt;&gt;&gt; charge.s(account, card='1234 5678 1234 5678').set(\n...     kwargsrepr=repr({'card': '**** **** **** 5678'})\n... ).delay()\n</code></pre> <p>Warning</p> <p>敏感信息仍然可以被任何能够从代理读取任务消息或以其他方式拦截它的人访问。</p> <p>因此，如果您的消息包含敏感信息，您可能应该加密您的消息，或者在此示例中，信用卡的实际号码可以加密存储在安全存储中，您在任务中检索并解密。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_13","level":2,"title":"重试","text":"<p><code>retry()</code> 可用于重新执行任务，例如在发生可恢复错误时。</p> <p>当您调用 <code>retry()</code> 时，它将使用相同的任务ID发送新消息，并确保消息传递到与原始任务相同的队列。</p> <p>当任务被重试时，这也会被记录为任务状态，以便您可以使用结果实例跟踪任务的进度（参见 任务状态）。</p> <p>以下是使用 <code>retry()</code> 的示例：</p> <pre><code>@app.task(bind=True)\ndef send_twitter_status(self, oauth, tweet):\n    try:\n        twitter = Twitter(oauth)\n        twitter.update_status(tweet)\n    except (Twitter.FailWhaleError, Twitter.LoginError) as exc:\n        raise self.retry(exc=exc)\n</code></pre> <p>Note</p> <p><code>retry()</code> 调用将引发异常，因此重试之后的任何代码都不会被执行。这是 <code>Retry</code> 异常，它不被视为错误，而是作为半谓词向工作进程表示任务将被重试，以便在启用结果后端时可以存储正确的状态。</p> <p>这是正常操作，除非重试的 <code>throw</code> 参数设置为 <code>False</code>，否则总是会发生。</p> <p>任务的装饰器中的 bind 参数将提供对 <code>self</code>（任务类型实例）的访问。</p> <p><code>exc</code> 参数用于传递异常信息，这些信息在日志记录和存储任务结果时使用。异常和回溯都将在任务状态中可用（如果启用了结果后端）。</p> <p>如果任务有 <code>max_retries</code> 值，当超过最大重试次数时，当前异常将被重新抛出，但以下情况不会发生：</p> <ul> <li> <p>未提供 <code>exc</code> 参数</p> <p>在这种情况下，将引发 <code>MaxRetriesExceededError</code> 异常。</p> </li> <li> <p>没有当前异常</p> <p>如果没有原始异常可以重新抛出，则将使用 <code>exc</code> 参数，因此：</p> <pre><code>self.retry(exc=Twitter.LoginError())\n</code></pre> <p>将引发给定的 <code>exc</code> 参数。</p> </li> </ul>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_14","level":3,"title":"使用自定义重试延迟","text":"<p>当任务需要重试时，它可以在重试前等待指定的时间，默认延迟由 <code>default_retry_delay</code> 属性定义。默认设置为 3 分钟。请注意，设置延迟的单位是秒（整数或浮点数）。</p> <p>您还可以提供 <code>countdown</code> 参数给 <code>retry()</code> 来覆盖此默认值。</p> <pre><code>@app.task(bind=True, default_retry_delay=30 * 60)  # 30分钟后重试\ndef add(self, x, y):\n    try:\n        something_raising()\n    except Exception as exc:\n        # 覆盖默认延迟，在1分钟后重试\n        raise self.retry(exc=exc, countdown=60)\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_15","level":3,"title":"对已知异常进行自动重试","text":"<p>有时，您只想在引发特定异常时重试任务。</p> <p>幸运的是，您可以通过在 <code>task()</code> 装饰器中使用 <code>autoretry_for</code> 参数来告诉 Celery 自动重试任务：</p> <pre><code>from twitter.exceptions import FailWhaleError\n\n@app.task(autoretry_for=(FailWhaleError,))\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user)\n</code></pre> <p>如果您想为内部的 <code>retry()</code> 调用指定自定义参数，请将 <code>retry_kwargs</code> 参数传递给 <code>task()</code> 装饰器：</p> <pre><code>@app.task(autoretry_for=(FailWhaleError,), retry_kwargs={'max_retries': 5})\ndef refresh_timeline(user):\n    return twitter.refresh_timeline(user)\n</code></pre> <p>这提供了手动处理异常的替代方案，上面的示例与将任务体包装在 <code>try</code> ... <code>except</code> 语句中的效果相同：</p> <pre><code>@app.task\ndef refresh_timeline(user):\n    try:\n        twitter.refresh_timeline(user)\n    except FailWhaleError as exc:\n        raise refresh_timeline.retry(exc=exc, max_retries=5)\n</code></pre> <p>如果您想对任何错误都自动重试，只需使用：</p> <pre><code>@app.task(autoretry_for=(Exception,))\ndef x():\n    ...\n</code></pre> <p>如果您的任务依赖于另一个服务，比如向API发出请求，那么使用指数退避是一个好主意，以避免用您的请求淹没该服务。幸运的是，Celery的自动重试支持使这变得容易。只需指定 <code>retry_backoff</code> 参数，如下所示：</p> <pre><code>from requests.exceptions import RequestException\n\n@app.task(autoretry_for=(RequestException,), retry_backoff=True)\ndef x():\n    ...\n</code></pre> <p>默认情况下，这种指数退避还会引入随机抖动，以避免所有任务在同一时刻运行。它还会将最大退避延迟限制为10分钟。所有这些设置都可以通过下面记录的选项进行自定义。</p> <p>您还可以在基于类的任务中设置 <code>autoretry_for</code>、<code>max_retries</code>、<code>retry_backoff</code>、<code>retry_backoff_max</code> 和 <code>retry_jitter</code> 选项：</p> <pre><code>class BaseTaskWithRetry(Task):\n    autoretry_for = (TypeError,)\n    max_retries = 5\n    retry_backoff = True\n    retry_backoff_max = 700\n    retry_jitter = False\n</code></pre> 属性 描述 autoretry_for  异常类的列表/元组。如果在任务执行期间引发这些异常中的任何一个，任务将自动重试。 默认情况下，不会自动重试任何异常。  max_retries  一个数字。放弃前的最大重试次数。值为 <code>None</code> 表示任务将永远重试。 默认情况下，此选项设置为 <code>3</code>。  retry_backoff  布尔值或数字。如果此选项设置为 <code>True</code>，自动重试将按照 指数退避 的规则延迟。第一次重试将延迟1秒， 第二次重试将延迟2秒，第三次延迟4秒，第四次延迟8秒，依此类推。 （但是，如果启用了 <code>retry_jitter</code>，此延迟值会被修改。） 如果此选项设置为数字，则用作延迟因子。例如，如果此选项设置为 <code>3</code>， 第一次重试将延迟3秒，第二次延迟6秒，第三次延迟12秒，第四次延迟24秒，依此类推。 默认情况下，此选项设置为 <code>False</code>，自动重试不会延迟。  retry_backoff_max  一个数字。如果启用了 <code>retry_backoff</code>，此选项将设置任务自动重试之间的 最大延迟（以秒为单位）。默认情况下，此选项设置为 <code>600</code>，即10分钟。  retry_jitter  布尔值。抖动用于在指数退避延迟中引入随机性，以防止队列中的所有任务 同时执行。如果此选项设置为 <code>True</code>，由 <code>retry_backoff</code> 计算的延迟值被视为最大值，实际延迟值将是零到该最大值之间的随机数。 默认情况下，此选项设置为 <code>True</code>。  dont_autoretry_for  异常类的列表/元组。这些异常不会被自动重试。 这允许排除一些匹配 <code>autoretry_for</code> 但您不希望重试的异常。","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#pydantic","level":2,"title":"使用 Pydantic 进行参数验证","text":"<p>您可以通过传递 <code>pydantic=True</code> 来使用 Pydantic 验证和转换参数，以及基于类型提示序列化结果。</p> <p>Note</p> <p>参数验证仅涵盖任务端的参数/返回值。在使用 <code>delay()</code> 或 <code>apply_async()</code> 调用任务时，您仍然需要自己序列化参数。</p> <p>例如：</p> <pre><code>from pydantic import BaseModel\n\nclass ArgModel(BaseModel):\n    value: int\n\nclass ReturnModel(BaseModel):\n    value: str\n\n@app.task(pydantic=True)\ndef x(arg: ArgModel) -&gt; ReturnModel:\n    # 类型提示为 Pydantic 模型的 args/kwargs 将被转换\n    assert isinstance(arg, ArgModel)\n\n    # 返回的模型将自动转换为字典\n    return ReturnModel(value=f\"example: {arg.value}\")\n</code></pre> <p>然后可以使用与模型匹配的字典调用任务，您将收到返回的模型\"转储\"（使用 <code>BaseModel.model_dump()</code> 序列化）：</p> <pre><code>&gt;&gt;&gt; result = x.delay({'value': 1})\n&gt;&gt;&gt; result.get(timeout=1)\n{'value': 'example: 1'}\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_16","level":3,"title":"联合类型，泛型参数","text":"<p>联合类型（例如 <code>Union[SomeModel, OtherModel]</code>）或泛型参数（例如 <code>list[SomeModel]</code>）不受支持。</p> <p>如果您想要支持列表或类似类型，建议使用 <code>pydantic.RootModel</code>。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_17","level":3,"title":"可选参数/返回值","text":"<p>可选参数或返回值也会得到正确处理。例如，给定以下任务：</p> <pre><code>from typing import Optional\n\n# 模型与上面相同\n\n@app.task(pydantic=True)\ndef x(arg: Optional[ArgModel] = None) -&gt; Optional[ReturnModel]:\n    if arg is None:\n        return None\n    return ReturnModel(value=f\"example: {arg.value}\")\n</code></pre> <p>您将得到以下行为：</p> <pre><code>&gt;&gt;&gt; result = x.delay()\n&gt;&gt;&gt; result.get(timeout=1) is None\nTrue\n&gt;&gt;&gt; result = x.delay({'value': 1})\n&gt;&gt;&gt; result.get(timeout=1)\n{'value': 'example: 1'}\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_18","level":3,"title":"返回值处理","text":"<p>只有当返回的模型与注解匹配时，返回值才会被序列化。如果您传递不同类型的模型实例，它将不会被序列化。<code>mypy</code> 应该已经捕获此类错误，您应该修复类型提示。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#pydantic_1","level":3,"title":"Pydantic 参数","text":"<p>还有几个影响 Pydantic 行为的选项：</p> 属性 描述 pydantic_strict  默认情况下，严格模式 是禁用的。您可以传递 <code>True</code> 来启用严格模型验证。  pydantic_context  在 Pydantic 模型验证期间传递额外的验证上下文。 默认情况下，上下文已经包含应用程序对象作为 <code>celery_app</code> 和任务名称作为 <code>celery_task_name</code>。  pydantic_dump_kwargs  在序列化结果时，将这些附加参数传递给 <code>dump_kwargs()</code>。 默认情况下，只传递 <code>mode='json'</code>。","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#task-options","level":2,"title":"选项列表","text":"<p>任务装饰器可以接受许多选项来改变任务的行为方式，例如您可以使用 <code>rate_limit</code> 选项设置任务的速率限制。</p> <p>传递给任务装饰器的任何关键字参数实际上都将设置为结果任务类的属性，这是内置属性的列表。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_19","level":3,"title":"通用选项","text":"属性 描述 name 任务注册的名称。您可以手动设置此名称，或者将使用模块和类名自动生成一个名称。 request 如果任务正在执行，这将包含有关当前请求的信息。使用线程本地存储。 max_retries  仅当任务调用 <code>self.retry</code> 或任务使用 <code>autoretry_for</code> 参数装饰时适用。 放弃前尝试重试的最大次数。 如果重试次数超过此值，将引发 <code>MaxRetriesExceededError</code> 异常。 默认值为 <code>3</code>。值为 <code>None</code> 将禁用重试限制，任务将无限重试直到成功。  throws  可选的预期错误类元组，这些错误不应被视为实际错误。 此列表中的错误将被报告为结果后端的失败，但工作进程不会将该事件记录为错误，并且不会包含回溯信息。 示例：  <pre><code>@task(throws=(KeyError, HttpNotFound)):\ndef get_foo():\n    something()\n</code></pre>  错误类型：  - 预期错误（在 `Task.throws` 中）：以 `INFO` 严重性记录，排除回溯信息。 - 意外错误：以 `ERROR` 严重性记录，包含回溯信息。  default_retry_delay 任务重试前默认等待时间（以秒为单位）。可以是 <code>int</code> 或 <code>float</code>。默认是三分钟的延迟。 rate_limit  设置此任务类型的速率限制（限制在给定时间范围内可以运行的任务数量）。当速率限制生效时，任务仍将完成，但可能需要一些时间才能允许开始。 如果为 <code>None</code>，则没有速率限制生效。如果是整数或浮点数，则解释为\"每秒任务数\"。 可以通过在值后附加 <code>\"/s\"</code>、<code>\"/m\"</code> 或 <code>\"/h\"</code> 来指定秒、分钟或小时的速率限制。任务将在指定的时间范围内均匀分布。 示例：<code>\"100/m\"</code>（每分钟一百个任务）。这将强制在同一工作实例上启动两个任务之间至少有600毫秒的延迟。 默认是 <code>task_default_rate_limit</code> 设置：如果未指定，意味着默认情况下任务速率限制被禁用。 请注意，这是*每个工作实例*的速率限制，而不是全局速率限制。要强制执行全局速率限制（例如，对于具有每秒最大请求数的API），您必须限制到特定队列。  time_limit 此任务的硬时间限制（以秒为单位）。未设置时使用工作进程的默认值。 soft_time_limit 此任务的软时间限制。未设置时使用工作进程的默认值。 ignore_result  不存储任务状态。请注意，这意味着您不能使用 <code>AsyncResult</code> 来检查任务是否准备就绪或获取其返回值。 注意：如果禁用任务结果，某些功能将无法工作。有关更多详细信息，请查看 Canvas 文档。  store_errors_even_if_ignored 如果为 <code>True</code>，即使任务配置为忽略结果，错误也将被存储。 serializer  标识要使用的默认序列化方法的字符串。默认为 <code>task_serializer</code> 设置。可以是 <code>pickle</code>、<code>json</code>、<code>yaml</code>，或任何已在 <code>kombu.serialization.registry</code> 中注册的自定义序列化方法。 请参阅 调用指南 - 序列化器 获取更多信息。  compression  标识要使用的默认压缩方案的字符串。 默认为 <code>task_compression</code> 设置。可以是 <code>gzip</code>、<code>bzip2</code>，或任何已在 <code>kombu.compression</code> 注册表中注册的自定义压缩方案。 请参阅 调用指南 - 压缩 获取更多信息。  backend 用于此任务的结果存储后端。<code>celery.backends</code> 中后端类之一的实例。默认为 <code>app.backend</code>，由 <code>result_backend</code> 设置定义。 acks_late  如果设置为 <code>True</code>，此任务的消息将在任务执行**后**确认，而不是*刚好在执行前*（默认行为）。 注意：这意味着如果工作进程在执行过程中崩溃，任务可能会被执行多次。请确保您的任务是 幂等的。 全局默认值可以通过 <code>task_acks_late</code> 设置覆盖。  track_started  如果为 <code>True</code>，当任务由工作进程执行时，任务将报告其状态为 \"started\"。默认值为 <code>False</code>， 因为正常行为是不报告该粒度级别。任务要么是挂起、完成，要么是等待重试。拥有\"started\"状态对于长时间运行的任务很有用，需要报告当前正在运行的任务。 执行任务的工作进程的主机名和进程ID将在状态元数据中可用（例如，`result.info['pid']`） 全局默认值可以通过 `task_track_started` 设置覆盖。","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#task-states","level":2,"title":"状态","text":"<p>Celery 可以跟踪任务的当前状态。状态还包含成功任务的结果，或失败任务的异常和回溯信息。</p> <p>有多个结果后端可供选择，它们都有不同的优势和劣势。</p> <p>在任务的生命周期中，它会经历多个可能的状态，每个状态都可能附加任意的元数据。当任务进入新状态时，之前的状态会被遗忘，但某些转换可以被推断出来（例如，现在处于 <code>FAILED</code> 状态的任务，意味着它曾经处于 <code>STARTED</code> 状态）。</p> <p>还有状态集合，如 <code>FAILURE_STATES</code> 集合和 <code>READY_STATES</code> 集合。</p> <p>客户端使用这些集合的成员关系来决定是否应重新引发异常（<code>PROPAGATE_STATES</code>），或者状态是否可以缓存（如果任务准备就绪，则可以缓存）。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_20","level":3,"title":"结果后端","text":"<p>如果您想跟踪任务或需要返回值，那么 Celery 必须将状态存储或发送到某个地方，以便以后可以检索。有多个内置的结果后端可供选择：SQLAlchemy/Django ORM、Memcached、RabbitMQ/QPid（<code>rpc</code>）和 Redis——或者您可以定义自己的后端。</p> <p>没有哪个后端适用于所有用例。您应该阅读每个后端的优势和劣势，并选择最适合您需求的后端。</p> <p>Warning</p> <p>后端使用资源来存储和传输结果。为确保 资源被释放，您必须最终调用 <code>get()</code> 或 <code>forget()</code> 在 调用任务后返回的每个 <code>AsyncResult</code> 实例上。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#rpc-rabbitmqqpid","level":4,"title":"RPC 结果后端 (RabbitMQ/QPid)","text":"<p>RPC 结果后端（<code>rpc://</code>）很特殊，因为它实际上并不存储状态，而是将它们作为消息发送。这是一个重要的区别，意味着结果只能被检索一次，并且只能由发起任务的客户端检索。两个不同的进程不能等待同一个结果。</p> <p>即使有这种限制，如果您需要实时接收状态更改，它也是一个绝佳的选择。使用消息传递意味着客户端不必轮询新状态。</p> <p>默认情况下，消息是瞬态的（非持久的），因此如果代理重启，结果将消失。您可以使用 <code>result_persistent</code> 设置来配置结果后端发送持久消息。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_21","level":4,"title":"数据库结果后端","text":"<p>将状态保存在数据库中可能对许多人很方便，特别是对于已经拥有数据库的 Web 应用程序，但它也有局限性。</p> <ul> <li> <p>轮询数据库以获取新状态是昂贵的，因此您应该增加操作的轮询间隔，例如 <code>result.get()</code>。</p> </li> <li> <p>某些数据库使用的默认事务隔离级别不适合轮询表的更改。</p> <p>在 MySQL 中，默认事务隔离级别是 <code>REPEATABLE-READ</code>：意味着事务在提交之前不会看到其他事务所做的更改。</p> <p>建议将其更改为 <code>READ-COMMITTED</code> 隔离级别。</p> </li> </ul>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#task-states","level":3,"title":"内置状态","text":"","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#pending","level":4,"title":"PENDING","text":"<p>任务正在等待执行或未知。任何未知的任务 ID 都被视为处于挂起状态。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#started","level":4,"title":"STARTED","text":"<p>任务已启动。默认情况下不报告，要启用请参见 <code>track_started</code>。</p> 标签 描述 meta-data 执行任务的 worker 进程的 <code>pid</code> 和 <code>hostname</code>。","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#success","level":4,"title":"SUCCESS","text":"<p>任务已成功执行。</p> 标签 描述 meta-data <code>result</code> 包含任务的返回值。 propagates 是 ready 是","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#failure","level":4,"title":"FAILURE","text":"<p>任务执行失败。</p> 标签 描述 meta-data <code>result</code> 包含发生的异常，<code>traceback</code> 包含引发异常时堆栈的回溯信息。 propagates 是 ready 是","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#retry","level":4,"title":"RETRY","text":"标签 描述 meta-data <code>result</code> 包含导致重试的异常，<code>traceback</code> 包含引发异常时堆栈的回溯信息。 propagates 否","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#revoked","level":4,"title":"REVOKED","text":"<p>任务已被撤销。</p> 标签 描述 propagates 是","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_22","level":3,"title":"自定义状态","text":"<p>您可以轻松定义自己的状态，只需要一个唯一的名称。状态的名称通常是一个大写字符串。例如，您可以查看 <code>celery.contrib.abortable</code> 它定义了一个自定义的 <code>ABORTED</code> 状态。</p> <p>使用 <code>update_state()</code> 来更新任务的状态：</p> <pre><code>@app.task(bind=True)\ndef upload_files(self, filenames):\n    for i, file in enumerate(filenames):\n        if not self.request.called_directly:\n            self.update_state(state='PROGRESS',\n                meta={'current': i, 'total': len(filenames)})\n</code></pre> <p>这里我创建了状态 <code>\"PROGRESS\"</code>，告诉任何了解此状态的应用程序该任务当前正在进行中，并且通过 <code>current</code> 和 <code>total</code> 计数作为状态元数据的一部分，还可以知道它在进程中的位置。这可以用于创建进度条等。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_23","level":3,"title":"创建可序列化的异常","text":"<p>一个鲜为人知的 Python 事实是，异常必须符合一些简单的规则才能支持被 pickle 模块序列化。</p> <p>当使用 Pickle 作为序列化器时，引发不可序列化异常的任务将无法正常工作。</p> <p>为确保您的异常可序列化，异常必须在其 <code>.args</code> 属性中提供它被实例化时使用的原始参数。确保这一点的最简单方法是让异常调用 <code>Exception.__init__</code>。</p> <p>让我们看一些有效的例子，以及一个无效的例子：</p> <pre><code># 正确：\nclass HttpError(Exception):\n    pass\n\n# 错误：\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n\n# 正确：\nclass HttpError(Exception):\n\n    def __init__(self, status_code):\n        self.status_code = status_code\n        Exception.__init__(self, status_code)  # &lt;-- 必需\n</code></pre> <p>所以规则是：对于任何支持自定义参数 <code>*args</code> 的异常，必须使用 <code>Exception.__init__(self, *args)</code>。</p> <p>没有对关键字参数的特殊支持，因此如果您希望在异常被反序列化时保留关键字参数，您必须将它们作为常规参数传递：</p> <pre><code>class HttpError(Exception):\n\n    def __init__(self, status_code, headers=None, body=None):\n        self.status_code = status_code\n        self.headers = headers\n        self.body = body\n\n        super(HttpError, self).__init__(status_code, headers, body)\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_24","level":2,"title":"半谓词","text":"<p>工作器将任务包装在一个跟踪函数中，该函数记录任务的最终状态。有许多异常可以用来向此函数发出信号，以改变它处理任务返回的方式。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#ignore","level":3,"title":"Ignore","text":"<p>任务可以抛出 <code>Ignore</code> 异常来强制工作器忽略该任务。这意味着不会记录该任务的状态，但消息仍然会被确认（从队列中移除）。</p> <p>如果您想要实现自定义的撤销类功能，或者手动存储任务结果，可以使用此功能。</p> <p>示例：在Redis集合中保留已撤销的任务：</p> <pre><code>from celery.exceptions import Ignore\n\n@app.task(bind=True)\ndef some_task(self):\n    if redis.ismember('tasks.revoked', self.request.id):\n        raise Ignore()\n</code></pre> <p>示例：手动存储结果：</p> <pre><code>from celery import states\nfrom celery.exceptions import Ignore\n\n@app.task(bind=True)\ndef get_tweets(self, user):\n    timeline = twitter.get_timeline(user)\n    if not self.request.called_directly:\n        self.update_state(state=states.SUCCESS, meta=timeline)\n    raise Ignore()\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#reject","level":3,"title":"Reject","text":"<p>任务可以抛出 <code>Reject</code> 异常来使用AMQP的 <code>basic_reject</code> 方法拒绝任务消息。除非启用了 <code>acks_late</code>，否则这不会产生任何效果。</p> <p>拒绝消息与确认消息具有相同的效果，但一些代理可能实现可以使用的附加功能。例如，RabbitMQ支持死信交换的概念，其中可以配置队列使用死信交换，被拒绝的消息会被重新投递到该交换。</p> <p>Reject也可以用于重新排队消息，但请非常小心地使用此功能，因为它很容易导致无限消息循环。</p> <p>示例：当任务导致内存不足条件时使用reject：</p> <pre><code>import errno\nfrom celery.exceptions import Reject\n\n@app.task(bind=True, acks_late=True)\ndef render_scene(self, path):\n    file = get_file(path)\n    try:\n        renderer.render_scene(file)\n\n    # 如果文件太大无法放入内存\n    # 我们拒绝它，以便它被重新投递到死信交换\n    # 我们可以手动检查情况。\n    except MemoryError as exc:\n        raise Reject(exc, requeue=False)\n    except OSError as exc:\n        if exc.errno == errno.ENOMEM:\n            raise Reject(exc, requeue=False)\n\n    # 对于任何其他错误，我们在10秒后重试。\n    except Exception as exc:\n        raise self.retry(exc, countdown=10)\n</code></pre> <p>示例：重新排队消息：</p> <pre><code>from celery.exceptions import Reject\n\n@app.task(bind=True, acks_late=True)\ndef requeues(self):\n    if not self.request.delivery_info['redelivered']:\n        raise Reject('no reason', requeue=True)\n    print('received two times')\n</code></pre> <p>有关 <code>basic_reject</code> 方法的更多详细信息，请查阅您的代理文档。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#retry_1","level":3,"title":"Retry","text":"<p><code>Retry</code> 异常由 <code>Task.retry</code> 方法抛出，用于告诉工作器任务正在被重试。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_25","level":2,"title":"自定义任务类","text":"<p>所有任务都继承自 <code>Task</code> 类。<code>run()</code> 方法成为任务的主体。</p> <p>例如，以下代码：</p> <pre><code>@app.task\ndef add(x, y):\n    return x + y\n</code></pre> <p>在幕后大致会这样做：</p> <pre><code>class _AddTask(app.Task):\n\n    def run(self, x, y):\n        return x + y\n\n\nadd = app.tasks[_AddTask.name]\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_26","level":3,"title":"实例化","text":"<p>任务不会为每个请求实例化，而是在任务注册表中作为全局实例注册。</p> <p>这意味着 <code>__init__</code> 构造函数在每个进程中只会被调用一次，并且任务类在语义上更接近于 Actor 模式。</p> <p>如果你有一个任务：</p> <pre><code>from celery import Task\n\nclass NaiveAuthenticateServer(Task):\n\n    def __init__(self):\n        self.users = {'george': 'password'}\n\n    def run(self, username, password):\n        try:\n            return self.users[username] == password\n        except KeyError:\n            return False\n</code></pre> <p>并且你将每个请求路由到同一个进程，那么它将在请求之间保持状态。</p> <p>这对于缓存资源也很有用，例如，一个缓存数据库连接的基础任务类：</p> <pre><code>from celery import Task\n\nclass DatabaseTask(Task):\n    _db = None\n\n    @property\n    def db(self):\n        if self._db is None:\n            self._db = Database.connect()\n        return self._db\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_27","level":4,"title":"每个任务使用","text":"<p>上述内容可以像这样添加到每个任务中：</p> <pre><code>from celery.app import task\n\n@app.task(base=DatabaseTask, bind=True)\ndef process_rows(self: task):\n    for row in self.db.table.all():\n        process_row(row)\n</code></pre> <p><code>process_rows</code> 任务的 <code>db</code> 属性将在每个进程中始终保持相同。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_28","level":4,"title":"应用程序范围使用","text":"<p>你也可以在整个 Celery 应用程序中使用你的自定义类，通过在实例化应用程序时将其作为 <code>task_cls</code> 参数传递。这个参数应该是一个字符串，给出你的 Task 类的 Python 路径，或者是类本身：</p> <pre><code>from celery import Celery\n\napp = Celery('tasks', task_cls='your.module.path:DatabaseTask')\n</code></pre> <p>这将使你在应用程序中使用装饰器语法声明的所有任务都使用你的 <code>DatabaseTask</code> 类，并且都将具有 <code>db</code> 属性。</p> <p>默认值是 Celery 提供的类：<code>'celery.app.task:Task'</code>。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_29","level":3,"title":"处理器","text":"<p>任务处理器是在任务生命周期特定点执行的方法。所有处理器都在执行任务的同一个工作进程和线程中同步运行。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_30","level":4,"title":"执行时间线","text":"<p>以下图表显示了确切的执行顺序：</p> <pre><code>Worker Process Timeline\n┌───────────────────────────────────────────────────────────────┐\n│  1. before_start()      ← Blocks until complete               │\n│  2. run()               ← Your task function                  │\n│  3. [Result Backend]    ← State + return value persisted      │\n│  4. on_success() OR     ← Outcome-specific handler            │\n│     on_retry() OR       │                                     │\n│     on_failure()        │                                     │\n│  5. after_return()      ← Always runs last                    │\n└───────────────────────────────────────────────────────────────┘\n</code></pre> <p>Tip</p> <p>关键点：</p> <ul> <li>所有处理器都在与你的任务相同的工作进程中运行</li> <li><code>before_start</code> 阻塞任务 - <code>run()</code> 直到它完成后才会开始</li> <li>结果后端在 <code>on_success</code>/<code>on_failure</code> 之前更新 - 其他客户端可以在处理器仍在运行时看到任务已完成</li> <li><code>after_return</code> 总是执行，无论任务结果如何</li> </ul>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_31","level":4,"title":"可用的处理器","text":"<p>before_start(self, task_id, args, kwargs)</p> <p>由工作进程在任务开始执行之前运行。</p> <p>Note</p> <p>此处理器阻塞任务：<code>run()</code> 方法在 <code>before_start</code> 返回之前不会开始。</p> 参数 描述 task_id 要执行的任务的唯一ID。 args 要执行的任务的原始参数。 kwargs 要执行的任务的原始关键字参数。 <p>此处理器的返回值被忽略。</p> <p>on_success(self, retval, task_id, args, kwargs)</p> <p>成功处理器。</p> <p>如果任务成功执行，由工作进程运行。</p> <p>Note</p> <p>在任务结果已经持久化到结果后端之后调用。外部客户端可能在此处理器仍在运行时观察到任务为 <code>SUCCESS</code> 状态。</p> 参数 描述 retval 任务的返回值。 task_id 已执行任务的唯一ID。 args 已执行任务的原始参数。 kwargs 已执行任务的原始关键字参数。 <p>此处理器的返回值被忽略。</p> <p>on_retry(self, exc, task_id, args, kwargs, einfo)</p> <p>重试处理器。</p> <p>当任务要重试时由工作进程运行。</p> <p>Note</p> <p>在任务状态已在结果后端更新为 <code>RETRY</code> 之后调用，但在重试被调度之前。</p> 参数 描述 exc 发送到 <code>retry()</code> 的异常。 task_id 要重试的任务的唯一ID。 args 要重试的任务的原始参数。 kwargs 要重试的任务的原始关键字参数。 einfo <code>billiard.einfo.ExceptionInfo</code> 实例。 <p>此处理器的返回值被忽略。</p> <p>on_failure(self, exc, task_id, args, kwargs, einfo)</p> <p>失败处理器。</p> <p>当任务失败时由工作进程运行。</p> <p>Note</p> <p>在任务结果已经以 <code>FAILURE</code> 状态持久化到结果后端之后调用。外部客户端可能在此处理器仍在运行时观察到任务失败。</p> 参数 描述 exc 任务引发的异常。 task_id 失败任务的唯一ID。 args 失败任务的原始参数。 kwargs 失败任务的原始关键字参数。 einfo <code>billiard.einfo.ExceptionInfo</code> 实例。 <p>此处理器的返回值被忽略。</p> <p>after_return(self, status, retval, task_id, args, kwargs, einfo)</p> <p>任务返回后调用的处理器。</p> <p>Note</p> <p>在 <code>on_success</code>/<code>on_retry</code>/<code>on_failure</code> 之后执行。这是任务生命周期中的最终钩子，总是运行，无论结果如何。</p> 参数 描述 status 当前任务状态。 retval 任务返回值/异常。 task_id 任务的唯一ID。 args 返回的任务的原始参数。 kwargs 返回的任务的原始关键字参数。 einfo <code>billiard.einfo.ExceptionInfo</code> 实例。 <p>此处理器的返回值被忽略。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_32","level":3,"title":"示例用法","text":"<pre><code>import time\nfrom celery import Task\n\nclass MyTask(Task):\n\n    def before_start(self, task_id, args, kwargs):\n        print(f\"Task {task_id} starting with args {args}\")\n        # 这会阻塞 - run() 在此返回之前不会开始\n\n    def on_success(self, retval, task_id, args, kwargs):\n        print(f\"Task {task_id} succeeded with result: {retval}\")\n        # 此时结果已经对客户端可见\n\n    def on_failure(self, exc, task_id, args, kwargs, einfo):\n        print(f\"Task {task_id} failed: {exc}\")\n        # 任务状态在后端已经是 FAILURE\n\n    def after_return(self, status, retval, task_id, args, kwargs, einfo):\n        print(f\"Task {task_id} finished with status: {status}\")\n        # 总是最后运行\n\n@app.task(base=MyTask)\ndef my_task(x, y):\n    return x + y\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_33","level":3,"title":"请求和自定义请求","text":"<p>当接收到运行任务的消息时，工作进程指南创建一个 <code>request</code> 来表示这种需求。</p> <p>自定义任务类可以通过更改属性 <code>celery.app.task.Task.Request</code> 来覆盖要使用的请求类。你可以分配自定义请求类本身，或者其完全限定名称。</p> <p>请求有几个职责。自定义请求类应该覆盖所有这些职责——它们负责实际运行和跟踪任务。我们强烈建议从 <code>celery.worker.request.Request</code> 继承。</p> <p>当使用 工作进程指南 - 并发性 时，方法 <code>celery.worker.request.Request.on_timeout</code> 和 <code>celery.worker.request.Request.on_failure</code> 在主工作进程中执行。应用程序可以利用这种机制来检测使用 <code>celery.app.task.Task.on_failure</code> 无法检测到的故障。</p> <p>例如，以下自定义请求检测并记录硬时间限制和其他故障。</p> <pre><code>import logging\nfrom celery import Task\nfrom celery.worker.request import Request\n\nlogger = logging.getLogger('my.package')\n\nclass MyRequest(Request):\n   '一个最小的自定义请求，用于记录故障和硬时间限制。'\n\n   def on_timeout(self, soft, timeout):\n       super(MyRequest, self).on_timeout(soft, timeout)\n       if not soft:\n          logger.warning(\n              'A hard timeout was enforced for task %s',\n              self.task.name\n          )\n\n   def on_failure(self, exc_info, send_failed_event=True, return_ok=False):\n       super().on_failure(\n           exc_info,\n           send_failed_event=send_failed_event,\n           return_ok=return_ok\n       )\n       logger.warning(\n           'Failure detected for task %s',\n           self.task.name\n       )\n\nclass MyTask(Task):\n   Request = MyRequest  # 你可以使用完全限定名称 'my.package:MyRequest'\n\n@app.task(base=MyTask)\ndef some_longrunning_task():\n   # 发挥你的想象力\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_34","level":2,"title":"工作原理","text":"<p>接下来是技术细节。这部分内容不是您必须了解的，但您可能会感兴趣。</p> <p>所有定义的任务都列在一个注册表中。该注册表包含task名称及其任务类的列表。您可以自己检查这个注册表：</p> <pre><code>&gt;&gt;&gt; from proj.celery import app\n&gt;&gt;&gt; app.tasks\n{'celery.chord_unlock':\n    &lt;@task: celery.chord_unlock&gt;,\n 'celery.backend_cleanup':\n    &lt;@task: celery.backend_cleanup&gt;,\n 'celery.chord':\n    &lt;@task: celery.chord&gt;}\n</code></pre> <p>这是Celery内置的任务列表。请注意，任务只有在定义它们的模块被导入时才会注册。</p> <p>默认加载器会导入 <code>imports</code> 设置中列出的任何模块。</p> <p><code>task()</code> 装饰器负责将您的任务注册到应用程序的任务注册表中。</p> <p>当任务被发送时，不会发送实际的函数代码，只发送要执行的task名称。当工作器接收到消息时，它可以在其任务注册表中查找该名称以找到执行代码。</p> <p>这意味着您的工作器应该始终与客户端使用相同的软件进行更新。这是一个缺点，但替代方案是一个尚未解决的技术挑战。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_35","level":2,"title":"提示和最佳实践","text":"","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_36","level":3,"title":"忽略不需要的结果","text":"<p>如果您不关心任务的结果，请务必设置 <code>ignore_result</code> 选项，因为存储结果会浪费时间和资源。</p> <pre><code>@app.task(ignore_result=True)\ndef mytask():\n    something()\n</code></pre> <p>甚至可以使用 <code>task_ignore_result</code> 设置全局禁用结果。</p> <p>在调用 <code>apply_async</code> 时，可以通过传递 <code>ignore_result</code> 布尔参数，按每次执行启用/禁用结果。</p> <pre><code>@app.task\ndef mytask(x, y):\n    return x + y\n\n# 不会存储结果\nresult = mytask.apply_async((1, 2), ignore_result=True)\nprint(result.get()) # -&gt; None\n\n# 会存储结果\nresult = mytask.apply_async((1, 2), ignore_result=False)\nprint(result.get()) # -&gt; 3\n</code></pre> <p>默认情况下，当配置了结果后端时，任务将不会忽略结果（<code>ignore_result=False</code>）。</p> <p>选项优先级顺序如下：</p> <ol> <li>全局 <code>task_ignore_result</code></li> <li><code>ignore_result</code> 选项</li> <li>任务执行选项 <code>ignore_result</code></li> </ol>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_37","level":3,"title":"更多优化提示","text":"<p>您可以在 优化指南 中找到其他优化提示。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_38","level":3,"title":"避免启动同步子任务","text":"<p>让一个任务等待另一个任务的结果是非常低效的，如果工作池耗尽，甚至可能导致死锁。</p> <p>请改为使用异步设计，例如使用回调。</p> <p>不好的做法：</p> <pre><code>@app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get()\n    info = parse_page.delay(page).get()\n    store_page_info.delay(url, info)\n\n@app.task\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task\ndef store_page_info(url, info):\n    return PageInfo.objects.create(url, info)\n</code></pre> <p>好的做法：</p> <pre><code>def update_page_info(url):\n    # fetch_page -&gt; parse_page -&gt; store_page\n    chain = fetch_page.s(url) | parse_page.s() | store_page_info.s(url)\n    chain()\n\n@app.task()\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task()\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task(ignore_result=True)\ndef store_page_info(info, url):\n    PageInfo.objects.create(url=url, info=info)\n</code></pre> <p>这里我通过链接不同的 <code>signature</code> 创建了一个任务链。您可以在 设计工作流 中阅读有关链和其他强大构造的内容。</p> <p>默认情况下，Celery 不允许您在任务内同步运行子任务，但在罕见或极端情况下，您可能需要这样做。</p> <p>警告：启用子任务同步运行是不推荐的！</p> <pre><code>@app.task\ndef update_page_info(url):\n    page = fetch_page.delay(url).get(disable_sync_subtasks=False)\n    info = parse_page.delay(page).get(disable_sync_subtasks=False)\n    store_page_info.delay(url, info)\n\n@app.task\ndef fetch_page(url):\n    return myhttplib.get(url)\n\n@app.task\ndef parse_page(page):\n    return myparser.parse_document(page)\n\n@app.task\ndef store_page_info(url, info):\n    return PageInfo.objects.create(url, info)\n</code></pre>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_39","level":2,"title":"性能和策略","text":"","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_40","level":3,"title":"粒度","text":"<p>任务粒度是每个子任务所需的计算量。通常来说，将问题拆分成许多小任务比使用几个长时间运行的任务更好。</p> <p>使用较小的任务，您可以并行处理更多任务，并且任务不会运行太长时间而阻塞工作进程处理其他等待的任务。</p> <p>然而，执行任务确实有开销。需要发送消息，数据可能不是本地的，等等。因此，如果任务过于细粒度，增加的开销可能会抵消任何好处。</p> <p>《并发编程的艺术》这本书有一个专门讨论任务粒度主题的章节[AOC1]<sup>1</sup>。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_41","level":3,"title":"数据局部性","text":"<p>处理任务的工作进程应尽可能靠近数据。最好是在内存中有一个副本，最坏的情况是从另一个大陆进行完整传输。</p> <p>如果数据很远，您可以尝试在位置运行另一个工作进程，或者如果不可能的话，缓存经常使用的数据，或预加载您知道将要使用的数据。</p> <p>在工作进程之间共享数据的最简单方法是使用分布式缓存系统，如memcached。</p> <p>Jim Gray的论文分布式计算经济学是数据局部性主题的优秀介绍。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_42","level":3,"title":"状态","text":"<p>由于Celery是一个分布式系统，您无法知道任务将在哪个进程或哪台机器上执行。您甚至无法知道任务是否会及时运行。</p> <p>古老的异步格言告诉我们\"断言世界是任务的责任\"。这意味着自任务请求以来，世界视图可能已经改变，因此任务有责任确保世界处于应有的状态；如果您有一个重新索引搜索引擎的任务，并且搜索引擎最多每5分钟才应重新索引一次，那么这必须是任务的责任来断言这一点，而不是调用者的责任。</p> <p>另一个需要注意的问题是Django模型对象。它们不应作为参数传递给任务。几乎总是更好的是在任务运行时从数据库中重新获取对象，因为使用旧数据可能导致竞态条件。</p> <p>想象以下场景：您有一篇文章和一个自动扩展其中某些缩写的任务：</p> <pre><code>class Article(models.Model):\n    title = models.CharField()\n    body = models.TextField()\n\n@app.task\ndef expand_abbreviations(article):\n    article.body.replace('MyCorp', 'My Corporation')\n    article.save()\n</code></pre> <p>首先，作者创建一篇文章并保存，然后作者点击一个按钮来启动缩写任务：</p> <pre><code>&gt;&gt;&gt; article = Article.objects.get(id=102)\n&gt;&gt;&gt; expand_abbreviations.delay(article)\n</code></pre> <p>现在，队列非常繁忙，因此任务将在2分钟后才会运行。与此同时，另一位作者对文章进行了更改，因此当任务最终运行时，文章正文会恢复到旧版本，因为任务参数中包含了旧正文。</p> <p>修复竞态条件很容易，只需使用文章ID，并在任务体中重新获取文章：</p> <pre><code>@app.task\ndef expand_abbreviations(article_id):\n    article = Article.objects.get(id=article_id)\n    article.body.replace('MyCorp', 'My Corporation')\n    article.save()\n</code></pre> <pre><code>&gt;&gt;&gt; expand_abbreviations.delay(article_id)\n</code></pre> <p>这种方法甚至可能有性能优势，因为发送大消息可能很昂贵。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_43","level":3,"title":"数据库事务","text":"<p>让我们看另一个例子：</p> <pre><code>from django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    expand_abbreviations.delay(article.pk)\n    return HttpResponseRedirect('/articles/')\n</code></pre> <p>这是一个Django视图，在数据库中创建一个文章对象，然后将主键传递给任务。它使用 <code>transaction.atomic</code> 装饰器，该装饰器将在视图返回时提交事务，或者在视图引发异常时回滚。</p> <p>存在竞态条件，因为事务是原子性的。这意味着文章对象在视图函数返回响应之前不会持久化到数据库中。如果异步任务在事务提交之前开始执行，它可能会尝试查询尚不存在的文章对象。为了防止这种情况，我们需要确保在触发任务之前提交事务。</p> <p>解决方案是使用 <code>delay_on_commit()</code> 代替：</p> <pre><code>from django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    expand_abbreviations.delay_on_commit(article.pk)\n    return HttpResponseRedirect('/articles/')\n</code></pre> <p>此方法在Celery 5.4中添加。它是一个快捷方式，使用Django的 <code>on_commit</code> 回调在所有事务成功提交后启动您的Celery任务。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#celery-54","level":4,"title":"对于Celery &lt;5.4","text":"<p>如果您使用的是较旧版本的Celery，可以使用Django回调直接复制此行为，如下所示：</p> <pre><code>import functools\nfrom django.db import transaction\nfrom django.http import HttpResponseRedirect\n\n@transaction.atomic\ndef create_article(request):\n    article = Article.objects.create()\n    transaction.on_commit(\n        functools.partial(expand_abbreviations.delay, article.pk)\n    )\n    return HttpResponseRedirect('/articles/')\n</code></pre> <p>Note</p> <p><code>on_commit</code>在Django 1.9及以上版本中可用，如果您使用的是较早版本，则django-transaction-hooks库添加了对它的支持。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#_44","level":2,"title":"示例","text":"<p>让我们举一个真实世界的例子：一个需要过滤评论垃圾邮件的博客。当评论创建时，垃圾邮件过滤器在后台运行，因此用户无需等待其完成。</p> <p>我有一个允许在博客文章上评论的Django博客应用程序。我将描述这个应用程序的模型/视图和任务部分。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#blogmodelspy","level":3,"title":"<code>blog/models.py</code>","text":"<p>评论模型如下所示：</p> <pre><code>from django.db import models\nfrom django.utils.translation import ugettext_lazy as _\n\n\nclass Comment(models.Model):\n    name = models.CharField(_('name'), max_length=64)\n    email_address = models.EmailField(_('email address'))\n    homepage = models.URLField(_('home page'), blank=True, verify_exists=False)\n    comment = models.TextField(_('comment'))\n    pub_date = models.DateTimeField(_('Published date'), editable=False, auto_add_now=True)\n    is_spam = models.BooleanField(_('spam?'), default=False, editable=False)\n\n    class Meta:\n        verbose_name = _('comment')\n        verbose_name_plural = _('comments')\n</code></pre> <p>在发布评论的视图中，我首先将评论写入数据库，然后在后台启动垃圾邮件过滤器任务。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#blogviewspy","level":3,"title":"<code>blog/views.py</code>","text":"<pre><code>from django import forms\nfrom django.http import HttpResponseRedirect\nfrom django.template.context import RequestContext\nfrom django.shortcuts import get_object_or_404, render_to_response\n\nfrom blog import tasks\nfrom blog.models import Comment\n\n\nclass CommentForm(forms.ModelForm):\n\n    class Meta:\n        model = Comment\n\n\ndef add_comment(request, slug, template_name='comments/create.html'):\n    post = get_object_or_404(Entry, slug=slug)\n    remote_addr = request.META.get('REMOTE_ADDR')\n\n    if request.method == 'post':\n        form = CommentForm(request.POST, request.FILES)\n        if form.is_valid():\n            comment = form.save()\n            # 异步检查垃圾邮件。\n            tasks.spam_filter.delay(comment_id=comment.id,\n                                    remote_addr=remote_addr)\n            return HttpResponseRedirect(post.get_absolute_url())\n    else:\n        form = CommentForm()\n\n    context = RequestContext(request, {'form': form})\n    return render_to_response(template_name, context_instance=context)\n</code></pre> <p>为了过滤评论中的垃圾邮件，我使用Akismet，该服务用于过滤发布到免费博客平台Wordpress的评论中的垃圾邮件。Akismet对个人使用是免费的，但对于商业用途需要付费。您必须注册他们的服务才能获得API密钥。</p> <p>为了向Akismet进行API调用，我使用由Michael Foord编写的akismet.py库。</p>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/tasks/#blogtaskspy","level":3,"title":"<code>blog/tasks.py</code>","text":"<pre><code>from celery import Celery\n\nfrom akismet import Akismet\n\nfrom django.core.exceptions import ImproperlyConfigured\nfrom django.contrib.sites.models import Site\n\nfrom blog.models import Comment\n\n\napp = Celery(broker='amqp://')\n\n\n@app.task\ndef spam_filter(comment_id, remote_addr=None):\n    logger = spam_filter.get_logger()\n    logger.info('Running spam filter for comment %s', comment_id)\n\n    comment = Comment.objects.get(pk=comment_id)\n    current_domain = Site.objects.get_current().domain\n    akismet = Akismet(settings.AKISMET_KEY, 'http://{0}'.format(current_domain))\n    if not akismet.verify_key():\n        raise ImproperlyConfigured('Invalid AKISMET_KEY')\n\n\n    is_spam = akismet.comment_check(user_ip=remote_addr,\n                        comment_content=comment.comment,\n                        comment_author=comment.name,\n                        comment_author_email=comment.email_address)\n    if is_spam:\n        comment.is_spam = True\n        comment.save()\n\n    return is_spam\n</code></pre> <ol> <li> <p>Breshears, Clay. 第2.2.1节，\"并发编程的艺术\"。O'Reilly Media, Inc. 2009年5月15日。ISBN-13 978-0-596-52153-0。 ↩</p> </li> </ol>","path":["用户指南","任务"],"tags":[]},{"location":"user-guide/testing/","level":1,"title":"使用 Celery 进行测试","text":"<p>使用 Celery 进行测试分为两个部分：</p> <ul> <li>单元测试和集成测试：使用 <code>celery.contrib.pytest</code></li> <li>冒烟测试/生产测试：使用 <code>pytest-celery</code> &gt;= 1.0.0</li> </ul> <p>安装 pytest-celery 插件也会安装 <code>celery.contrib.pytest</code> 基础设施，以及 pytest 插件基础设施。区别在于如何使用它们。</p> <p>Warning</p> <p>这两个 API 彼此不兼容。pytest-celery 插件基于 Docker，而 <code>celery.contrib.pytest</code> 基于模拟（mock）。</p> <p>要使用 <code>celery.contrib.pytest</code> 基础设施，请遵循以下说明。</p> <p>pytest-celery 插件有自己的文档。</p>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#_1","level":2,"title":"任务和单元测试","text":"<p>在单元测试中测试任务行为的首选方法是模拟（mocking）。</p> <p>Eager 模式</p> <p>由 <code>task_always_eager</code> 设置启用的 eager 模式根据定义不适合用于单元测试。</p> <p>当使用 eager 模式进行测试时，您只是在测试一个模拟的工作进程行为，而模拟和实际情况之间存在很多差异。</p> <p>请注意，默认情况下，急切执行的任务不会将结果写入后端。如果您想启用此功能，请查看 <code>task_store_eager_result</code>。</p> <p>Celery 任务很像 Web 视图，因为它应该只定义在被作为任务调用时如何执行操作。</p> <p>这意味着理想情况下，任务只处理序列化、消息头、重试等事情，而实际逻辑在其他地方实现。</p> <p>假设我们有这样一个任务：</p> <pre><code>from .models import Product\n\n\n@app.task(bind=True)\ndef send_order(self, product_pk, quantity, price):\n    price = Decimal(price)  # json 将其序列化为字符串。\n\n    # 模型通过 id 传递，而不是序列化。\n    product = Product.objects.get(product_pk)\n\n    try:\n        product.order(quantity, price)\n    except OperationalError as exc:\n        raise self.retry(exc=exc)\n</code></pre> <p><code>注意</code>：一个任务被绑定意味着任务的第一个参数将始终是任务实例（self）。这意味着您确实会得到一个 self 参数作为第一个参数，并且可以使用 Task 类的方法和属性。</p> <p>您可以使用模拟为此任务编写单元测试， 如以下示例所示：</p> <pre><code>from pytest import raises\n\nfrom celery.exceptions import Retry\n\n# 对于 python 2：使用来自 `pip install mock` 的 mock.patch。\nfrom unittest.mock import patch\n\nfrom proj.models import Product\nfrom proj.tasks import send_order\n\nclass test_send_order:\n\n    @patch('proj.tasks.Product.order')  # &lt; 修补上面模块中的 Product\n    def test_success(self, product_order):\n        product = Product.objects.create(\n            name='Foo',\n        )\n        send_order(product.pk, 3, Decimal(30.3))\n        product_order.assert_called_with(3, Decimal(30.3))\n\n    @patch('proj.tasks.Product.order')\n    @patch('proj.tasks.send_order.retry')\n    def test_failure(self, send_order_retry, product_order):\n        product = Product.objects.create(\n            name='Foo',\n        )\n\n        # 在修补的方法上设置副作用\n        # 以便它们引发我们想要的错误。\n        send_order_retry.side_effect = Retry()\n        product_order.side_effect = OperationalError()\n\n        with raises(Retry):\n            send_order(product.pk, 3, Decimal(30.6))\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#pytest","level":2,"title":"pytest","text":"<p>Celery 还提供了一个 <code>pytest</code> 插件，该插件添加了可以在集成（或单元）测试套件中使用的夹具。</p>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#_2","level":3,"title":"启用","text":"<p>Celery 最初以禁用状态提供该插件。要启用它，您可以：</p> <ul> <li><code>pip install celery[pytest]</code></li> <li>或添加环境变量 <code>PYTEST_PLUGINS=celery.contrib.pytest</code></li> <li>或在根目录的 conftest.py 中添加 <code>pytest_plugins = (\"celery.contrib.pytest\", )</code></li> </ul>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#_3","level":3,"title":"标记","text":"<p><code>celery</code> - 设置测试应用配置。</p> <p><code>celery</code> 标记使您能够覆盖用于单个测试用例的配置：</p> <pre><code>@pytest.mark.celery(result_backend='redis://')\ndef test_something():\n    ...\n</code></pre> <p>或用于类中的所有测试用例：</p> <pre><code>@pytest.mark.celery(result_backend='redis://')\nclass test_something:\n\n    def test_one(self):\n        ...\n\n    def test_two(self):\n        ...\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#_4","level":3,"title":"夹具","text":"","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#_5","level":4,"title":"函数作用域","text":"","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_app","level":5,"title":"<code>celery_app</code>","text":"<p>用于测试的Celery应用。</p> <p>此夹具返回一个可用于测试的Celery应用。</p> <p>示例：</p> <pre><code>def test_create_task(celery_app, celery_worker):\n    @celery_app.task\n    def mul(x, y):\n        return x * y\n\n    celery_worker.reload()\n    assert mul.delay(4, 4).get(timeout=10) == 16\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_worker","level":5,"title":"<code>celery_worker</code>","text":"<p>嵌入实时工作器。</p> <p>此夹具启动一个Celery工作器实例，可用于集成测试。工作器将在单独的线程中启动，并在测试返回时立即关闭。</p> <p>默认情况下，夹具将等待工作器完成未完成任务最多10秒，如果超过时间限制将引发异常。可以通过设置 <code>celery_worker_parameters</code> 夹具返回的字典中的 <code>shutdown_timeout</code> 键来自定义超时时间。</p> <p>示例：</p> <pre><code># 将此放入conftest.py中\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'redis://'\n    }\n\ndef test_add(celery_worker):\n    mytask.delay()\n\n\n# 如果希望仅在一个测试用例中覆盖某些设置\n# - 可以使用`celery`标记：\n@pytest.mark.celery(result_backend='rpc')\ndef test_other(celery_worker):\n    ...\n</code></pre> <p>默认情况下禁用心跳，这意味着测试工作器不会发送 <code>worker-online</code>、<code>worker-offline</code> 和 <code>worker-heartbeat</code> 事件。要启用心跳，请修改 <code>celery_worker_parameters</code> 夹具：</p> <pre><code># 将此放入conftest.py中\n@pytest.fixture(scope=\"session\")\ndef celery_worker_parameters():\n    return {\"without_heartbeat\": False}\n    ...\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#_6","level":4,"title":"会话作用域","text":"","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_config","level":5,"title":"<code>celery_config</code>","text":"<p>覆盖以设置Celery测试应用配置。</p> <p>您可以重新定义此夹具来配置测试Celery应用。</p> <p>您的夹具返回的配置将用于配置 <code>celery_app</code> 和 <code>celery_session_app</code> 夹具。</p> <p>示例：</p> <pre><code>@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'rpc',\n    }\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_parameters","level":5,"title":"<code>celery_parameters</code>","text":"<p>覆盖以设置Celery测试应用参数。</p> <p>您可以重新定义此夹具来更改测试 Celery 应用的 <code>__init__</code> 参数。与 <code>celery_config</code> 不同，这些参数在实例化 <code>Celery</code> 时直接传递。</p> <p>您的夹具返回的配置将用于配置 <code>celery_app</code> 和 <code>celery_session_app</code> 夹具。</p> <p>示例：</p> <pre><code>@pytest.fixture(scope='session')\ndef celery_parameters():\n    return {\n        'task_cls':  my.package.MyCustomTaskClass,\n        'strict_typing': False,\n    }\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_worker_parameters","level":5,"title":"<code>celery_worker_parameters</code>","text":"<p>覆盖以设置Celery工作器参数。</p> <p>您可以重新定义此夹具来更改测试 Celery 工作器的 <code>__init__</code> 参数。这些参数在实例化 <code>WorkController</code> 时直接传递。</p> <p>您的夹具返回的配置将用于配置 <code>celery_worker</code> 和 <code>celery_session_worker</code> 夹具。</p> <p>示例：</p> <pre><code>@pytest.fixture(scope='session')\ndef celery_worker_parameters():\n    return {\n        'queues':  ('high-prio', 'low-prio'),\n        'exclude_queues': ('celery'),\n    }\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_enable_logging","level":5,"title":"<code>celery_enable_logging</code>","text":"<p>覆盖以在嵌入工作器中启用日志记录。</p> <p>这是一个您可以覆盖的夹具，用于在嵌入工作器中启用日志记录。</p> <p>示例：</p> <pre><code>@pytest.fixture(scope='session')\ndef celery_enable_logging():\n    return True\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_includes","level":5,"title":"<code>celery_includes</code>","text":"<p>为嵌入工作器添加额外的导入。</p> <p>您可以覆盖此夹具以在嵌入工作器启动时包含模块。</p> <p>您可以使其返回要导入的模块名称列表，这些模块可以是任务模块、注册信号的模块等。</p> <p>示例：</p> <pre><code>@pytest.fixture(scope='session')\ndef celery_includes():\n    return [\n        'proj.tests.tasks',\n        'proj.tests.celery_signal_handlers',\n    ]\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_worker_pool","level":5,"title":"<code>celery_worker_pool</code>","text":"<p>覆盖嵌入工作器使用的池。</p> <p>您可以覆盖此夹具以配置嵌入工作器使用的执行池。</p> <p>示例：</p> <pre><code>@pytest.fixture(scope='session')\ndef celery_worker_pool():\n    return 'prefork'\n</code></pre> <p>Warning</p> <p>您不能使用gevent/eventlet池，除非您的整个测试套件都启用了monkeypatch。</p>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_session_worker","level":5,"title":"<code>celery_session_worker</code>","text":"<p>在整个会话期间存在的嵌入工作器。</p> <p>此夹具启动一个在整个测试会话期间存在的工作器（不会为每个测试启动/停止）。</p> <p>示例：</p> <pre><code># 将此添加到conftest.py中\n@pytest.fixture(scope='session')\ndef celery_config():\n    return {\n        'broker_url': 'amqp://',\n        'result_backend': 'rpc',\n    }\n\n# 在测试中执行此操作。\ndef test_add_task(celery_session_worker):\n    assert add.delay(2, 2).get() == 4\n</code></pre> <p>Warning</p> <p>混合使用会话和临时工作器可能不是一个好主意...</p>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#celery_session_app","level":5,"title":"<code>celery_session_app</code>","text":"<p>用于测试的Celery应用（会话作用域）。</p> <p>当其他会话作用域的夹具需要引用Celery应用实例时，可以使用此夹具。</p>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/testing/#use_celery_app_trap","level":5,"title":"<code>use_celery_app_trap</code>","text":"<p>在回退到默认应用时引发异常。</p> <p>这是一个您可以在 <code>conftest.py</code> 中覆盖的夹具，用于启用\"应用陷阱\"：如果某些东西尝试访问默认应用或 current_app，将引发异常。</p> <p>示例：</p> <pre><code>@pytest.fixture(scope='session')\ndef use_celery_app_trap():\n    return True\n</code></pre> <p>如果测试想要访问默认应用，您必须使用 <code>depends_on_current_app</code> 夹具标记它：</p> <pre><code>@pytest.mark.usefixtures('depends_on_current_app')\ndef test_something():\n    something()\n</code></pre>","path":["用户指南","使用 Celery 进行测试"],"tags":[]},{"location":"user-guide/workers/","level":1,"title":"工作进程","text":"","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#worker","level":2,"title":"启动 worker","text":"<p>守护进程化</p> <p>你可能希望使用守护进程化工具来在后台启动工作者。有关使用流行的服务管理器将工作者作为守护进程启动的帮助，请参阅 守护进程指南。</p> <p>你可以通过执行以下命令在前台启动工作者：</p> <pre><code>celery -A proj worker -l INFO\n</code></pre> <p>有关可用命令行选项的完整列表，请参阅 <code>celery.bin.worker</code>，或者简单地执行：</p> <pre><code>celery worker --help\n</code></pre> <p>你可以在同一台机器上启动多个工作者，但 请确保通过使用 <code>celery worker --hostname</code> 参数指定节点名称来命名每个单独的工作者：</p> <pre><code>celery -A proj worker --loglevel=INFO --concurrency=10 -n worker1@%h\ncelery -A proj worker --loglevel=INFO --concurrency=10 -n worker2@%h\ncelery -A proj worker --loglevel=INFO --concurrency=10 -n worker3@%h\n</code></pre> <p><code>hostname</code> 参数可以展开以下变量：</p> <ul> <li><code>%h</code>: 主机名，包括域名。</li> <li><code>%n</code>: 仅主机名。</li> <li><code>%d</code>: 仅域名。</li> </ul> <p>如果当前主机名是 george.example.com，这些变量将展开为：</p> 变量 模板 结果 <code>%h</code> <code>worker1@%h</code> worker1@george.example.com <code>%n</code> <code>worker1@%n</code> worker1@george <code>%d</code> <code>worker1@%d</code> worker1@example.com","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#worker-stopping","level":2,"title":"停止 worker 进程","text":"<p>关闭应该使用 <code>TERM</code> 信号来完成。</p> <p>当关闭启动时，工作进程将在实际终止之前完成所有当前正在执行的任务。如果这些任务很重要，您应该等待它完成，然后再采取任何激进的措施，比如发送 <code>KILL</code> 信号。</p> <p>如果工作进程在合理的时间内无法关闭，例如因为陷入无限循环或类似情况，您可以使用 <code>KILL</code> 信号来强制终止工作进程：但请注意，当前正在执行的任务将会丢失（即，除非任务设置了 <code>acks_late</code> 选项）。</p> <p>此外，由于进程无法覆盖 <code>KILL</code> 信号，工作进程将无法回收其子进程；请确保手动执行此操作。以下命令通常可以解决问题：</p> <pre><code>pkill -9 -f 'celery worker'\n</code></pre> <p>如果您的系统没有 <code>pkill</code> 命令，可以使用稍长一些的版本：</p> <pre><code>ps auxww | awk '/celery worker/ {print $2}' | xargs kill -9\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_2","level":3,"title":"工作进程关闭","text":"<p>我们将使用术语暖关闭、软关闭、冷关闭、硬关闭来描述工作进程关闭的不同阶段。当工作进程接收到 <code>TERM</code> 或 <code>QUIT</code> 信号时，它将启动关闭过程。<code>INT</code> (Ctrl-C) 信号在关闭过程中也会被处理，并且总是触发关闭过程的下一阶段。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#warm-shutdown","level":4,"title":"暖关闭（Warm Shutdown）","text":"<p>当工作进程接收到 <code>TERM</code> 信号时，它将启动暖关闭。工作进程将在实际终止之前完成所有当前正在执行的任务。工作进程第一次接收到 <code>INT</code> (Ctrl-C) 信号时，也会启动暖关闭。</p> <p>暖关闭将停止调用 <code>celery.worker.worker.WorkController.start()</code> 并调用 <code>celery.worker.worker.WorkController.stop()</code>。</p> <ul> <li>在暖关闭过程中，额外的 <code>TERM</code> 信号将被忽略。</li> <li>下一个 <code>INT</code> 信号将触发关闭过程的下一阶段。</li> </ul>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#worker-cold-shutdown","level":4,"title":"冷关闭（Cold Shutdown）","text":"<p>当工作进程接收到 <code>QUIT</code> 信号时，将启动冷关闭。工作进程将停止所有当前正在执行的任务并立即终止。</p> <p>Note</p> <p>如果环境变量 <code>REMAP_SIGTERM</code> 设置为 <code>SIGQUIT</code>，工作进程在接收到 <code>TERM</code> 信号时也会启动冷关闭，而不是暖关闭。</p> <p>冷关闭将停止调用 <code>celery.worker.worker.WorkController.start()</code> 并调用 <code>celery.worker.worker.WorkController.terminate()</code>。</p> <p>如果暖关闭已经启动，向冷关闭的过渡将运行一个信号处理程序 <code>on_cold_shutdown</code> 来取消主进程中所有当前正在执行的任务，并可能触发 软关闭。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#worker-soft-shutdown","level":4,"title":"软关闭（Soft Shutdown）","text":"<p>软关闭是一种有时间限制的暖关闭，在冷关闭之前启动。工作进程将允许 <code>worker_soft_shutdown_timeout</code> 秒的时间让所有当前正在执行的任务完成，然后终止。如果达到时间限制，工作进程将启动冷关闭并取消所有当前正在执行的任务。如果在软关闭期间接收到 <code>QUIT</code> 信号，工作进程将取消所有当前正在执行的任务，但仍会等待时间限制结束才终止，这给了工作进程一个更优雅地执行冷关闭的机会。</p> <p>软关闭默认是禁用的，以保持与 冷关闭 行为的向后兼容性。要启用软关闭，请将 <code>worker_soft_shutdown_timeout</code> 设置为一个正浮点数值。如果没有任务在运行，软关闭将被跳过。要强制软关闭，同时启用 <code>worker_enable_soft_shutdown_on_idle</code> 设置。</p> <p>Warning</p> <p>如果工作进程没有运行任何任务但保留了 ETA 任务，除非启用了 <code>worker_enable_soft_shutdown_on_idle</code> 设置，否则不会启动软关闭，这可能导致在冷关闭期间丢失任务。在使用 ETA 任务时，建议启用空闲时的软关闭。尝试不同的 :setting:<code>worker_soft_shutdown_timeout</code> 值，找到最适合您设置的配置，以将任务丢失的风险降到最低。</p> <p>例如，当设置 <code>worker_soft_shutdown_timeout=3</code> 时，工作进程将允许 3 秒的时间让所有当前正在执行的任务完成，然后终止。如果达到时间限制，工作进程将启动冷关闭并取消所有当前正在执行的任务。</p> <pre><code>[INFO/MainProcess] Task myapp.long_running_task[6f748357-b2c7-456a-95de-f05c00504042] received\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 1/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 2/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 3/2000s\n^C\nworker: Hitting Ctrl+C again will initiate cold shutdown, terminating all running tasks!\n\nworker: Warm shutdown (MainProcess)\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 4/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 5/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 6/2000s\n^C\nworker: Hitting Ctrl+C again will terminate all running tasks!\n[WARNING/MainProcess] Initiating Soft Shutdown, terminating in 3 seconds\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 7/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 8/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 9/2000s\n[WARNING/MainProcess] Restoring 1 unacknowledged message(s)\n</code></pre> <ul> <li>下一个 <code>QUIT</code> 信号将取消软关闭中仍在运行的任务，但工作进程仍会等待时间限制结束才终止。</li> <li>下一个（第 2 个）<code>QUIT</code> 或 <code>INT</code> 信号将触发关闭过程的下一阶段。</li> </ul>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#hard-shutdown","level":4,"title":"硬关闭（Hard Shutdown）","text":"<p>硬关闭主要用于本地或调试目的，允许连续发送 <code>INT</code> (Ctrl-C) 信号来强制工作进程立即终止。工作进程将停止所有当前正在执行的任务，并通过在主进程中引发 <code>WorkerTerminate</code> 异常来立即终止。</p> <p>例如，注意下面日志中的 <code>^C</code>（使用 <code>INT</code> 信号在不同阶段之间移动）：</p> <pre><code>[INFO/MainProcess] Task myapp.long_running_task[7235ac16-543d-4fd5-a9e1-2d2bb8ab630a] received\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 1/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 2/2000s\n^C\nworker: Hitting Ctrl+C again will initiate cold shutdown, terminating all running tasks!\n\nworker: Warm shutdown (MainProcess)\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 3/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 4/2000s\n^C\nworker: Hitting Ctrl+C again will terminate all running tasks!\n[WARNING/MainProcess] Initiating Soft Shutdown, terminating in 10 seconds\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 5/2000s\n[WARNING/ForkPoolWorker-8] long_running_task is running, sleeping 6/2000s\n^C\nWaiting gracefully for cold shutdown to complete...\n\nworker: Cold shutdown (MainProcess)\n^C[WARNING/MainProcess] Restoring 1 unacknowledged message(s)\n</code></pre> <p>Warning</p> <p>日志 <code>Restoring 1 unacknowledged message(s)</code> 具有误导性，因为在硬关闭后不能保证消息会被恢复。暖关闭 允许在暖关闭和冷关闭之间添加一个时间窗口，从而提高关闭过程的优雅性。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#worker_1","level":2,"title":"重启 worker 进程","text":"<p>要重启工作进程，您应该发送 <code>TERM</code> 信号并启动一个新的实例。在开发环境中管理工作进程最简单的方法是使用 <code>celery multi</code>：</p> <pre><code>celery multi start 1 -A proj -l INFO -c4 --pidfile=/var/run/celery/%n.pid\ncelery multi restart 1 --pidfile=/var/run/celery/%n.pid\n</code></pre> <p>对于生产部署，您应该使用初始化脚本或进程监控系统（参见 守护进程指南）。</p> <p>除了停止然后启动工作进程来重启之外，您也可以使用 <code>HUP</code> 信号来重启工作进程。请注意，工作进程将负责自行重启，因此这种方法容易出现问题，不建议在生产环境中使用：</p> <pre><code>kill -HUP $pid\n</code></pre> <p>Note</p> <p>通过 <code>HUP</code> 重启仅在工作进程作为守护进程在后台运行时有效（它没有控制终端）。</p> <p><code>HUP</code> 在 macOS 上被禁用，因为该平台存在限制。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_3","level":2,"title":"连接丢失时自动重连到代理","text":"<p>除非 <code>broker_connection_retry_on_startup</code> 设置为 False，Celery 将在第一次连接丢失后自动重试重新连接到代理。<code>broker_connection_retry</code> 控制是否自动重试重新连接到代理以进行后续重连。</p> <p>如果 <code>worker_cancel_long_running_tasks_on_connection_loss</code> 设置为 True，Celery 还将取消当前正在运行的任何长时间运行的任务。</p> <p>由于消息代理不跟踪在连接丢失之前已经获取了多少任务，Celery 将通过当前正在运行的任务数量乘以 <code>worker_prefetch_multiplier</code> 来减少预取计数。预取计数将在每次连接丢失前正在运行的任务完成后逐渐恢复到允许的最大值。</p> <p>此功能默认启用，但可以通过将 False 设置为 <code>worker_enable_prefetch_count_reduction</code> 来禁用。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_4","level":2,"title":"进程信号","text":"<p>工作进程的主进程重写了以下信号：</p> Signal Action <code>TERM</code> 温和关闭，等待任务完成。 <code>QUIT</code> 强制关闭，尽快终止 <code>USR1</code> 转储所有活动线程的堆栈跟踪。 <code>USR2</code> 远程调试，参见 <code>celery.contrib.rdb</code>。","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_5","level":2,"title":"文件路径中的变量","text":"<p><code>--logfile &lt;celery worker --logfile&gt;</code>、<code>--pidfile &lt;celery worker --pidfile&gt;</code> 和 <code>--statedb &lt;celery worker --statedb&gt;</code> 的文件路径参数可以包含变量，工作进程会展开这些变量：</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_6","level":3,"title":"节点名称替换","text":"<ul> <li><code>%p</code>: 完整节点名称</li> <li><code>%h</code>: 主机名，包括域名</li> <li><code>%n</code>: 仅主机名</li> <li><code>%d</code>: 仅域名</li> <li><code>%i</code>: 预分叉池进程索引，如果是主进程则为 0</li> <li><code>%I</code>: 带分隔符的预分叉池进程索引</li> </ul> <p>例如，如果当前主机名是 <code>george@foo.example.com</code>，那么这些变量会展开为：</p> <ul> <li><code>--logfile=%p.log</code> -&gt; <code>george@foo.example.com.log</code></li> <li><code>--logfile=%h.log</code> -&gt; <code>foo.example.com.log</code></li> <li><code>--logfile=%n.log</code> -&gt; <code>george.log</code></li> <li><code>--logfile=%d.log</code> -&gt; <code>example.com.log</code></li> </ul>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_7","level":3,"title":"预分叉池进程索引","text":"<p>预分叉池进程索引说明符会根据最终需要打开文件的进程展开为不同的文件名。</p> <p>这可以用于为每个子进程指定一个日志文件。</p> <p>请注意，即使进程退出或使用了自动缩放/<code>maxtasksperchild</code>/时间限制， 数字也会保持在进程限制范围内。也就是说，这个数字是进程索引， 而不是进程计数或进程ID。</p> <ul> <li> <p><code>%i</code> - 池进程索引，如果是主进程则为 0</p> <p>其中 <code>-n worker1@example.com -c2 -f %n-%i.log</code> 会产生三个日志文件：</p> <ul> <li><code>worker1-0.log</code> (主进程)</li> <li><code>worker1-1.log</code> (池进程 1)</li> <li><code>worker1-2.log</code> (池进程 2)</li> </ul> </li> <li> <p><code>%I</code> - 带分隔符的池进程索引</p> <p>其中 <code>-n worker1@example.com -c2 -f %n%I.log</code> 会产生三个日志文件：</p> <ul> <li><code>worker1.log</code> (主进程)</li> <li><code>worker1-1.log</code> (池进程 1)</li> <li><code>worker1-2.log</code> (池进程 2)</li> </ul> </li> </ul>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#worker-concurrency","level":2,"title":"并发性","text":"<p>默认情况下使用多进程来执行任务的并发执行，但你也可以使用 Eventlet。工作进程/线程的数量可以使用 <code>celery worker --concurrency</code> 参数进行更改，默认值为机器上可用的CPU数量。</p> <p>进程数量（多进程/prefork池）</p> <p>更多的池进程通常更好，但存在一个临界点，超过这个点添加更多的池进程会对性能产生负面影响。甚至有证据表明，运行多个工作实例可能比单个工作实例性能更好。例如，3个工作实例，每个有10个池进程。你需要进行实验来找到最适合你的数字，因为这取决于应用程序、工作负载、任务运行时间和其他因素。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_8","level":2,"title":"远程控制","text":"<p><code>celery</code> 命令</p> <p><code>celery</code> 程序用于从命令行执行远程控制命令。它支持下面列出的所有命令。</p> 支持 说明 pool prefork, eventlet, gevent, thread, blocking:solo (参见注释) broker amqp, redis <p>工作器具有使用高优先级广播消息队列进行远程控制的能力。命令可以定向到所有工作器，或特定的工作器列表。</p> <p>命令也可以有回复。客户端可以等待并收集这些回复。由于没有中央机构知道集群中有多少工作器可用，也无法估计有多少工作器可能发送回复，因此客户端有一个可配置的超时时间——回复到达的截止时间（以秒为单位）。此超时时间默认为一秒。如果工作器在截止时间内没有回复，并不一定意味着工作器没有回复，或者更糟的是已经死亡，而可能只是由网络延迟或工作器处理命令速度较慢引起的，因此请相应地调整超时时间。</p> <p>除了超时时间，客户端还可以指定等待的最大回复数。如果指定了目标，此限制将设置为目标主机的数量。</p> <p>Note</p> <p><code>solo</code> 池支持远程控制命令，但任何正在执行的任务都会阻塞任何等待的控制命令，因此如果工作器非常繁忙，其用途有限。在那种情况下，您必须增加客户端等待回复的超时时间。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#broadcast","level":3,"title":"<code>broadcast</code> 函数","text":"<p>这是用于向工作器发送命令的客户端函数。一些远程控制命令也有使用 <code>broadcast()</code> 在后台的更高级接口，例如 <code>rate_limit()</code> 和 <code>ping()</code>。</p> <p>发送 <code>rate_limit()</code> 命令和关键字参数：</p> <pre><code>&gt;&gt;&gt; app.control.broadcast('rate_limit', arguments={'task_name': 'myapp.mytask', 'rate_limit': '200/m'})\n</code></pre> <p>这将异步发送命令，无需等待回复。要请求回复，您必须使用 <code>reply</code> 参数：</p> <pre><code>&gt;&gt;&gt; app.control.broadcast('rate_limit', {'task_name': 'myapp.mytask', 'rate_limit': '200/m'}, reply=True)\n[{'worker1.example.com': 'New rate limit set successfully'},\n {'worker2.example.com': 'New rate limit set successfully'},\n {'worker3.example.com': 'New rate limit set successfully'}]\n</code></pre> <p>使用 <code>destination</code> 参数，您可以指定要接收命令的工作器列表：</p> <pre><code>&gt;&gt;&gt; app.control.broadcast('rate_limit', {\n...     'task_name': 'myapp.mytask',\n...     'rate_limit': '200/m'}, reply=True,\n...                             destination=['worker1@example.com'])\n[{'worker1.example.com': 'New rate limit set successfully'}]\n</code></pre> <p>当然，使用更高级的接口来设置速率限制要方便得多，但有些命令只能通过 <code>broadcast()</code> 请求。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_9","level":2,"title":"命令","text":"","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#revoke","level":3,"title":"<code>revoke</code>：撤销任务","text":"支持 说明 pool all, terminate only supported by prefork, eventlet and gevent broker amqp, redis command <code>celery -A proj control revoke &lt;task_id&gt;</code> <p>所有工作节点都会在内存中保留已撤销任务ID的记录，可以是内存中或持久化到磁盘。</p> <p>Note</p> <p>内存中保留的已撤销任务的最大数量可以通过 <code>CELERY_WORKER_REVOKES_MAX</code> 环境变量指定，默认值为50000。当超过限制时，撤销将在10800秒（3小时）后过期。可以使用 <code>CELERY_WORKER_REVOKE_EXPIRES</code> 环境变量更改此值。</p> <p>成功任务的内存限制也可以通过 <code>CELERY_WORKER_SUCCESSFUL_MAX</code> 和 <code>CELERY_WORKER_SUCCESSFUL_EXPIRES</code> 环境变量设置，默认值分别为1000和10800。</p> <p>当工作节点收到撤销请求时，它将跳过执行该任务，但不会终止已经在执行的任务，除非设置了 <code>terminate</code> 选项。</p> <p>Note</p> <p>terminate选项是管理员在任务卡住时的最后手段。它不是用于终止任务，而是用于终止执行任务的进程，并且该进程可能在发送信号时已经开始处理另一个任务，因此您绝不能以编程方式调用此功能。</p> <p>如果设置了 <code>terminate</code>，处理任务的子进程将被终止。默认发送的信号是 <code>TERM</code>，但您可以使用 <code>signal</code> 参数指定。信号可以是Python标准库中 <code>signal</code> 模块定义的任何信号的大写名称。</p> <p>终止任务也会撤销它。</p> <p>示例</p> <pre><code>&gt;&gt;&gt; result.revoke()\n\n&gt;&gt;&gt; AsyncResult(id).revoke()\n\n&gt;&gt;&gt; app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed')\n\n&gt;&gt;&gt; app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed',\n...                    terminate=True)\n\n&gt;&gt;&gt; app.control.revoke('d9078da5-9915-40a0-bfa1-392c7bde42ed',\n...                    terminate=True, signal='SIGKILL')\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_10","level":3,"title":"撤销多个任务","text":"<p>revoke方法也接受列表参数，可以一次性撤销多个任务。</p> <p>示例</p> <pre><code>&gt;&gt;&gt; app.control.revoke([\n...    '7993b0aa-1f0b-4780-9af0-c47c0858b3f2',\n...    'f565793e-b041-4b2b-9ca4-dca22762a55d',\n...    'd9d35e03-2997-42d0-a13e-64a66b88a618',\n])\n</code></pre> <p>自版本3.1起，<code>GroupResult.revoke</code> 方法就利用了此功能。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_11","level":3,"title":"持久化撤销","text":"<p>撤销任务的工作原理是向所有工作节点发送广播消息，工作节点随后在内存中保留已撤销任务的列表。当工作节点启动时，它将与集群中的其他工作节点同步已撤销的任务。</p> <p>已撤销任务的列表存储在内存中，因此如果所有工作节点都重启，已撤销ID的列表也会消失。如果要在重启之间保留此列表，需要使用 <code>--statedb</code> 参数指定一个文件来存储这些信息：</p> <pre><code>celery -A proj worker -l INFO --statedb=/var/run/celery/worker.state\n</code></pre> <p>或者如果使用 <code>celery multi</code>，您需要为每个工作节点实例创建一个文件，因此使用 <code>%n</code> 格式来扩展当前节点名称：</p> <pre><code>celery multi start 2 -l INFO --statedb=/var/run/celery/%n.state\n</code></pre> <p>请注意，撤销功能需要远程控制命令正常工作。目前仅RabbitMQ（amqp）和Redis支持远程控制命令。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#revoke_by_stamped_headers","level":3,"title":"<code>revoke_by_stamped_headers</code>：通过标记头撤销任务","text":"支持 说明 pool all, terminate only supported by prefork and eventlet broker amqp, redis command <code>celery -A proj control revoke_by_stamped_headers &lt;header=value&gt;</code> <p>此命令类似于 <code>revoke()</code>，但不是指定任务ID，而是将标记头指定为键值对，每个具有与键值对匹配的标记头的任务都将被撤销。</p> <p>Warning</p> <p>已撤销头的映射在重启之间不是持久的，因此如果重启工作节点，已撤销的头将丢失，需要重新映射。</p> <p>Warning</p> <p>如果工作池并发性高且启用了terminate，此命令的性能可能较差，因为它必须迭代所有正在运行的任务来查找具有指定标记头的任务。</p> <p>示例</p> <pre><code>&gt;&gt;&gt; app.control.revoke_by_stamped_headers({'header': 'value'})\n\n&gt;&gt;&gt; app.control.revoke_by_stamped_headers({'header': 'value'}, terminate=True)\n\n&gt;&gt;&gt; app.control.revoke_by_stamped_headers({'header': 'value'}, terminate=True, signal='SIGKILL')\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_12","level":3,"title":"通过标记头撤销多个任务","text":"<p><code>revoke_by_stamped_headers</code> 方法也接受列表参数，可以通过多个头或多个值进行撤销。</p> <p>示例</p> <pre><code>&gt;&gt; app.control.revoke_by_stamped_headers({\n...    'header_A': 'value_1',\n...    'header_B': ['value_2', 'value_3'],\n})\n</code></pre> <p>这将撤销所有具有标记头 <code>header_A</code> 且值为 <code>value_1</code> 的任务，以及所有具有标记头 <code>header_B</code> 且值为 <code>value_2</code> 或 <code>value_3</code> 的任务。</p> <p>CLI 示例</p> <pre><code>celery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2\n\ncelery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2 --terminate\n\ncelery -A proj control revoke_by_stamped_headers stamped_header_key_A=stamped_header_value_1 stamped_header_key_B=stamped_header_value_2 --terminate --signal=SIGKILL\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#time-limits","level":2,"title":"时间限制","text":"支持 说明 pool prefork/gevent (参见下面的注释) <p>软限制还是硬限制？</p> <p>时间限制设置为两个值：<code>soft</code>（软限制）和<code>hard</code>（硬限制）。软时间限制允许任务捕获异常，在终止前进行清理：硬超时无法捕获，会强制终止任务。</p> <p>单个任务可能永远运行，如果您有很多任务在等待永远不会发生的事件，您将无限期地阻止工作者处理新任务。防御这种情况发生的最佳方法是启用时间限制。</p> <p>时间限制（<code>--time-limit</code>）是任务在执行的进程被终止并由新进程替换之前可以运行的最大秒数。您还可以启用软时间限制（<code>--soft-time-limit</code>），这会在硬时间限制终止任务之前引发一个任务可以捕获的异常以进行清理：</p> <pre><code>from myapp import app\nfrom celery.exceptions import SoftTimeLimitExceeded\n\n@app.task\ndef mytask():\n    try:\n        do_work()\n    except SoftTimeLimitExceeded:\n        clean_up_in_a_hurry()\n</code></pre> <p>时间限制也可以使用 <code>task_time_limit</code> / <code>task_soft_time_limit</code> 设置来配置。您还可以使用 <code>AsyncResult.get()</code> 函数的 <code>timeout</code> 参数为客户端操作指定时间限制。</p> <p>Note</p> <p>时间限制目前在不支持 <code>SIGUSR1</code> 信号的平台上不起作用。</p> <p>Note</p> <p>gevent 池不实现软时间限制。此外，如果任务正在阻塞，它不会强制执行硬时间限制。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_13","level":3,"title":"运行时更改时间限制","text":"支持 说明 broker amqp, redis <p>有一个远程控制命令可以让您更改任务的软硬时间限制——名为 <code>time_limit</code>。</p> <p>将 <code>tasks.crawl_the_web</code> 任务的时间限制更改为软限制一分钟，硬限制两分钟的示例：</p> <pre><code>&gt;&gt;&gt; app.control.time_limit('tasks.crawl_the_web', soft=60, hard=120, reply=True)\n[{'worker1.example.com': {'ok': 'time limits set successfully'}}]\n</code></pre> <p>只有时间限制更改后开始执行的任务才会受到影响。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_14","level":2,"title":"速率限制","text":"","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_15","level":3,"title":"运行时更改速率限制","text":"<p>示例：将 <code>myapp.mytask</code> 任务的速率限制更改为每分钟最多执行200个该类型的任务：</p> <pre><code>&gt;&gt;&gt; app.control.rate_limit('myapp.mytask', '200/m')\n</code></pre> <p>上面的示例没有指定目标，因此更改请求将影响集群中的所有工作实例。如果您只想影响特定的工作器列表，可以包含 <code>destination</code> 参数：</p> <pre><code>&gt;&gt;&gt; app.control.rate_limit('myapp.mytask', '200/m', destination=['celery@worker1.example.com'])\n</code></pre> <p>Warning</p> <p>这不会影响启用了 <code>worker_disable_rate_limits</code> 设置的工作器。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#max-tasks-per-child","level":2,"title":"每个子进程最大任务数设置","text":"支持 说明 pool prefork <p>使用此选项，您可以配置工作进程在被新进程替换之前可以执行的最大任务数。</p> <p>这在您有无法控制的内存泄漏时非常有用，例如来自闭源C扩展的内存泄漏。</p> <p>该选项可以通过工作进程的 <code>celery worker --max-tasks-per-child</code> 参数或使用 <code>worker_max_tasks_per_child</code> 设置来配置。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_16","level":2,"title":"每个子进程的最大内存设置","text":"支持 说明 pool prefork <p>通过此选项，您可以配置工作进程在被新进程替换之前可以执行的最大驻留内存量。</p> <p>如果您有无法控制的内存泄漏（例如来自闭源C扩展），这将非常有用。</p> <p>该选项可以使用工作进程的 <code>celery worker --max-memory-per-child</code> 参数或使用 <code>worker_max_memory_per_child</code> 设置来配置。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_17","level":2,"title":"自动扩展","text":"支持 说明 pool prefork, gevent <p>autoscaler（自动扩展器）组件用于根据负载动态调整池的大小：</p> <ul> <li>当有工作需要处理时，自动扩展器会添加更多的池进程；当工作负载较低时，开始移除进程。</li> </ul> <p>通过 <code>celery worker --autoscale</code> 选项启用自动扩展功能，该选项需要两个数字：池进程的最大和最小数量：</p> <pre><code>--autoscale=AUTOSCALE\n     Enable autoscaling by providing\n     max_concurrency,min_concurrency.  Example:\n       --autoscale=10,3 (always keep 3 processes, but grow to\n      10 if necessary).\n</code></pre> <p>您也可以通过继承 <code>celery.worker.autoscale.Autoscaler</code> 类来为自动扩展器定义自己的规则。一些指标的想法包括平均负载或可用内存量。您可以使用 <code>worker_autoscaler</code> 设置来指定自定义的自动扩展器。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_18","level":2,"title":"队列","text":"<p>一个工作实例可以从任意数量的队列中消费消息。默认情况下，它将消费在 <code>task_queues</code> 设置中定义的所有队列（如果未指定，则回退到名为 <code>celery</code> 的默认队列）。</p> <p>您可以在启动时通过向 <code>celery worker -Q</code> 选项提供逗号分隔的队列列表来指定要从哪些队列消费：</p> <pre><code>celery -A proj worker -l INFO -Q foo,bar,baz\n</code></pre> <p>如果队列名称在 <code>task_queues</code> 中定义，它将使用该配置，但如果未在队列列表中定义，Celery 将自动为您生成一个新队列（取决于 <code>task_create_missing_queues</code> 选项）。</p> <p>您还可以使用远程控制命令 <code>add_consumer</code> 和 <code>cancel_consumer</code> 在运行时告诉工作器开始和停止从队列消费。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_19","level":3,"title":"添加消费者","text":"<p><code>add_consumer</code> 控制命令将告诉一个或多个工作器开始从队列消费消息。此操作是幂等的。</p> <p>要告诉集群中的所有工作器开始从名为 \"<code>foo</code>\" 的队列消费，您可以使用 <code>celery control</code> 程序：</p> <pre><code>celery -A proj control add_consumer foo\n-&gt; worker1.local: OK\n    started consuming from u'foo'\n</code></pre> <p>如果您想指定特定的工作器，可以使用 <code>celery control --destination</code> 参数：</p> <pre><code>celery -A proj control add_consumer foo -d celery@worker1.local\n</code></pre> <p>同样可以使用 <code>add_consumer()</code> 方法动态完成：</p> <pre><code>&gt;&gt;&gt; app.control.add_consumer('foo', reply=True)\n[{u'worker1.local': {u'ok': u\"already consuming from u'foo'\"}}]\n\n&gt;&gt;&gt; app.control.add_consumer('foo', reply=True,\n...                          destination=['worker1@example.com'])\n[{u'worker1.local': {u'ok': u\"already consuming from u'foo'\"}}]\n</code></pre> <p>到目前为止，我们只展示了使用自动队列的示例，如果您需要更多控制，还可以指定交换器、路由键甚至其他选项：</p> <pre><code>&gt;&gt;&gt; app.control.add_consumer(\n...     queue='baz',\n...     exchange='ex',\n...     exchange_type='topic',\n...     routing_key='media.*',\n...     options={\n...         'queue_durable': False,\n...         'exchange_durable': False,\n...     },\n...     reply=True,\n...     destination=['w1@example.com', 'w2@example.com'])\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_20","level":3,"title":"取消消费者","text":"<p>您可以使用 <code>cancel_consumer</code> 控制命令通过队列名称取消消费者。</p> <p>要强制集群中的所有工作器取消从队列消费，您可以使用 <code>celery control</code> 程序：</p> <pre><code>celery -A proj control cancel_consumer foo\n</code></pre> <p><code>celery control --destination</code> 参数可用于指定一个工作器或工作器列表来执行该命令：</p> <pre><code>celery -A proj control cancel_consumer foo -d celery@worker1.local\n</code></pre> <p>您也可以使用 <code>cancel_consumer()</code> 方法以编程方式取消消费者：</p> <pre><code>&gt;&gt;&gt; app.control.cancel_consumer('foo', reply=True)\n[{u'worker1.local': {u'ok': u\"no longer consuming from u'foo'\"}}]\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_21","level":3,"title":"活动队列列表","text":"<p>您可以使用 <code>active_queues</code> 控制命令获取工作器正在消费的队列列表：</p> <pre><code>celery -A proj inspect active_queues\n[...]\n</code></pre> <p>与所有其他远程控制命令一样，这也支持 <code>celery inspect --destination</code> 参数，用于指定应回复请求的工作器：</p> <pre><code>$ celery -A proj inspect active_queues -d celery@worker1.local\n[...]\n</code></pre> <p>这也可以通过使用 <code>active_queues()</code> 方法以编程方式完成：</p> <pre><code>&gt;&gt;&gt; app.control.inspect().active_queues()\n[...]\n\n&gt;&gt;&gt; app.control.inspect(['worker1.local']).active_queues()\n[...]\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_22","level":2,"title":"检查工作进程","text":"<p><code>inspect</code> 允许您检查正在运行的工作进程。它在底层使用远程控制命令。</p> <p>您也可以使用 <code>celery</code> 命令来检查工作进程，它支持与 <code>control</code> 接口相同的命令。</p> <pre><code>&gt;&gt;&gt; # 检查所有节点。\n&gt;&gt;&gt; i = app.control.inspect()\n\n&gt;&gt;&gt; # 指定多个节点进行检查。\n&gt;&gt;&gt; i = app.control.inspect(['worker1.example.com',\n                            'worker2.example.com'])\n\n&gt;&gt;&gt; # 指定单个节点进行检查。\n&gt;&gt;&gt; i = app.control.inspect('worker1.example.com')\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_23","level":3,"title":"已注册任务的转储","text":"<p>您可以使用 <code>registered()</code> 获取工作进程中已注册任务的列表：</p> <pre><code>&gt;&gt;&gt; i.registered()\n[{'worker1.example.com': ['tasks.add', 'tasks.sleeptask']}]\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_24","level":3,"title":"当前执行任务的转储","text":"<p>您可以使用 <code>active()</code> 获取活动任务的列表：</p> <pre><code>&gt;&gt;&gt; i.active()\n[{'worker1.example.com':\n    [{'name': 'tasks.sleeptask',\n      'id': '32666e9b-809c-41fa-8e93-5ae0c80afbbf',\n      'args': '(8,)',\n      'kwargs': '{}'}]}]\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#eta","level":3,"title":"已调度（ETA）任务的转储","text":"<p>您可以使用 <code>scheduled()</code> 获取等待调度的任务列表：</p> <pre><code>&gt;&gt;&gt; i.scheduled()\n[{'worker1.example.com':\n    [{'eta': '2010-06-07 09:07:52', 'priority': 0,\n      'request': {\n        'name': 'tasks.sleeptask',\n        'id': '1a7980ea-8b19-413e-91d2-0b74f3844c4d',\n        'args': '[1]',\n        'kwargs': '{}'}},\n     {'eta': '2010-06-07 09:07:53', 'priority': 0,\n      'request': {\n        'name': 'tasks.sleeptask',\n        'id': '49661b9a-aa22-4120-94b7-9ee8031d219d',\n        'args': '[2]',\n         'kwargs': '{}'}}]}]\n</code></pre> <p>Note</p> <p>这些是具有 ETA/倒计时参数的任务，不是周期性任务。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_25","level":3,"title":"保留任务的转储","text":"<p>保留任务是已接收但仍在等待执行的任务。</p> <p>您可以使用 <code>reserved()</code> 获取这些任务的列表：</p> <pre><code>&gt;&gt;&gt; i.reserved()\n[{'worker1.example.com':\n    [{'name': 'tasks.sleeptask',\n      'id': '32666e9b-809c-41fa-8e93-5ae0c80afbbf',\n      'args': '(8,)',\n      'kwargs': '{}'}]}]\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#worker-statistics","level":3,"title":"统计信息","text":"<p>远程控制命令 <code>inspect stats</code>（或 <code>stats()</code>）将为您提供有关工作进程的有用（或不太有用）统计信息的长列表：</p> <pre><code>celery -A proj inspect stats\n</code></pre> <p>有关输出详细信息，请查阅 <code>stats()</code> 的参考文档。</p>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_26","level":2,"title":"附加命令","text":"","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_27","level":3,"title":"远程关机","text":"<p>此命令将优雅地远程关闭工作进程：</p> <pre><code>&gt;&gt;&gt; app.control.broadcast('shutdown') # 关闭所有工作进程\n&gt;&gt;&gt; app.control.broadcast('shutdown', destination='worker1@example.com')\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#ping","level":3,"title":"Ping","text":"<p>此命令向存活的工作进程请求 ping。工作进程回复字符串 'pong'，仅此而已。除非您指定自定义超时时间，否则它将使用默认的一秒超时时间：</p> <pre><code>&gt;&gt;&gt; app.control.ping(timeout=0.5)\n[{'worker1.example.com': 'pong'},\n {'worker2.example.com': 'pong'},\n {'worker3.example.com': 'pong'}]\n</code></pre> <p><code>ping()</code> 也支持 <code>destination</code> 参数，因此您可以指定要 ping 的工作进程：</p> <pre><code>&gt;&gt;&gt; ping(['worker2.example.com', 'worker3.example.com'])\n[{'worker2.example.com': 'pong'},\n {'worker3.example.com': 'pong'}]\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_28","level":3,"title":"启用/禁用事件","text":"<p>您可以使用 <code>enable_events</code>、<code>disable_events</code> 命令来启用/禁用事件。 这对于使用 <code>celery events</code>/<code>celerymon</code> 临时监控工作进程很有用。</p> <pre><code>&gt;&gt;&gt; app.control.enable_events()\n&gt;&gt;&gt; app.control.disable_events()\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/workers/#_29","level":2,"title":"编写你自己的远程控制命令","text":"<p>有两种类型的远程控制命令：</p> <ul> <li> <p>检查命令（Inspect command）</p> <p>没有副作用，通常只是返回在worker中找到的一些值，比如当前注册的任务列表、活动任务列表等。</p> </li> <li> <p>控制命令（Control command）</p> <p>执行副作用操作，比如添加一个新的队列来消费。</p> </li> </ul> <p>远程控制命令在控制面板中注册，它们接受一个参数：当前的 <code>celery.worker.control.ControlDispatch</code>实例。从这里你可以访问活动的 <code>celery.worker.consumer.Consumer</code>（如果需要的话）。</p> <p>这是一个增加任务预取计数的控制命令示例：</p> <pre><code>from celery.worker.control import control_command\n\n@control_command(\n    args=[('n', int)],\n    signature='[N=1]',  # &lt;- 用于命令行帮助。\n)\ndef increase_prefetch_count(state, n=1):\n    state.consumer.qos.increment_eventually(n)\n    return {'ok': 'prefetch count incremented'}\n</code></pre> <p>确保你将此代码添加到worker导入的模块中：这可以是定义Celery应用程序的同一个模块，或者你可以将该模块添加到 <code>imports</code> 设置中。</p> <p>重启worker以便控制命令被注册，现在你可以使用 <code>celery control</code> 实用程序调用你的命令：</p> <pre><code>celery -A proj control increase_prefetch_count 3\n</code></pre> <p>你也可以向:program:<code>celery inspect</code>程序添加操作，例如一个读取当前预取计数的操作：</p> <pre><code>from celery.worker.control import inspect_command\n\n@inspect_command()\ndef current_prefetch_count(state):\n    return {'prefetch_count': state.consumer.qos.value}\n</code></pre> <p>重启worker后，你现在可以使用 <code>celery inspect</code> 程序查询这个值：</p> <pre><code>celery -A proj inspect current_prefetch_count\n</code></pre>","path":["用户指南","工作进程"],"tags":[]},{"location":"user-guide/concurrency/","level":1,"title":"并发","text":"<p>Celery 中的并发支持任务的并行执行。默认模型 <code>prefork</code> 适用于许多场景，通常推荐给大多数用户使用。事实上，切换到其他模式会静默禁用某些功能，如 <code>soft_timeout</code> 和 <code>max_tasks_per_child</code>。</p> <p>本页简要概述了可用的选项，您可以在启动 worker 时使用 <code>--pool</code> 选项进行选择。</p>","path":["用户指南","并发"],"tags":[]},{"location":"user-guide/concurrency/#_2","level":2,"title":"并发选项概述","text":"<ul> <li><code>prefork</code>：默认选项，适用于CPU密集型任务和大多数用例。它稳健可靠，除非有特定需求，否则推荐使用。</li> <li><code>eventlet</code> 和 <code>gevent</code>：专为 IO 密集型任务设计，这些模型使用 greenlets 实现高并发。请注意，某些功能（如 <code>soft_timeout</code>）在这些模式下不可用。这些模式有详细的文档页面链接如下。</li> <li><code>solo</code>：在主线程中顺序执行任务。</li> <li><code>threads</code>：利用线程实现并发，如果 <code>concurrent.futures</code> 模块存在则可用。</li> <li> <p><code>custom</code>：允许通过环境变量指定自定义的worker池实现。</p> </li> <li> <p>Eventlet</p> </li> <li>Gevent</li> </ul> <p>Note</p> <p>虽然 <code>eventlet</code> 和 <code>gevent</code> 等替代模型可用，但它们可能缺少 <code>prefork</code> 的某些功能。除非有特定要求，否则我们推荐将 <code>prefork</code> 作为起点。</p>","path":["用户指南","并发"],"tags":[]},{"location":"user-guide/concurrency/eventlet/","level":1,"title":"使用 Eventlet 实现并发","text":"","path":["用户指南","并发","使用 Eventlet 实现并发"],"tags":[]},{"location":"user-guide/concurrency/eventlet/#_1","level":2,"title":"介绍","text":"<p>Eventlet 官网将其描述为一个用于 Python 的并发网络库，它允许您改变代码的运行方式，而不是编写方式。</p> <ul> <li>它使用 <code>epoll(4)</code> 或 <code>libevent</code> 来实现 <code>高度可扩展的非阻塞 I/O</code>_。</li> <li><code>协程</code> 确保开发者使用类似于线程的阻塞式编程风格，但提供了非阻塞 I/O 的优势。</li> <li>事件分发是隐式的：这意味着您可以轻松地从 Python 解释器使用 Eventlet，或者作为大型应用程序的一小部分使用。</li> </ul> <p>Celery 支持 Eventlet 作为替代的执行池实现，在某些情况下优于 prefork。但是，您需要确保一个任务不会阻塞事件循环太长时间。通常，CPU 密集型操作与 Eventlet 配合不佳。还要注意，某些库（通常带有 C 扩展）无法进行猴子补丁，因此无法从使用 Eventlet 中受益。如果您不确定，请参考它们的文档。例如，pylibmc 不允许与 Eventlet 协作，但 psycopg2 可以（当它们都是带有 C 扩展的库时）。</p> <p>prefork 池可以利用多个进程，但数量通常限制为每个 CPU 几个进程。使用 Eventlet，您可以高效地生成数百或数千个绿色线程。在一个非正式的测试中，使用 feed hub 系统，Eventlet 池每秒可以获取和处理数百个 feed，而 prefork 池处理 100 个 feed 需要 14 秒。请注意，这是异步 I/O 特别擅长的应用之一（异步 HTTP 请求）。您可能希望混合使用 Eventlet 和 prefork worker，并根据兼容性或最佳效果来路由任务。</p>","path":["用户指南","并发","使用 Eventlet 实现并发"],"tags":[]},{"location":"user-guide/concurrency/eventlet/#eventlet_1","level":2,"title":"启用 Eventlet","text":"<p>您可以使用 <code>celery worker -P</code> worker 选项来启用 Eventlet 池。</p> <pre><code>celery -A proj worker -P eventlet -c 1000\n</code></pre>","path":["用户指南","并发","使用 Eventlet 实现并发"],"tags":[]},{"location":"user-guide/concurrency/eventlet/#_2","level":2,"title":"示例","text":"<p>请参阅 Celery 发行版中的 Eventlet 示例 目录，了解一些使用 Eventlet 支持的示例。</p>","path":["用户指南","并发","使用 Eventlet 实现并发"],"tags":[]},{"location":"user-guide/concurrency/gevent/","level":1,"title":"使用 gevent 的并发","text":"","path":["用户指南","并发","使用 gevent 的并发"],"tags":[]},{"location":"user-guide/concurrency/gevent/#_1","level":2,"title":"介绍","text":"<p>gevent 主页将其描述为一个基于协程的 Python 网络库，它使用 greenlet 在 libev 或 libuv 事件循环之上提供高级同步 API。</p> <p>特性包括：</p> <ul> <li>基于 libev 或 libuv 的快速事件循环</li> <li>基于 greenlets 的轻量级执行单元</li> <li>重用 Python 标准库概念的 API（例如有 events 和 queues）</li> <li>支持 SSL 的协作式套接字</li> <li>通过线程池、dnspython 或 c-ares 执行的协作式 DNS 查询</li> <li>猴子补丁工具使第三方模块变得协作式</li> <li>TCP/UDP/HTTP 服务器</li> <li>子进程支持（通过 gevent.subprocess）</li> <li>线程池</li> </ul> <p>gevent 受 eventlet 启发，但具有更一致的 API、更简单的实现和更好的性能。阅读其他人为什么使用 gevent并查看基于 gevent 的开源项目列表。</p>","path":["用户指南","并发","使用 gevent 的并发"],"tags":[]},{"location":"user-guide/concurrency/gevent/#gevent_1","level":2,"title":"启用 gevent","text":"<p>您可以使用 <code>celery worker -P gevent</code> 或 <code>celery worker --pool=gevent</code> 工作器选项来启用 gevent 池。</p> <pre><code>celery -A proj worker -P gevent -c 1000\n</code></pre>","path":["用户指南","并发","使用 gevent 的并发"],"tags":[]},{"location":"user-guide/concurrency/gevent/#_2","level":2,"title":"示例","text":"<p>请参阅 Celery 发行版中的 gevent 示例 目录，了解一些使用 Eventlet 支持的示例。</p>","path":["用户指南","并发","使用 gevent 的并发"],"tags":[]},{"location":"user-guide/concurrency/gevent/#_3","level":2,"title":"已知问题","text":"<p>使用 Python 3.11 和 gevent 存在一个已知问题。该问题在此处有文档记录，并在 gevent 问题 中得到解决。升级到 greenlet 3.0 可以解决此问题。</p>","path":["用户指南","并发","使用 gevent 的并发"],"tags":[]}]}